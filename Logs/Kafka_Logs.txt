2025-12-08 11:22:32.816 | ===> User
2025-12-08 11:22:32.820 | uid=0(root) gid=0(root) groups=0(root)
2025-12-08 11:22:32.820 | ===> Configuring ...
2025-12-08 11:22:32.835 | Running in Zookeeper mode...
2025-12-08 11:22:46.152 | ===> Running preflight checks ... 
2025-12-08 11:22:46.164 | ===> Check if /var/lib/kafka/data is writable ...
2025-12-08 11:22:47.683 | ===> Check if Zookeeper is healthy ...
2025-12-08 11:22:52.759 | [2025-12-08 05:52:52,759] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.760 | [2025-12-08 05:52:52,759] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.760 | [2025-12-08 05:52:52,760] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.760 | [2025-12-08 05:52:52,760] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.760 | [2025-12-08 05:52:52,760] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.760 | [2025-12-08 05:52:52,760] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-clients-7.4.0-ccs.jar:/usr/share/java/cp-base-new/kafka_2.13-7.4.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.11.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.4.0-ccs.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/kafka-raft-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.2-1.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.4.0-ccs.jar:/usr/share/java/cp-base-new/snappy-java-1.1.8.4.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/common-utils-7.4.0.jar:/usr/share/java/cp-base-new/kafka-metadata-7.4.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/logredactor-1.0.11.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/utility-belt-7.4.0.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.4.0-ccs.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.4.0.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/kafka-server-common-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/jose4j-0.7.9.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.6.0.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.761 | [2025-12-08 05:52:52,761] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.761 | [2025-12-08 05:52:52,761] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.761 | [2025-12-08 05:52:52,761] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.761 | [2025-12-08 05:52:52,761] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.762 | [2025-12-08 05:52:52,761] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.762 | [2025-12-08 05:52:52,762] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.762 | [2025-12-08 05:52:52,762] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.762 | [2025-12-08 05:52:52,762] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.762 | [2025-12-08 05:52:52,762] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.762 | [2025-12-08 05:52:52,762] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.763 | [2025-12-08 05:52:52,763] INFO Client environment:os.memory.max=1932MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.763 | [2025-12-08 05:52:52,763] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.779 | [2025-12-08 05:52:52,779] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@797badd3 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:52.811 | [2025-12-08 05:52:52,811] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-08 11:22:52.854 | [2025-12-08 05:52:52,853] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-08 11:22:52.932 | [2025-12-08 05:52:52,930] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:53.181 | [2025-12-08 05:52:53,181] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:53.181 | [2025-12-08 05:52:53,181] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:53.257 | [2025-12-08 05:52:53,244] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:53.257 | java.net.ConnectException: Connection refused
2025-12-08 11:22:53.257 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 11:22:53.257 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 11:22:53.257 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 11:22:53.257 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 11:22:54.384 | [2025-12-08 05:52:54,383] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:54.385 | [2025-12-08 05:52:54,384] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:54.389 | [2025-12-08 05:52:54,387] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:54.389 | java.net.ConnectException: Connection refused
2025-12-08 11:22:54.389 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 11:22:54.389 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 11:22:54.389 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 11:22:54.389 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 11:22:55.491 | [2025-12-08 05:52:55,490] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:55.491 | [2025-12-08 05:52:55,491] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:55.495 | [2025-12-08 05:52:55,494] INFO Socket connection established, initiating session, client: /172.18.0.4:56494, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:55.785 | [2025-12-08 05:52:55,785] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x10000d40e7a0000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:55.874 | [2025-12-08 05:52:55,874] WARN An exception was thrown while closing send thread for session 0x10000d40e7a0000. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:55.875 | EndOfStreamException: Unable to read additional data from server sessionid 0x10000d40e7a0000, likely server has closed socket
2025-12-08 11:22:55.875 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-08 11:22:55.875 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-08 11:22:55.875 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 11:22:55.984 | [2025-12-08 05:52:55,984] INFO Session: 0x10000d40e7a0000 closed (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:22:55.987 | [2025-12-08 05:52:55,987] INFO EventThread shut down for session: 0x10000d40e7a0000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:22:56.037 | Using log4j config /etc/kafka/log4j.properties
2025-12-08 11:22:56.238 | ===> Launching ... 
2025-12-08 11:22:56.338 | ===> Launching kafka ... 
2025-12-08 11:23:01.231 | [2025-12-08 05:53:01,230] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-12-08 11:23:03.546 | [2025-12-08 05:53:03,545] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-08 11:23:04.208 | [2025-12-08 05:53:04,200] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-08 11:23:04.225 | [2025-12-08 05:53:04,225] INFO starting (kafka.server.KafkaServer)
2025-12-08 11:23:04.237 | [2025-12-08 05:53:04,237] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-12-08 11:23:04.298 | [2025-12-08 05:53:04,298] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,352] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,353] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,353] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,353] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,353] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,353] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.353 | [2025-12-08 05:53:04,353] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.358 | [2025-12-08 05:53:04,358] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@37c7595 (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:23:04.372 | [2025-12-08 05:53:04,372] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-08 11:23:04.411 | [2025-12-08 05:53:04,410] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:23:04.441 | [2025-12-08 05:53:04,430] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 11:23:04.448 | [2025-12-08 05:53:04,448] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:23:04.480 | [2025-12-08 05:53:04,479] INFO Socket connection established, initiating session, client: /172.18.0.4:56498, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:23:04.596 | [2025-12-08 05:53:04,595] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x10000d40e7a0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:23:04.606 | [2025-12-08 05:53:04,605] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 11:23:06.263 | [2025-12-08 05:53:06,261] INFO Cluster ID = xTa4oP5DQQqhwOcnPmb7dg (kafka.server.KafkaServer)
2025-12-08 11:23:06.299 | [2025-12-08 05:53:06,298] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
2025-12-08 11:23:06.522 | [2025-12-08 05:53:06,521] INFO KafkaConfig values: 
2025-12-08 11:23:06.522 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-12-08 11:23:06.522 | 	alter.config.policy.class.name = null
2025-12-08 11:23:06.522 | 	alter.log.dirs.replication.quota.window.num = 11
2025-12-08 11:23:06.522 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-12-08 11:23:06.522 | 	authorizer.class.name = 
2025-12-08 11:23:06.522 | 	auto.create.topics.enable = true
2025-12-08 11:23:06.522 | 	auto.include.jmx.reporter = true
2025-12-08 11:23:06.522 | 	auto.leader.rebalance.enable = true
2025-12-08 11:23:06.522 | 	background.threads = 10
2025-12-08 11:23:06.522 | 	broker.heartbeat.interval.ms = 2000
2025-12-08 11:23:06.522 | 	broker.id = 1
2025-12-08 11:23:06.522 | 	broker.id.generation.enable = true
2025-12-08 11:23:06.522 | 	broker.rack = null
2025-12-08 11:23:06.522 | 	broker.session.timeout.ms = 9000
2025-12-08 11:23:06.522 | 	client.quota.callback.class = null
2025-12-08 11:23:06.522 | 	compression.type = producer
2025-12-08 11:23:06.522 | 	connection.failed.authentication.delay.ms = 100
2025-12-08 11:23:06.522 | 	connections.max.idle.ms = 600000
2025-12-08 11:23:06.522 | 	connections.max.reauth.ms = 0
2025-12-08 11:23:06.522 | 	control.plane.listener.name = null
2025-12-08 11:23:06.522 | 	controlled.shutdown.enable = true
2025-12-08 11:23:06.522 | 	controlled.shutdown.max.retries = 3
2025-12-08 11:23:06.522 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-12-08 11:23:06.522 | 	controller.listener.names = null
2025-12-08 11:23:06.522 | 	controller.quorum.append.linger.ms = 25
2025-12-08 11:23:06.522 | 	controller.quorum.election.backoff.max.ms = 1000
2025-12-08 11:23:06.522 | 	controller.quorum.election.timeout.ms = 1000
2025-12-08 11:23:06.522 | 	controller.quorum.fetch.timeout.ms = 2000
2025-12-08 11:23:06.522 | 	controller.quorum.request.timeout.ms = 2000
2025-12-08 11:23:06.522 | 	controller.quorum.retry.backoff.ms = 20
2025-12-08 11:23:06.522 | 	controller.quorum.voters = []
2025-12-08 11:23:06.522 | 	controller.quota.window.num = 11
2025-12-08 11:23:06.522 | 	controller.quota.window.size.seconds = 1
2025-12-08 11:23:06.522 | 	controller.socket.timeout.ms = 30000
2025-12-08 11:23:06.522 | 	create.topic.policy.class.name = null
2025-12-08 11:23:06.522 | 	default.replication.factor = 1
2025-12-08 11:23:06.522 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-12-08 11:23:06.522 | 	delegation.token.expiry.time.ms = 86400000
2025-12-08 11:23:06.522 | 	delegation.token.master.key = null
2025-12-08 11:23:06.522 | 	delegation.token.max.lifetime.ms = 604800000
2025-12-08 11:23:06.522 | 	delegation.token.secret.key = null
2025-12-08 11:23:06.522 | 	delete.records.purgatory.purge.interval.requests = 1
2025-12-08 11:23:06.522 | 	delete.topic.enable = true
2025-12-08 11:23:06.522 | 	early.start.listeners = null
2025-12-08 11:23:06.522 | 	fetch.max.bytes = 57671680
2025-12-08 11:23:06.522 | 	fetch.purgatory.purge.interval.requests = 1000
2025-12-08 11:23:06.522 | 	group.initial.rebalance.delay.ms = 3000
2025-12-08 11:23:06.522 | 	group.max.session.timeout.ms = 1800000
2025-12-08 11:23:06.522 | 	group.max.size = 2147483647
2025-12-08 11:23:06.522 | 	group.min.session.timeout.ms = 6000
2025-12-08 11:23:06.522 | 	initial.broker.registration.timeout.ms = 60000
2025-12-08 11:23:06.522 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-12-08 11:23:06.522 | 	inter.broker.protocol.version = 3.4-IV0
2025-12-08 11:23:06.522 | 	kafka.metrics.polling.interval.secs = 10
2025-12-08 11:23:06.522 | 	kafka.metrics.reporters = []
2025-12-08 11:23:06.522 | 	leader.imbalance.check.interval.seconds = 300
2025-12-08 11:23:06.522 | 	leader.imbalance.per.broker.percentage = 10
2025-12-08 11:23:06.522 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-12-08 11:23:06.522 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-12-08 11:23:06.522 | 	log.cleaner.backoff.ms = 15000
2025-12-08 11:23:06.522 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-12-08 11:23:06.522 | 	log.cleaner.delete.retention.ms = 86400000
2025-12-08 11:23:06.522 | 	log.cleaner.enable = true
2025-12-08 11:23:06.522 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-12-08 11:23:06.522 | 	log.cleaner.io.buffer.size = 524288
2025-12-08 11:23:06.522 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-12-08 11:23:06.522 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-12-08 11:23:06.522 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-12-08 11:23:06.522 | 	log.cleaner.min.compaction.lag.ms = 0
2025-12-08 11:23:06.522 | 	log.cleaner.threads = 1
2025-12-08 11:23:06.522 | 	log.cleanup.policy = [delete]
2025-12-08 11:23:06.522 | 	log.dir = /tmp/kafka-logs
2025-12-08 11:23:06.522 | 	log.dirs = /var/lib/kafka/data
2025-12-08 11:23:06.522 | 	log.flush.interval.messages = 9223372036854775807
2025-12-08 11:23:06.522 | 	log.flush.interval.ms = null
2025-12-08 11:23:06.522 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-12-08 11:23:06.522 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-12-08 11:23:06.522 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-12-08 11:23:06.522 | 	log.index.interval.bytes = 4096
2025-12-08 11:23:06.522 | 	log.index.size.max.bytes = 10485760
2025-12-08 11:23:06.522 | 	log.message.downconversion.enable = true
2025-12-08 11:23:06.522 | 	log.message.format.version = 3.0-IV1
2025-12-08 11:23:06.522 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-12-08 11:23:06.522 | 	log.message.timestamp.type = CreateTime
2025-12-08 11:23:06.522 | 	log.preallocate = false
2025-12-08 11:23:06.522 | 	log.retention.bytes = -1
2025-12-08 11:23:06.522 | 	log.retention.check.interval.ms = 300000
2025-12-08 11:23:06.522 | 	log.retention.hours = 168
2025-12-08 11:23:06.522 | 	log.retention.minutes = null
2025-12-08 11:23:06.522 | 	log.retention.ms = null
2025-12-08 11:23:06.522 | 	log.roll.hours = 168
2025-12-08 11:23:06.522 | 	log.roll.jitter.hours = 0
2025-12-08 11:23:06.522 | 	log.roll.jitter.ms = null
2025-12-08 11:23:06.522 | 	log.roll.ms = null
2025-12-08 11:23:06.522 | 	log.segment.bytes = 1073741824
2025-12-08 11:23:06.522 | 	log.segment.delete.delay.ms = 60000
2025-12-08 11:23:06.522 | 	max.connection.creation.rate = 2147483647
2025-12-08 11:23:06.522 | 	max.connections = 2147483647
2025-12-08 11:23:06.522 | 	max.connections.per.ip = 2147483647
2025-12-08 11:23:06.522 | 	max.connections.per.ip.overrides = 
2025-12-08 11:23:06.522 | 	max.incremental.fetch.session.cache.slots = 1000
2025-12-08 11:23:06.522 | 	message.max.bytes = 1048588
2025-12-08 11:23:06.522 | 	metadata.log.dir = null
2025-12-08 11:23:06.522 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-12-08 11:23:06.522 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-12-08 11:23:06.522 | 	metadata.log.segment.bytes = 1073741824
2025-12-08 11:23:06.522 | 	metadata.log.segment.min.bytes = 8388608
2025-12-08 11:23:06.522 | 	metadata.log.segment.ms = 604800000
2025-12-08 11:23:06.522 | 	metadata.max.idle.interval.ms = 500
2025-12-08 11:23:06.522 | 	metadata.max.retention.bytes = 104857600
2025-12-08 11:23:06.522 | 	metadata.max.retention.ms = 604800000
2025-12-08 11:23:06.522 | 	metric.reporters = []
2025-12-08 11:23:06.522 | 	metrics.num.samples = 2
2025-12-08 11:23:06.522 | 	metrics.recording.level = INFO
2025-12-08 11:23:06.522 | 	metrics.sample.window.ms = 30000
2025-12-08 11:23:06.522 | 	min.insync.replicas = 1
2025-12-08 11:23:06.522 | 	node.id = 1
2025-12-08 11:23:06.522 | 	num.io.threads = 8
2025-12-08 11:23:06.522 | 	num.network.threads = 3
2025-12-08 11:23:06.522 | 	num.partitions = 1
2025-12-08 11:23:06.522 | 	num.recovery.threads.per.data.dir = 1
2025-12-08 11:23:06.522 | 	num.replica.alter.log.dirs.threads = null
2025-12-08 11:23:06.522 | 	num.replica.fetchers = 1
2025-12-08 11:23:06.522 | 	offset.metadata.max.bytes = 4096
2025-12-08 11:23:06.522 | 	offsets.commit.required.acks = -1
2025-12-08 11:23:06.522 | 	offsets.commit.timeout.ms = 5000
2025-12-08 11:23:06.522 | 	offsets.load.buffer.size = 5242880
2025-12-08 11:23:06.522 | 	offsets.retention.check.interval.ms = 600000
2025-12-08 11:23:06.522 | 	offsets.retention.minutes = 10080
2025-12-08 11:23:06.522 | 	offsets.topic.compression.codec = 0
2025-12-08 11:23:06.522 | 	offsets.topic.num.partitions = 50
2025-12-08 11:23:06.522 | 	offsets.topic.replication.factor = 1
2025-12-08 11:23:06.522 | 	offsets.topic.segment.bytes = 104857600
2025-12-08 11:23:06.522 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-12-08 11:23:06.522 | 	password.encoder.iterations = 4096
2025-12-08 11:23:06.522 | 	password.encoder.key.length = 128
2025-12-08 11:23:06.522 | 	password.encoder.keyfactory.algorithm = null
2025-12-08 11:23:06.522 | 	password.encoder.old.secret = null
2025-12-08 11:23:06.522 | 	password.encoder.secret = null
2025-12-08 11:23:06.523 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-12-08 11:23:06.523 | 	process.roles = []
2025-12-08 11:23:06.523 | 	producer.id.expiration.check.interval.ms = 600000
2025-12-08 11:23:06.523 | 	producer.id.expiration.ms = 86400000
2025-12-08 11:23:06.523 | 	producer.purgatory.purge.interval.requests = 1000
2025-12-08 11:23:06.523 | 	queued.max.request.bytes = -1
2025-12-08 11:23:06.523 | 	queued.max.requests = 500
2025-12-08 11:23:06.523 | 	quota.window.num = 11
2025-12-08 11:23:06.523 | 	quota.window.size.seconds = 1
2025-12-08 11:23:06.523 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-12-08 11:23:06.523 | 	remote.log.manager.task.interval.ms = 30000
2025-12-08 11:23:06.523 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-12-08 11:23:06.523 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-12-08 11:23:06.523 | 	remote.log.manager.task.retry.jitter = 0.2
2025-12-08 11:23:06.523 | 	remote.log.manager.thread.pool.size = 10
2025-12-08 11:23:06.523 | 	remote.log.metadata.manager.class.name = null
2025-12-08 11:23:06.523 | 	remote.log.metadata.manager.class.path = null
2025-12-08 11:23:06.523 | 	remote.log.metadata.manager.impl.prefix = null
2025-12-08 11:23:06.523 | 	remote.log.metadata.manager.listener.name = null
2025-12-08 11:23:06.523 | 	remote.log.reader.max.pending.tasks = 100
2025-12-08 11:23:06.523 | 	remote.log.reader.threads = 10
2025-12-08 11:23:06.523 | 	remote.log.storage.manager.class.name = null
2025-12-08 11:23:06.523 | 	remote.log.storage.manager.class.path = null
2025-12-08 11:23:06.523 | 	remote.log.storage.manager.impl.prefix = null
2025-12-08 11:23:06.523 | 	remote.log.storage.system.enable = false
2025-12-08 11:23:06.523 | 	replica.fetch.backoff.ms = 1000
2025-12-08 11:23:06.523 | 	replica.fetch.max.bytes = 1048576
2025-12-08 11:23:06.523 | 	replica.fetch.min.bytes = 1
2025-12-08 11:23:06.523 | 	replica.fetch.response.max.bytes = 10485760
2025-12-08 11:23:06.523 | 	replica.fetch.wait.max.ms = 500
2025-12-08 11:23:06.523 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-12-08 11:23:06.523 | 	replica.lag.time.max.ms = 30000
2025-12-08 11:23:06.523 | 	replica.selector.class = null
2025-12-08 11:23:06.523 | 	replica.socket.receive.buffer.bytes = 65536
2025-12-08 11:23:06.523 | 	replica.socket.timeout.ms = 30000
2025-12-08 11:23:06.523 | 	replication.quota.window.num = 11
2025-12-08 11:23:06.523 | 	replication.quota.window.size.seconds = 1
2025-12-08 11:23:06.523 | 	request.timeout.ms = 30000
2025-12-08 11:23:06.523 | 	reserved.broker.max.id = 1000
2025-12-08 11:23:06.523 | 	sasl.client.callback.handler.class = null
2025-12-08 11:23:06.523 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-12-08 11:23:06.523 | 	sasl.jaas.config = null
2025-12-08 11:23:06.523 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-12-08 11:23:06.523 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-12-08 11:23:06.523 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-12-08 11:23:06.523 | 	sasl.kerberos.service.name = null
2025-12-08 11:23:06.523 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-12-08 11:23:06.523 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-12-08 11:23:06.523 | 	sasl.login.callback.handler.class = null
2025-12-08 11:23:06.523 | 	sasl.login.class = null
2025-12-08 11:23:06.523 | 	sasl.login.connect.timeout.ms = null
2025-12-08 11:23:06.523 | 	sasl.login.read.timeout.ms = null
2025-12-08 11:23:06.523 | 	sasl.login.refresh.buffer.seconds = 300
2025-12-08 11:23:06.523 | 	sasl.login.refresh.min.period.seconds = 60
2025-12-08 11:23:06.523 | 	sasl.login.refresh.window.factor = 0.8
2025-12-08 11:23:06.523 | 	sasl.login.refresh.window.jitter = 0.05
2025-12-08 11:23:06.523 | 	sasl.login.retry.backoff.max.ms = 10000
2025-12-08 11:23:06.523 | 	sasl.login.retry.backoff.ms = 100
2025-12-08 11:23:06.523 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-12-08 11:23:06.523 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.expected.audience = null
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.expected.issuer = null
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.scope.claim.name = scope
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.sub.claim.name = sub
2025-12-08 11:23:06.523 | 	sasl.oauthbearer.token.endpoint.url = null
2025-12-08 11:23:06.523 | 	sasl.server.callback.handler.class = null
2025-12-08 11:23:06.523 | 	sasl.server.max.receive.size = 524288
2025-12-08 11:23:06.523 | 	security.inter.broker.protocol = PLAINTEXT
2025-12-08 11:23:06.523 | 	security.providers = null
2025-12-08 11:23:06.523 | 	socket.connection.setup.timeout.max.ms = 30000
2025-12-08 11:23:06.523 | 	socket.connection.setup.timeout.ms = 10000
2025-12-08 11:23:06.523 | 	socket.listen.backlog.size = 50
2025-12-08 11:23:06.523 | 	socket.receive.buffer.bytes = 102400
2025-12-08 11:23:06.523 | 	socket.request.max.bytes = 104857600
2025-12-08 11:23:06.523 | 	socket.send.buffer.bytes = 102400
2025-12-08 11:23:06.523 | 	ssl.cipher.suites = []
2025-12-08 11:23:06.523 | 	ssl.client.auth = none
2025-12-08 11:23:06.523 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-12-08 11:23:06.523 | 	ssl.endpoint.identification.algorithm = https
2025-12-08 11:23:06.523 | 	ssl.engine.factory.class = null
2025-12-08 11:23:06.523 | 	ssl.key.password = null
2025-12-08 11:23:06.523 | 	ssl.keymanager.algorithm = SunX509
2025-12-08 11:23:06.523 | 	ssl.keystore.certificate.chain = null
2025-12-08 11:23:06.523 | 	ssl.keystore.key = null
2025-12-08 11:23:06.523 | 	ssl.keystore.location = null
2025-12-08 11:23:06.523 | 	ssl.keystore.password = null
2025-12-08 11:23:06.523 | 	ssl.keystore.type = JKS
2025-12-08 11:23:06.523 | 	ssl.principal.mapping.rules = DEFAULT
2025-12-08 11:23:06.523 | 	ssl.protocol = TLSv1.3
2025-12-08 11:23:06.523 | 	ssl.provider = null
2025-12-08 11:23:06.523 | 	ssl.secure.random.implementation = null
2025-12-08 11:23:06.523 | 	ssl.trustmanager.algorithm = PKIX
2025-12-08 11:23:06.523 | 	ssl.truststore.certificates = null
2025-12-08 11:23:06.523 | 	ssl.truststore.location = null
2025-12-08 11:23:06.523 | 	ssl.truststore.password = null
2025-12-08 11:23:06.523 | 	ssl.truststore.type = JKS
2025-12-08 11:23:06.523 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-12-08 11:23:06.523 | 	transaction.max.timeout.ms = 900000
2025-12-08 11:23:06.523 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-12-08 11:23:06.523 | 	transaction.state.log.load.buffer.size = 5242880
2025-12-08 11:23:06.523 | 	transaction.state.log.min.isr = 1
2025-12-08 11:23:06.523 | 	transaction.state.log.num.partitions = 50
2025-12-08 11:23:06.523 | 	transaction.state.log.replication.factor = 1
2025-12-08 11:23:06.523 | 	transaction.state.log.segment.bytes = 104857600
2025-12-08 11:23:06.523 | 	transactional.id.expiration.ms = 604800000
2025-12-08 11:23:06.523 | 	unclean.leader.election.enable = false
2025-12-08 11:23:06.523 | 	zookeeper.clientCnxnSocket = null
2025-12-08 11:23:06.523 | 	zookeeper.connect = zookeeper:2181
2025-12-08 11:23:06.523 | 	zookeeper.connection.timeout.ms = null
2025-12-08 11:23:06.523 | 	zookeeper.max.in.flight.requests = 10
2025-12-08 11:23:06.523 | 	zookeeper.metadata.migration.enable = false
2025-12-08 11:23:06.523 | 	zookeeper.session.timeout.ms = 18000
2025-12-08 11:23:06.523 | 	zookeeper.set.acl = false
2025-12-08 11:23:06.523 | 	zookeeper.ssl.cipher.suites = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.client.enable = false
2025-12-08 11:23:06.523 | 	zookeeper.ssl.crl.enable = false
2025-12-08 11:23:06.523 | 	zookeeper.ssl.enabled.protocols = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-12-08 11:23:06.523 | 	zookeeper.ssl.keystore.location = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.keystore.password = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.keystore.type = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.ocsp.enable = false
2025-12-08 11:23:06.523 | 	zookeeper.ssl.protocol = TLSv1.2
2025-12-08 11:23:06.523 | 	zookeeper.ssl.truststore.location = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.truststore.password = null
2025-12-08 11:23:06.523 | 	zookeeper.ssl.truststore.type = null
2025-12-08 11:23:06.523 |  (kafka.server.KafkaConfig)
2025-12-08 11:23:06.778 | [2025-12-08 05:53:06,760] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:23:06.781 | [2025-12-08 05:53:06,777] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:23:06.782 | [2025-12-08 05:53:06,781] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:23:06.792 | [2025-12-08 05:53:06,760] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:23:06.910 | [2025-12-08 05:53:06,910] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 11:23:06.926 | [2025-12-08 05:53:06,925] INFO Attempting recovery for all logs in /var/lib/kafka/data since no clean shutdown file was found (kafka.log.LogManager)
2025-12-08 11:23:07.054 | [2025-12-08 05:53:07,054] INFO Loaded 0 logs in 143ms. (kafka.log.LogManager)
2025-12-08 11:23:07.056 | [2025-12-08 05:53:07,055] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-12-08 11:23:07.074 | [2025-12-08 05:53:07,074] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-12-08 11:23:07.214 | [2025-12-08 05:53:07,214] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-12-08 11:23:08.635 | [2025-12-08 05:53:08,635] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
2025-12-08 11:23:08.952 | [2025-12-08 05:53:08,952] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 11:23:08.979 | [2025-12-08 05:53:08,978] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
2025-12-08 11:23:09.093 | [2025-12-08 05:53:09,092] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:23:10.780 | [2025-12-08 05:53:10,779] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-08 11:23:10.793 | [2025-12-08 05:53:10,793] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-12-08 11:23:10.941 | [2025-12-08 05:53:10,941] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-12-08 11:23:10.965 | [2025-12-08 05:53:10,965] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-08 11:23:10.967 | [2025-12-08 05:53:10,966] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-12-08 11:23:11.025 | [2025-12-08 05:53:11,024] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-12-08 11:23:11.104 | [2025-12-08 05:53:11,102] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:23:11.159 | [2025-12-08 05:53:11,159] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.178 | [2025-12-08 05:53:11,178] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.202 | [2025-12-08 05:53:11,202] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.202 | [2025-12-08 05:53:11,202] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.255 | [2025-12-08 05:53:11,252] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 11:23:11.393 | [2025-12-08 05:53:11,392] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-12-08 11:23:11.450 | [2025-12-08 05:53:11,450] INFO Stat of the created znode at /brokers/ids/1 is: 27,27,1765173191425,1765173191425,1,0,0,72058504813871105,270,0,27
2025-12-08 11:23:11.450 |  (kafka.zk.KafkaZkClient)
2025-12-08 11:23:11.453 | [2025-12-08 05:53:11,452] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 27 (kafka.zk.KafkaZkClient)
2025-12-08 11:23:11.717 | [2025-12-08 05:53:11,712] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 11:23:11.753 | [2025-12-08 05:53:11,752] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.802 | [2025-12-08 05:53:11,792] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
2025-12-08 11:23:11.839 | [2025-12-08 05:53:11,838] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.841 | [2025-12-08 05:53:11,840] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
2025-12-08 11:23:11.849 | [2025-12-08 05:53:11,848] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:11.867 | [2025-12-08 05:53:11,867] INFO [Controller id=1] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map()) (kafka.controller.KafkaController)
2025-12-08 11:23:11.884 | [2025-12-08 05:53:11,883] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:11.891 | [2025-12-08 05:53:11,890] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
2025-12-08 11:23:11.920 | [2025-12-08 05:53:11,920] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:11.958 | [2025-12-08 05:53:11,957] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 11:23:11.982 | [2025-12-08 05:53:11,982] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 11:23:11.986 | [2025-12-08 05:53:11,986] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-12-08 11:23:11.990 | [2025-12-08 05:53:11,988] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-12-08 11:23:12.007 | [2025-12-08 05:53:12,007] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-12-08 11:23:12.018 | [2025-12-08 05:53:12,017] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 11:23:12.019 | [2025-12-08 05:53:12,018] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-12-08 11:23:12.034 | [2025-12-08 05:53:12,034] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-12-08 11:23:12.149 | [2025-12-08 05:53:12,148] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 27) (kafka.controller.KafkaController)
2025-12-08 11:23:12.187 | [2025-12-08 05:53:12,186] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-08 11:23:12.213 | [2025-12-08 05:53:12,212] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:23:12.243 | [2025-12-08 05:53:12,242] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-12-08 11:23:12.310 | [2025-12-08 05:53:12,307] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-12-08 11:23:12.310 | [2025-12-08 05:53:12,308] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-12-08 11:23:12.310 | [2025-12-08 05:53:12,308] INFO [Controller id=1] Current list of topics in the cluster: HashSet() (kafka.controller.KafkaController)
2025-12-08 11:23:12.310 | [2025-12-08 05:53:12,309] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-12-08 11:23:12.336 | [2025-12-08 05:53:12,336] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-12-08 11:23:12.338 | [2025-12-08 05:53:12,338] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-12-08 11:23:12.351 | [2025-12-08 05:53:12,341] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-12-08 11:23:12.351 | [2025-12-08 05:53:12,351] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-12-08 11:23:12.354 | [2025-12-08 05:53:12,353] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 11:23:12.355 | [2025-12-08 05:53:12,355] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-12-08 11:23:12.358 | [2025-12-08 05:53:12,358] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-12-08 11:23:12.368 | [2025-12-08 05:53:12,367] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-12-08 11:23:12.398 | [2025-12-08 05:53:12,398] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-12-08 11:23:12.461 | [2025-12-08 05:53:12,461] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-12-08 11:23:12.464 | [2025-12-08 05:53:12,463] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-08 11:23:12.469 | [2025-12-08 05:53:12,469] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-12-08 11:23:12.472 | [2025-12-08 05:53:12,472] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-08 11:23:12.475 | [2025-12-08 05:53:12,474] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap() (kafka.controller.ZkReplicaStateMachine)
2025-12-08 11:23:12.479 | [2025-12-08 05:53:12,478] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-12-08 11:23:12.482 | [2025-12-08 05:53:12,482] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-12-08 11:23:12.545 | [2025-12-08 05:53:12,544] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap() (kafka.controller.ZkPartitionStateMachine)
2025-12-08 11:23:12.545 | [2025-12-08 05:53:12,544] INFO [Controller id=1] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
2025-12-08 11:23:12.606 | [2025-12-08 05:53:12,606] INFO Kafka version: 7.4.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 11:23:12.607 | [2025-12-08 05:53:12,607] INFO Kafka commitId: 30969fa33c185e880b9e02044761dfaac013151d (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 11:23:12.608 | [2025-12-08 05:53:12,608] INFO Kafka startTimeMs: 1765173192548 (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 11:23:12.629 | [2025-12-08 05:53:12,629] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-12-08 11:23:12.654 | [2025-12-08 05:53:12,654] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-12-08 11:23:12.655 | [2025-12-08 05:53:12,655] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-12-08 11:23:12.656 | [2025-12-08 05:53:12,656] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-12-08 11:23:12.657 | [2025-12-08 05:53:12,657] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-12-08 11:23:12.659 | [2025-12-08 05:53:12,659] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-12-08 11:23:12.738 | [2025-12-08 05:53:12,738] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-12-08 11:23:12.897 | [2025-12-08 05:53:12,897] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:23:12.915 | [2025-12-08 05:53:12,914] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 11:23:12.932 | [2025-12-08 05:53:12,932] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:23:15.639 | [2025-12-08 05:53:15,638] INFO Creating topic booking-email with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-12-08 11:23:15.702 | [2025-12-08 05:53:15,702] INFO [Controller id=1] New topics: [Set(booking-email)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(booking-email,Some(ZZs51CcXT3m5RospnghyvA),Map(booking-email-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-12-08 11:23:15.708 | [2025-12-08 05:53:15,708] INFO [Controller id=1] New partition creation callback for booking-email-0 (kafka.controller.KafkaController)
2025-12-08 11:23:15.713 | [2025-12-08 05:53:15,712] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 23 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 45 -> ArrayBuffer(1), 46 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 49 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2025-12-08 11:23:15.717 | [2025-12-08 05:53:15,716] INFO [Controller id=1 epoch=1] Changed partition booking-email-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.718 | [2025-12-08 05:53:15,717] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:23:15.737 | [2025-12-08 05:53:15,737] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition booking-email-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.737 | [2025-12-08 05:53:15,737] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:23:15.865 | [2025-12-08 05:53:15,865] INFO [Controller id=1 epoch=1] Changed partition booking-email-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:15.872 | [2025-12-08 05:53:15,872] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition booking-email-0 (state.change.logger)
2025-12-08 11:23:15.875 | [2025-12-08 05:53:15,874] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
2025-12-08 11:23:15.882 | [2025-12-08 05:53:15,882] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
2025-12-08 11:23:15.884 | [2025-12-08 05:53:15,884] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition booking-email-0 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:15.885 | [2025-12-08 05:53:15,884] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:23:15.899 | [2025-12-08 05:53:15,898] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 1 partitions (state.change.logger)
2025-12-08 11:23:15.899 | [2025-12-08 05:53:15,899] INFO [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(s1of94BtTGS8K-UMhA2LCA),HashMap(__consumer_offsets-22 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-30 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-25 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-35 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-37 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-38 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-13 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-8 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-21 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-27 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-9 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-46 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-41 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-33 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-23 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-49 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-47 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-16 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-28 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-31 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-36 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-42 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-18 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-15 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-24 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-17 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-48 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-19 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-11 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-43 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-6 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-14 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-20 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-44 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-39 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-12 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-45 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-5 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-26 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-29 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-34 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-32 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-40 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
2025-12-08 11:23:15.901 | [2025-12-08 05:53:15,901] INFO [Controller id=1] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-37,__consumer_offsets-38,__consumer_offsets-13,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.controller.KafkaController)
2025-12-08 11:23:15.902 | [2025-12-08 05:53:15,902] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.902 | [2025-12-08 05:53:15,902] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.903 | [2025-12-08 05:53:15,903] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.903 | [2025-12-08 05:53:15,903] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.903 | [2025-12-08 05:53:15,903] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.904 | [2025-12-08 05:53:15,903] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.904 | [2025-12-08 05:53:15,903] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:15.907 | [2025-12-08 05:53:15,904] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.909 | [2025-12-08 05:53:15,908] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.911 | [2025-12-08 05:53:15,911] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.911 | [2025-12-08 05:53:15,911] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.911 | [2025-12-08 05:53:15,911] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.911 | [2025-12-08 05:53:15,911] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.912 | [2025-12-08 05:53:15,911] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.912 | [2025-12-08 05:53:15,912] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.912 | [2025-12-08 05:53:15,912] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.912 | [2025-12-08 05:53:15,912] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.912 | [2025-12-08 05:53:15,912] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.913 | [2025-12-08 05:53:15,913] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.914 | [2025-12-08 05:53:15,914] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.914 | [2025-12-08 05:53:15,914] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.914 | [2025-12-08 05:53:15,914] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.915 | [2025-12-08 05:53:15,914] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.915 | [2025-12-08 05:53:15,915] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.921 | [2025-12-08 05:53:15,915] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.922 | [2025-12-08 05:53:15,921] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.922 | [2025-12-08 05:53:15,922] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.922 | [2025-12-08 05:53:15,922] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.923 | [2025-12-08 05:53:15,922] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.923 | [2025-12-08 05:53:15,923] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.923 | [2025-12-08 05:53:15,923] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.923 | [2025-12-08 05:53:15,923] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.924 | [2025-12-08 05:53:15,923] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.924 | [2025-12-08 05:53:15,924] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.924 | [2025-12-08 05:53:15,924] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.924 | [2025-12-08 05:53:15,924] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.925 | [2025-12-08 05:53:15,924] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.925 | [2025-12-08 05:53:15,925] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.925 | [2025-12-08 05:53:15,925] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.925 | [2025-12-08 05:53:15,925] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.926 | [2025-12-08 05:53:15,925] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.926 | [2025-12-08 05:53:15,925] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.926 | [2025-12-08 05:53:15,926] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.926 | [2025-12-08 05:53:15,926] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.927 | [2025-12-08 05:53:15,926] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.927 | [2025-12-08 05:53:15,927] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.927 | [2025-12-08 05:53:15,927] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.927 | [2025-12-08 05:53:15,927] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.927 | [2025-12-08 05:53:15,927] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.927 | [2025-12-08 05:53:15,927] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.928 | [2025-12-08 05:53:15,927] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
2025-12-08 11:23:15.928 | [2025-12-08 05:53:15,928] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:23:15.931 | [2025-12-08 05:53:15,930] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.932 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.932 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.932 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.932 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.932 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,932] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.933 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.934 | [2025-12-08 05:53:15,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,934] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.935 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.936 | [2025-12-08 05:53:15,935] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.936 | [2025-12-08 05:53:15,936] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.936 | [2025-12-08 05:53:15,936] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.937 | [2025-12-08 05:53:15,936] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.937 | [2025-12-08 05:53:15,936] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.937 | [2025-12-08 05:53:15,936] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,937] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.938 | [2025-12-08 05:53:15,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
2025-12-08 11:23:15.939 | [2025-12-08 05:53:15,939] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:23:15.978 | [2025-12-08 05:53:15,978] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-08 11:23:15.982 | [2025-12-08 05:53:15,981] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(booking-email-0) (kafka.server.ReplicaFetcherManager)
2025-12-08 11:23:15.983 | [2025-12-08 05:53:15,983] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 1 as part of the become-leader transition for 1 partitions (state.change.logger)
2025-12-08 11:23:16.175 | [2025-12-08 05:53:16,173] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.209 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.210 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.210 | [2025-12-08 05:53:16,209] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.210 | [2025-12-08 05:53:16,210] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.210 | [2025-12-08 05:53:16,210] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.210 | [2025-12-08 05:53:16,210] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.210 | [2025-12-08 05:53:16,210] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.213 | [2025-12-08 05:53:16,212] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.213 | [2025-12-08 05:53:16,213] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.214 | [2025-12-08 05:53:16,213] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.214 | [2025-12-08 05:53:16,214] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.214 | [2025-12-08 05:53:16,214] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.214 | [2025-12-08 05:53:16,214] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.215 | [2025-12-08 05:53:16,214] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.216 | [2025-12-08 05:53:16,215] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.216 | [2025-12-08 05:53:16,216] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.216 | [2025-12-08 05:53:16,216] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.216 | [2025-12-08 05:53:16,216] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,216] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,216] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.217 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,217] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.218 | [2025-12-08 05:53:16,218] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,218] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,219] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 11:23:16.224 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,220] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,221] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,223] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,223] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,223] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,223] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 50 become-leader and 0 become-follower partitions (state.change.logger)
2025-12-08 11:23:16.225 | [2025-12-08 05:53:16,224] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 50 partitions (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,226] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,226] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,226] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,226] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.227 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,227] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.228 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.229 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.230 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.230 | [2025-12-08 05:53:16,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.230 | [2025-12-08 05:53:16,230] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.230 | [2025-12-08 05:53:16,230] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.230 | [2025-12-08 05:53:16,230] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.231 | [2025-12-08 05:53:16,231] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.231 | [2025-12-08 05:53:16,231] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.231 | [2025-12-08 05:53:16,231] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.231 | [2025-12-08 05:53:16,231] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
2025-12-08 11:23:16.233 | [2025-12-08 05:53:16,232] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:23:16.233 | [2025-12-08 05:53:16,232] INFO Created log for partition booking-email-0 in /var/lib/kafka/data/booking-email-0 with properties {} (kafka.log.LogManager)
2025-12-08 11:23:16.236 | [2025-12-08 05:53:16,236] INFO [Partition booking-email-0 broker=1] No checkpointed highwatermark is found for partition booking-email-0 (kafka.cluster.Partition)
2025-12-08 11:23:16.239 | [2025-12-08 05:53:16,239] INFO [Partition booking-email-0 broker=1] Log loaded for partition booking-email-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.245 | [2025-12-08 05:53:16,245] INFO [Broker id=1] Leader booking-email-0 with topic id Some(ZZs51CcXT3m5RospnghyvA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.308 | [2025-12-08 05:53:16,308] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-08 11:23:16.319 | [2025-12-08 05:53:16,319] INFO [Broker id=1] Finished LeaderAndIsr request in 428ms correlationId 1 from controller 1 for 1 partitions (state.change.logger)
2025-12-08 11:23:16.327 | [2025-12-08 05:53:16,327] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=ZZs51CcXT3m5RospnghyvA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 11:23:16.338 | [2025-12-08 05:53:16,337] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition booking-email-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-12-08 11:23:16.343 | [2025-12-08 05:53:16,342] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
2025-12-08 11:23:16.345 | [2025-12-08 05:53:16,344] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,349] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 for 50 partitions (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.350 | [2025-12-08 05:53:16,350] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.351 | [2025-12-08 05:53:16,351] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.352 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.353 | [2025-12-08 05:53:16,352] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.353 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.353 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.353 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.353 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.353 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,353] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.354 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.355 | [2025-12-08 05:53:16,354] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.355 | [2025-12-08 05:53:16,355] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.355 | [2025-12-08 05:53:16,355] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.355 | [2025-12-08 05:53:16,355] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.355 | [2025-12-08 05:53:16,355] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.356 | [2025-12-08 05:53:16,355] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,395] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 11:23:16.396 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,396] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 11:23:16.397 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,397] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 11:23:16.398 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 11:23:16.399 | [2025-12-08 05:53:16,398] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 11:23:16.400 | [2025-12-08 05:53:16,399] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 11:23:16.400 | [2025-12-08 05:53:16,400] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 11:23:16.402 | [2025-12-08 05:53:16,401] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-12-08 11:23:16.402 | [2025-12-08 05:53:16,402] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 1 epoch 1 as part of the become-leader transition for 50 partitions (state.change.logger)
2025-12-08 11:23:16.416 | [2025-12-08 05:53:16,415] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.418 | [2025-12-08 05:53:16,418] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.420 | [2025-12-08 05:53:16,420] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
2025-12-08 11:23:16.420 | [2025-12-08 05:53:16,420] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.421 | [2025-12-08 05:53:16,420] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.438 | [2025-12-08 05:53:16,438] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.439 | [2025-12-08 05:53:16,439] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.439 | [2025-12-08 05:53:16,439] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
2025-12-08 11:23:16.439 | [2025-12-08 05:53:16,439] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.440 | [2025-12-08 05:53:16,439] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.469 | [2025-12-08 05:53:16,469] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.471 | [2025-12-08 05:53:16,470] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.471 | [2025-12-08 05:53:16,471] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
2025-12-08 11:23:16.471 | [2025-12-08 05:53:16,471] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.471 | [2025-12-08 05:53:16,471] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.486 | [2025-12-08 05:53:16,486] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.488 | [2025-12-08 05:53:16,487] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.488 | [2025-12-08 05:53:16,488] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
2025-12-08 11:23:16.488 | [2025-12-08 05:53:16,488] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.488 | [2025-12-08 05:53:16,488] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.510 | [2025-12-08 05:53:16,510] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.513 | [2025-12-08 05:53:16,512] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.513 | [2025-12-08 05:53:16,513] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
2025-12-08 11:23:16.513 | [2025-12-08 05:53:16,513] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.513 | [2025-12-08 05:53:16,513] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.572 | [2025-12-08 05:53:16,572] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.574 | [2025-12-08 05:53:16,573] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.574 | [2025-12-08 05:53:16,574] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
2025-12-08 11:23:16.574 | [2025-12-08 05:53:16,574] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.574 | [2025-12-08 05:53:16,574] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.597 | [2025-12-08 05:53:16,597] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.599 | [2025-12-08 05:53:16,598] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.599 | [2025-12-08 05:53:16,598] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
2025-12-08 11:23:16.599 | [2025-12-08 05:53:16,599] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.599 | [2025-12-08 05:53:16,599] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.614 | [2025-12-08 05:53:16,613] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.615 | [2025-12-08 05:53:16,615] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.615 | [2025-12-08 05:53:16,615] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
2025-12-08 11:23:16.616 | [2025-12-08 05:53:16,615] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.616 | [2025-12-08 05:53:16,616] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.636 | [2025-12-08 05:53:16,636] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.638 | [2025-12-08 05:53:16,637] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.638 | [2025-12-08 05:53:16,637] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
2025-12-08 11:23:16.638 | [2025-12-08 05:53:16,638] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.638 | [2025-12-08 05:53:16,638] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.657 | [2025-12-08 05:53:16,656] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.658 | [2025-12-08 05:53:16,658] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.658 | [2025-12-08 05:53:16,658] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
2025-12-08 11:23:16.658 | [2025-12-08 05:53:16,658] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.658 | [2025-12-08 05:53:16,658] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.683 | [2025-12-08 05:53:16,683] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.685 | [2025-12-08 05:53:16,684] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.685 | [2025-12-08 05:53:16,685] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
2025-12-08 11:23:16.685 | [2025-12-08 05:53:16,685] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.686 | [2025-12-08 05:53:16,686] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.731 | [2025-12-08 05:53:16,731] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.732 | [2025-12-08 05:53:16,732] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.733 | [2025-12-08 05:53:16,732] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
2025-12-08 11:23:16.733 | [2025-12-08 05:53:16,732] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.733 | [2025-12-08 05:53:16,732] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.749 | [2025-12-08 05:53:16,748] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.750 | [2025-12-08 05:53:16,750] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.750 | [2025-12-08 05:53:16,750] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
2025-12-08 11:23:16.750 | [2025-12-08 05:53:16,750] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.751 | [2025-12-08 05:53:16,750] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.767 | [2025-12-08 05:53:16,766] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.768 | [2025-12-08 05:53:16,768] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.768 | [2025-12-08 05:53:16,768] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
2025-12-08 11:23:16.768 | [2025-12-08 05:53:16,768] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.768 | [2025-12-08 05:53:16,768] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.794 | [2025-12-08 05:53:16,793] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.795 | [2025-12-08 05:53:16,795] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.795 | [2025-12-08 05:53:16,795] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
2025-12-08 11:23:16.795 | [2025-12-08 05:53:16,795] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.796 | [2025-12-08 05:53:16,795] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.817 | [2025-12-08 05:53:16,816] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.818 | [2025-12-08 05:53:16,818] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.818 | [2025-12-08 05:53:16,818] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
2025-12-08 11:23:16.818 | [2025-12-08 05:53:16,818] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.818 | [2025-12-08 05:53:16,818] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.858 | [2025-12-08 05:53:16,857] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.859 | [2025-12-08 05:53:16,859] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.859 | [2025-12-08 05:53:16,859] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
2025-12-08 11:23:16.859 | [2025-12-08 05:53:16,859] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.860 | [2025-12-08 05:53:16,860] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.881 | [2025-12-08 05:53:16,880] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.882 | [2025-12-08 05:53:16,882] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.882 | [2025-12-08 05:53:16,882] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
2025-12-08 11:23:16.882 | [2025-12-08 05:53:16,882] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.882 | [2025-12-08 05:53:16,882] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.907 | [2025-12-08 05:53:16,907] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.908 | [2025-12-08 05:53:16,908] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.908 | [2025-12-08 05:53:16,908] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
2025-12-08 11:23:16.908 | [2025-12-08 05:53:16,908] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.909 | [2025-12-08 05:53:16,908] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.929 | [2025-12-08 05:53:16,928] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.930 | [2025-12-08 05:53:16,930] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.930 | [2025-12-08 05:53:16,930] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
2025-12-08 11:23:16.930 | [2025-12-08 05:53:16,930] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.930 | [2025-12-08 05:53:16,930] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.950 | [2025-12-08 05:53:16,949] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.951 | [2025-12-08 05:53:16,951] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.951 | [2025-12-08 05:53:16,951] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
2025-12-08 11:23:16.951 | [2025-12-08 05:53:16,951] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.952 | [2025-12-08 05:53:16,952] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:16.974 | [2025-12-08 05:53:16,974] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:16.976 | [2025-12-08 05:53:16,975] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:16.976 | [2025-12-08 05:53:16,976] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
2025-12-08 11:23:16.976 | [2025-12-08 05:53:16,976] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:16.976 | [2025-12-08 05:53:16,976] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.030 | [2025-12-08 05:53:17,028] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.031 | [2025-12-08 05:53:17,031] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.031 | [2025-12-08 05:53:17,031] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
2025-12-08 11:23:17.031 | [2025-12-08 05:53:17,031] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.031 | [2025-12-08 05:53:17,031] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.058 | [2025-12-08 05:53:17,057] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.059 | [2025-12-08 05:53:17,059] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.059 | [2025-12-08 05:53:17,059] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
2025-12-08 11:23:17.059 | [2025-12-08 05:53:17,059] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.059 | [2025-12-08 05:53:17,059] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.083 | [2025-12-08 05:53:17,083] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.085 | [2025-12-08 05:53:17,085] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.085 | [2025-12-08 05:53:17,085] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
2025-12-08 11:23:17.086 | [2025-12-08 05:53:17,085] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.086 | [2025-12-08 05:53:17,086] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.101 | [2025-12-08 05:53:17,101] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.102 | [2025-12-08 05:53:17,102] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.102 | [2025-12-08 05:53:17,102] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
2025-12-08 11:23:17.102 | [2025-12-08 05:53:17,102] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.102 | [2025-12-08 05:53:17,102] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.127 | [2025-12-08 05:53:17,126] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.128 | [2025-12-08 05:53:17,128] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.128 | [2025-12-08 05:53:17,128] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
2025-12-08 11:23:17.128 | [2025-12-08 05:53:17,128] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.128 | [2025-12-08 05:53:17,128] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.150 | [2025-12-08 05:53:17,149] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.151 | [2025-12-08 05:53:17,151] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.151 | [2025-12-08 05:53:17,151] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
2025-12-08 11:23:17.151 | [2025-12-08 05:53:17,151] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.151 | [2025-12-08 05:53:17,151] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.189 | [2025-12-08 05:53:17,189] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.190 | [2025-12-08 05:53:17,190] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.191 | [2025-12-08 05:53:17,190] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
2025-12-08 11:23:17.191 | [2025-12-08 05:53:17,190] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.191 | [2025-12-08 05:53:17,190] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.207 | [2025-12-08 05:53:17,206] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.208 | [2025-12-08 05:53:17,208] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.208 | [2025-12-08 05:53:17,208] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
2025-12-08 11:23:17.208 | [2025-12-08 05:53:17,208] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.208 | [2025-12-08 05:53:17,208] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.227 | [2025-12-08 05:53:17,227] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.228 | [2025-12-08 05:53:17,228] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.228 | [2025-12-08 05:53:17,228] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
2025-12-08 11:23:17.228 | [2025-12-08 05:53:17,228] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.228 | [2025-12-08 05:53:17,228] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.252 | [2025-12-08 05:53:17,252] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.253 | [2025-12-08 05:53:17,253] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.253 | [2025-12-08 05:53:17,253] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
2025-12-08 11:23:17.253 | [2025-12-08 05:53:17,253] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.254 | [2025-12-08 05:53:17,254] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.315 | [2025-12-08 05:53:17,315] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.317 | [2025-12-08 05:53:17,317] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.318 | [2025-12-08 05:53:17,317] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
2025-12-08 11:23:17.318 | [2025-12-08 05:53:17,318] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.318 | [2025-12-08 05:53:17,318] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.334 | [2025-12-08 05:53:17,334] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.336 | [2025-12-08 05:53:17,336] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.336 | [2025-12-08 05:53:17,336] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
2025-12-08 11:23:17.336 | [2025-12-08 05:53:17,336] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.336 | [2025-12-08 05:53:17,336] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.362 | [2025-12-08 05:53:17,362] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.363 | [2025-12-08 05:53:17,363] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.363 | [2025-12-08 05:53:17,363] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
2025-12-08 11:23:17.363 | [2025-12-08 05:53:17,363] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.364 | [2025-12-08 05:53:17,363] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.385 | [2025-12-08 05:53:17,385] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.390 | [2025-12-08 05:53:17,387] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.390 | [2025-12-08 05:53:17,387] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
2025-12-08 11:23:17.390 | [2025-12-08 05:53:17,387] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.390 | [2025-12-08 05:53:17,388] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.406 | [2025-12-08 05:53:17,404] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.407 | [2025-12-08 05:53:17,407] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.407 | [2025-12-08 05:53:17,407] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
2025-12-08 11:23:17.407 | [2025-12-08 05:53:17,407] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.407 | [2025-12-08 05:53:17,407] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.465 | [2025-12-08 05:53:17,465] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.466 | [2025-12-08 05:53:17,466] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.466 | [2025-12-08 05:53:17,466] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
2025-12-08 11:23:17.466 | [2025-12-08 05:53:17,466] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.467 | [2025-12-08 05:53:17,466] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.481 | [2025-12-08 05:53:17,480] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.482 | [2025-12-08 05:53:17,482] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.482 | [2025-12-08 05:53:17,482] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
2025-12-08 11:23:17.482 | [2025-12-08 05:53:17,482] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.482 | [2025-12-08 05:53:17,482] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.506 | [2025-12-08 05:53:17,505] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.506 | [2025-12-08 05:53:17,506] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.506 | [2025-12-08 05:53:17,506] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
2025-12-08 11:23:17.507 | [2025-12-08 05:53:17,507] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.507 | [2025-12-08 05:53:17,507] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.530 | [2025-12-08 05:53:17,529] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.531 | [2025-12-08 05:53:17,531] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.531 | [2025-12-08 05:53:17,531] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
2025-12-08 11:23:17.531 | [2025-12-08 05:53:17,531] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.531 | [2025-12-08 05:53:17,531] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.590 | [2025-12-08 05:53:17,590] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.591 | [2025-12-08 05:53:17,591] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.591 | [2025-12-08 05:53:17,591] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
2025-12-08 11:23:17.591 | [2025-12-08 05:53:17,591] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.592 | [2025-12-08 05:53:17,592] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.613 | [2025-12-08 05:53:17,613] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.614 | [2025-12-08 05:53:17,613] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.614 | [2025-12-08 05:53:17,614] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
2025-12-08 11:23:17.614 | [2025-12-08 05:53:17,614] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.614 | [2025-12-08 05:53:17,614] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.628 | [2025-12-08 05:53:17,627] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.629 | [2025-12-08 05:53:17,628] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.629 | [2025-12-08 05:53:17,629] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
2025-12-08 11:23:17.629 | [2025-12-08 05:53:17,629] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.629 | [2025-12-08 05:53:17,629] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.672 | [2025-12-08 05:53:17,672] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.673 | [2025-12-08 05:53:17,673] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.674 | [2025-12-08 05:53:17,673] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
2025-12-08 11:23:17.674 | [2025-12-08 05:53:17,673] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.674 | [2025-12-08 05:53:17,673] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.686 | [2025-12-08 05:53:17,685] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.687 | [2025-12-08 05:53:17,686] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.687 | [2025-12-08 05:53:17,686] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
2025-12-08 11:23:17.687 | [2025-12-08 05:53:17,687] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.687 | [2025-12-08 05:53:17,687] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.700 | [2025-12-08 05:53:17,700] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.701 | [2025-12-08 05:53:17,701] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.701 | [2025-12-08 05:53:17,701] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
2025-12-08 11:23:17.701 | [2025-12-08 05:53:17,701] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.701 | [2025-12-08 05:53:17,701] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.717 | [2025-12-08 05:53:17,717] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.718 | [2025-12-08 05:53:17,718] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.718 | [2025-12-08 05:53:17,718] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
2025-12-08 11:23:17.718 | [2025-12-08 05:53:17,718] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.718 | [2025-12-08 05:53:17,718] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.741 | [2025-12-08 05:53:17,741] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 11:23:17.742 | [2025-12-08 05:53:17,742] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 11:23:17.743 | [2025-12-08 05:53:17,742] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.744 | [2025-12-08 05:53:17,743] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.744 | [2025-12-08 05:53:17,743] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
2025-12-08 11:23:17.744 | [2025-12-08 05:53:17,743] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.744 | [2025-12-08 05:53:17,744] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.748 | [2025-12-08 05:53:17,748] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 11:23:17.749 | [2025-12-08 05:53:17,749] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 11:23:17.797 | [2025-12-08 05:53:17,796] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 11:23:17.797 | [2025-12-08 05:53:17,797] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
2025-12-08 11:23:17.798 | [2025-12-08 05:53:17,797] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
2025-12-08 11:23:17.798 | [2025-12-08 05:53:17,797] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 11:23:17.798 | [2025-12-08 05:53:17,798] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 11:23:17.807 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,807] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 11:23:17.808 | [2025-12-08 05:53:17,808] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 11:23:17.811 | [2025-12-08 05:53:17,810] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.812 | [2025-12-08 05:53:17,812] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.814 | [2025-12-08 05:53:17,814] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.815 | [2025-12-08 05:53:17,815] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.816 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,816] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,816] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:17.817 | [2025-12-08 05:53:17,817] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.818 | [2025-12-08 05:53:17,818] INFO [Broker id=1] Finished LeaderAndIsr request in 1468ms correlationId 3 from controller 1 for 50 partitions (state.change.logger)
2025-12-08 11:23:17.820 | [2025-12-08 05:53:17,820] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=s1of94BtTGS8K-UMhA2LCA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 3 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 11:23:17.822 | [2025-12-08 05:53:17,822] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 8 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.823 | [2025-12-08 05:53:17,823] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.823 | [2025-12-08 05:53:17,823] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.823 | [2025-12-08 05:53:17,823] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,823] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,824] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,824] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,824] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,824] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,824] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.824 | [2025-12-08 05:53:17,824] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,824] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,824] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,824] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.825 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,825] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.826 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,826] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.827 | [2025-12-08 05:53:17,827] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.828 | [2025-12-08 05:53:17,827] INFO [Broker id=1] Add 50 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
2025-12-08 11:23:17.828 | [2025-12-08 05:53:17,828] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.829 | [2025-12-08 05:53:17,828] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.829 | [2025-12-08 05:53:17,828] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 4 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 11:23:17.829 | [2025-12-08 05:53:17,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.829 | [2025-12-08 05:53:17,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.829 | [2025-12-08 05:53:17,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.830 | [2025-12-08 05:53:17,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.830 | [2025-12-08 05:53:17,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.830 | [2025-12-08 05:53:17,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.830 | [2025-12-08 05:53:17,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.831 | [2025-12-08 05:53:17,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.831 | [2025-12-08 05:53:17,831] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 16 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.831 | [2025-12-08 05:53:17,831] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.831 | [2025-12-08 05:53:17,831] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.831 | [2025-12-08 05:53:17,831] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.832 | [2025-12-08 05:53:17,831] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.832 | [2025-12-08 05:53:17,832] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 16 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.833 | [2025-12-08 05:53:17,833] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.833 | [2025-12-08 05:53:17,833] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.834 | [2025-12-08 05:53:17,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.834 | [2025-12-08 05:53:17,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.834 | [2025-12-08 05:53:17,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.834 | [2025-12-08 05:53:17,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.834 | [2025-12-08 05:53:17,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.835 | [2025-12-08 05:53:17,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.835 | [2025-12-08 05:53:17,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.835 | [2025-12-08 05:53:17,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.835 | [2025-12-08 05:53:17,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.835 | [2025-12-08 05:53:17,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 18 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.836 | [2025-12-08 05:53:17,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.837 | [2025-12-08 05:53:17,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 19 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.837 | [2025-12-08 05:53:17,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.837 | [2025-12-08 05:53:17,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.837 | [2025-12-08 05:53:17,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:17.837 | [2025-12-08 05:53:17,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 20 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 11:23:18.277 | [2025-12-08 05:53:18,277] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Empty state. Created a new member id consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:18.297 | [2025-12-08 05:53:18,296] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:21.308 | [2025-12-08 05:53:21,308] INFO [GroupCoordinator 1]: Stabilized group email-group generation 1 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:23:21.334 | [2025-12-08 05:53:21,334] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd for group email-group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:28:17.704 | [2025-12-08 05:58:17,703] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 11:28:17.704 | [2025-12-08 05:58:17,703] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 11:28:17.708 | [2025-12-08 05:58:17,708] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 11:28:17.708 | [2025-12-08 05:58:17,708] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 11:33:17.665 | [2025-12-08 06:03:17,664] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 11:33:17.665 | [2025-12-08 06:03:17,665] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 11:33:17.667 | [2025-12-08 06:03:17,667] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 11:33:17.667 | [2025-12-08 06:03:17,667] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 11:38:17.629 | [2025-12-08 06:08:17,628] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 11:38:17.629 | [2025-12-08 06:08:17,628] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 11:38:17.631 | [2025-12-08 06:08:17,631] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 11:38:17.631 | [2025-12-08 06:08:17,631] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 11:40:38.627 | [2025-12-08 06:10:38,626] DEBUG [Controller id=1] There is no producerId block yet (Zk path version 0), creating the first block (kafka.controller.KafkaController)
2025-12-08 11:40:38.658 | [2025-12-08 06:10:38,658] INFO [Controller id=1] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=1, firstProducerId=0, size=1000) by writing to Zk with path version 1 (kafka.controller.KafkaController)
2025-12-08 11:43:17.601 | [2025-12-08 06:13:17,601] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 11:43:17.601 | [2025-12-08 06:13:17,601] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 11:43:17.603 | [2025-12-08 06:13:17,603] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 11:43:17.603 | [2025-12-08 06:13:17,603] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 11:48:17.584 | [2025-12-08 06:18:17,576] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 11:48:17.584 | [2025-12-08 06:18:17,583] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 11:48:17.585 | [2025-12-08 06:18:17,585] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 11:48:17.585 | [2025-12-08 06:18:17,585] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 11:48:41.032 | [2025-12-08 06:18:41,032] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: Removing member consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:48:41.035 | [2025-12-08 06:18:41,034] INFO [GroupCoordinator 1]: Group email-group with generation 2 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:48:41.049 | [2025-12-08 06:18:41,049] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:48:45.765 | [2025-12-08 06:18:45,764] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-08 11:48:45.771 | [2025-12-08 06:18:45,770] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-12-08 11:48:45.771 | [2025-12-08 06:18:45,771] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-12-08 11:48:45.790 | [2025-12-08 06:18:45,790] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-12-08 11:48:45.790 | [2025-12-08 06:18:45,790] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-12-08 11:48:45.792 | [2025-12-08 06:18:45,792] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-12-08 11:48:45.796 | [2025-12-08 06:18:45,796] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 11:48:45.802 | [2025-12-08 06:18:45,801] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),booking-email-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-12-08 11:48:45.805 | [2025-12-08 06:18:45,804] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
2025-12-08 11:48:45.810 | [2025-12-08 06:18:45,809] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 11:48:45.813 | [2025-12-08 06:18:45,812] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 11:48:45.814 | [2025-12-08 06:18:45,812] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 11:48:45.815 | [2025-12-08 06:18:45,815] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-12-08 11:48:45.824 | [2025-12-08 06:18:45,823] INFO [BrokerToControllerChannelManager broker=1 name=forwarding] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-12-08 11:48:45.834 | [2025-12-08 06:18:45,834] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-12-08 11:48:45.836 | [2025-12-08 06:18:45,836] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-12-08 11:48:45.838 | [2025-12-08 06:18:45,838] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-12-08 11:48:45.843 | [2025-12-08 06:18:45,842] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.846 | [2025-12-08 06:18:45,846] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.846 | [2025-12-08 06:18:45,846] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.847 | [2025-12-08 06:18:45,847] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-12-08 11:48:45.849 | [2025-12-08 06:18:45,848] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.850 | [2025-12-08 06:18:45,850] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.850 | [2025-12-08 06:18:45,850] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.852 | [2025-12-08 06:18:45,852] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 11:48:45.854 | [2025-12-08 06:18:45,853] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-12-08 11:48:45.854 | [2025-12-08 06:18:45,853] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 11:48:45.854 | [2025-12-08 06:18:45,854] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 11:48:45.855 | [2025-12-08 06:18:45,854] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 11:48:45.855 | [2025-12-08 06:18:45,855] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 11:48:45.856 | [2025-12-08 06:18:45,856] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:48:45.856 | [2025-12-08 06:18:45,856] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.857 | [2025-12-08 06:18:45,857] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.857 | [2025-12-08 06:18:45,857] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.858 | [2025-12-08 06:18:45,858] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.859 | [2025-12-08 06:18:45,858] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.859 | [2025-12-08 06:18:45,858] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.859 | [2025-12-08 06:18:45,859] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 11:48:45.861 | [2025-12-08 06:18:45,860] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-12-08 11:48:45.861 | [2025-12-08 06:18:45,861] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 11:48:45.863 | [2025-12-08 06:18:45,863] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 11:48:45.864 | [2025-12-08 06:18:45,863] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 11:48:45.864 | [2025-12-08 06:18:45,864] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-12-08 11:48:45.865 | [2025-12-08 06:18:45,865] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-12-08 11:48:45.866 | [2025-12-08 06:18:45,865] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-12-08 11:48:45.866 | [2025-12-08 06:18:45,866] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-12-08 11:48:45.866 | [2025-12-08 06:18:45,866] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.866 | [2025-12-08 06:18:45,866] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.866 | [2025-12-08 06:18:45,866] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.867 | [2025-12-08 06:18:45,866] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.868 | [2025-12-08 06:18:45,868] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.868 | [2025-12-08 06:18:45,868] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.868 | [2025-12-08 06:18:45,868] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.869 | [2025-12-08 06:18:45,869] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.869 | [2025-12-08 06:18:45,869] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.870 | [2025-12-08 06:18:45,869] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.871 | [2025-12-08 06:18:45,871] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.871 | [2025-12-08 06:18:45,871] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 11:48:45.878 | [2025-12-08 06:18:45,878] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-12-08 11:48:45.879 | [2025-12-08 06:18:45,878] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:48:45.879 | [2025-12-08 06:18:45,879] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:48:45.879 | [2025-12-08 06:18:45,879] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:48:45.881 | [2025-12-08 06:18:45,881] INFO Broker to controller channel manager for alterPartition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-12-08 11:48:45.881 | [2025-12-08 06:18:45,881] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:48:45.881 | [2025-12-08 06:18:45,881] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:48:45.882 | [2025-12-08 06:18:45,881] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-12-08 11:48:45.882 | [2025-12-08 06:18:45,882] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-12-08 11:48:45.883 | [2025-12-08 06:18:45,882] INFO Shutting down. (kafka.log.LogManager)
2025-12-08 11:48:45.884 | [2025-12-08 06:18:45,883] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-12-08 11:48:45.884 | [2025-12-08 06:18:45,884] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner)
2025-12-08 11:48:45.885 | [2025-12-08 06:18:45,884] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner)
2025-12-08 11:48:45.885 | [2025-12-08 06:18:45,884] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner)
2025-12-08 11:48:45.969 | [2025-12-08 06:18:45,969] INFO [ProducerStateManager partition=booking-email-0] Wrote producer snapshot at offset 1 with 1 producer ids in 4 ms. (kafka.log.ProducerStateManager)
2025-12-08 11:48:45.987 | [2025-12-08 06:18:45,987] INFO [ProducerStateManager partition=__consumer_offsets-8] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
2025-12-08 11:48:46.153 | [2025-12-08 06:18:46,153] INFO Shutdown complete. (kafka.log.LogManager)
2025-12-08 11:48:46.153 | [2025-12-08 06:18:46,153] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 11:48:46.154 | [2025-12-08 06:18:46,154] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 11:48:46.154 | [2025-12-08 06:18:46,154] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 11:48:46.155 | [2025-12-08 06:18:46,155] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-12-08 11:48:46.156 | [2025-12-08 06:18:46,155] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-08 11:48:46.157 | [2025-12-08 06:18:46,157] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-12-08 11:48:46.159 | [2025-12-08 06:18:46,159] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-12-08 11:48:46.160 | [2025-12-08 06:18:46,160] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-12-08 11:48:46.161 | [2025-12-08 06:18:46,161] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-12-08 11:48:46.162 | [2025-12-08 06:18:46,161] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-12-08 11:48:46.164 | [2025-12-08 06:18:46,164] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-12-08 11:48:46.165 | [2025-12-08 06:18:46,165] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 11:48:46.166 | [2025-12-08 06:18:46,166] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 11:48:46.166 | [2025-12-08 06:18:46,166] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 11:48:46.167 | [2025-12-08 06:18:46,167] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 11:48:46.280 | [2025-12-08 06:18:46,280] INFO Session: 0x10000d40e7a0001 closed (org.apache.zookeeper.ZooKeeper)
2025-12-08 11:48:46.280 | [2025-12-08 06:18:46,280] INFO EventThread shut down for session: 0x10000d40e7a0001 (org.apache.zookeeper.ClientCnxn)
2025-12-08 11:48:46.282 | [2025-12-08 06:18:46,282] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 11:48:46.283 | [2025-12-08 06:18:46,282] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.286 | [2025-12-08 06:18:46,286] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.286 | [2025-12-08 06:18:46,286] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.286 | [2025-12-08 06:18:46,286] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.287 | [2025-12-08 06:18:46,287] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 11:48:46.290 | [2025-12-08 06:18:46,289] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-12-08 11:48:46.328 | [2025-12-08 06:18:46,327] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-12-08 11:48:46.330 | [2025-12-08 06:18:46,330] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-12-08 11:48:46.330 | [2025-12-08 06:18:46,330] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-12-08 11:48:46.330 | [2025-12-08 06:18:46,330] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-12-08 11:48:46.333 | [2025-12-08 06:18:46,332] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-12-08 11:48:46.334 | [2025-12-08 06:18:46,334] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 11:48:46.335 | [2025-12-08 06:18:46,334] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-12-08 18:06:05.059 | ===> User
2025-12-08 18:06:05.068 | uid=0(root) gid=0(root) groups=0(root)
2025-12-08 18:06:05.069 | ===> Configuring ...
2025-12-08 18:06:05.078 | Running in Zookeeper mode...
2025-12-08 18:06:25.778 | ===> Running preflight checks ... 
2025-12-08 18:06:25.792 | ===> Check if /var/lib/kafka/data is writable ...
2025-12-08 18:06:26.901 | ===> Check if Zookeeper is healthy ...
2025-12-08 18:06:31.481 | [2025-12-08 12:36:31,480] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.491 | [2025-12-08 12:36:31,491] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.491 | [2025-12-08 12:36:31,491] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.491 | [2025-12-08 12:36:31,491] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.491 | [2025-12-08 12:36:31,491] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-clients-7.4.0-ccs.jar:/usr/share/java/cp-base-new/kafka_2.13-7.4.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.11.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.4.0-ccs.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/kafka-raft-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.2-1.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.4.0-ccs.jar:/usr/share/java/cp-base-new/snappy-java-1.1.8.4.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/common-utils-7.4.0.jar:/usr/share/java/cp-base-new/kafka-metadata-7.4.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/logredactor-1.0.11.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/utility-belt-7.4.0.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.4.0-ccs.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.4.0.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/kafka-server-common-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/jose4j-0.7.9.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.6.0.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.492 | [2025-12-08 12:36:31,491] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.494 | [2025-12-08 12:36:31,492] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.494 | [2025-12-08 12:36:31,492] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.494 | [2025-12-08 12:36:31,492] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.494 | [2025-12-08 12:36:31,492] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.494 | [2025-12-08 12:36:31,492] INFO Client environment:os.memory.max=1932MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.494 | [2025-12-08 12:36:31,492] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.568 | [2025-12-08 12:36:31,564] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@797badd3 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:31.694 | [2025-12-08 12:36:31,685] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-08 18:06:31.836 | [2025-12-08 12:36:31,833] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-08 18:06:31.924 | [2025-12-08 12:36:31,923] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:32.059 | [2025-12-08 12:36:32,059] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:32.059 | [2025-12-08 12:36:32,059] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:32.158 | [2025-12-08 12:36:32,143] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:32.158 | java.net.ConnectException: Connection refused
2025-12-08 18:06:32.158 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 18:06:32.158 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 18:06:32.158 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 18:06:32.158 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 18:06:33.279 | [2025-12-08 12:36:33,275] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:33.280 | [2025-12-08 12:36:33,275] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:33.280 | [2025-12-08 12:36:33,277] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:33.280 | java.net.ConnectException: Connection refused
2025-12-08 18:06:33.280 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 18:06:33.280 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 18:06:33.280 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 18:06:33.280 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 18:06:34.397 | [2025-12-08 12:36:34,397] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:34.397 | [2025-12-08 12:36:34,397] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:34.407 | [2025-12-08 12:36:34,398] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:34.408 | java.net.ConnectException: Connection refused
2025-12-08 18:06:34.408 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 18:06:34.408 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 18:06:34.408 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 18:06:34.408 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 18:06:35.507 | [2025-12-08 12:36:35,507] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:35.507 | [2025-12-08 12:36:35,507] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:35.509 | [2025-12-08 12:36:35,509] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:35.510 | java.net.ConnectException: Connection refused
2025-12-08 18:06:35.510 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 18:06:35.510 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 18:06:35.510 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 18:06:35.510 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 18:06:36.611 | [2025-12-08 12:36:36,610] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:36.611 | [2025-12-08 12:36:36,611] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:36.612 | [2025-12-08 12:36:36,612] INFO Socket connection established, initiating session, client: /172.18.0.4:32824, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:36.779 | [2025-12-08 12:36:36,776] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:36.779 | EndOfStreamException: Unable to read additional data from server sessionid 0x0, likely server has closed socket
2025-12-08 18:06:36.779 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-08 18:06:36.779 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-08 18:06:36.779 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 18:06:38.702 | [2025-12-08 12:36:38,698] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:38.702 | [2025-12-08 12:36:38,702] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:38.703 | [2025-12-08 12:36:38,703] INFO Socket connection established, initiating session, client: /172.18.0.4:32836, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:38.874 | [2025-12-08 12:36:38,874] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x1000245b2e60000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:38.960 | [2025-12-08 12:36:38,960] WARN An exception was thrown while closing send thread for session 0x1000245b2e60000. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:38.960 | EndOfStreamException: Unable to read additional data from server sessionid 0x1000245b2e60000, likely server has closed socket
2025-12-08 18:06:38.960 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-08 18:06:38.960 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-08 18:06:38.960 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 18:06:39.082 | [2025-12-08 12:36:39,064] INFO Session: 0x1000245b2e60000 closed (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:39.082 | [2025-12-08 12:36:39,064] INFO EventThread shut down for session: 0x1000245b2e60000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:39.137 | Using log4j config /etc/kafka/log4j.properties
2025-12-08 18:06:39.348 | ===> Launching ... 
2025-12-08 18:06:39.376 | ===> Launching kafka ... 
2025-12-08 18:06:43.427 | [2025-12-08 12:36:43,426] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-12-08 18:06:45.908 | [2025-12-08 12:36:45,907] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-08 18:06:46.981 | [2025-12-08 12:36:46,981] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-08 18:06:46.998 | [2025-12-08 12:36:46,997] INFO starting (kafka.server.KafkaServer)
2025-12-08 18:06:46.998 | [2025-12-08 12:36:46,998] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-12-08 18:06:47.113 | [2025-12-08 12:36:47,112] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 18:06:47.178 | [2025-12-08 12:36:47,178] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.178 | [2025-12-08 12:36:47,178] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.178 | [2025-12-08 12:36:47,178] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.178 | [2025-12-08 12:36:47,178] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.184 | [2025-12-08 12:36:47,184] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.188 | [2025-12-08 12:36:47,185] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.189 | [2025-12-08 12:36:47,189] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,189] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.190 | [2025-12-08 12:36:47,190] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.191 | [2025-12-08 12:36:47,191] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.191 | [2025-12-08 12:36:47,191] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.191 | [2025-12-08 12:36:47,191] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.256 | [2025-12-08 12:36:47,255] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@37c7595 (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:06:47.346 | [2025-12-08 12:36:47,345] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-08 18:06:47.387 | [2025-12-08 12:36:47,387] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:47.436 | [2025-12-08 12:36:47,435] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 18:06:47.452 | [2025-12-08 12:36:47,439] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:47.465 | [2025-12-08 12:36:47,464] INFO Socket connection established, initiating session, client: /172.18.0.4:40928, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:47.497 | [2025-12-08 12:36:47,497] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x1000245b2e60001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:06:47.537 | [2025-12-08 12:36:47,537] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 18:06:49.397 | [2025-12-08 12:36:49,397] INFO Cluster ID = xTa4oP5DQQqhwOcnPmb7dg (kafka.server.KafkaServer)
2025-12-08 18:06:49.732 | [2025-12-08 12:36:49,731] INFO KafkaConfig values: 
2025-12-08 18:06:49.732 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-12-08 18:06:49.732 | 	alter.config.policy.class.name = null
2025-12-08 18:06:49.732 | 	alter.log.dirs.replication.quota.window.num = 11
2025-12-08 18:06:49.732 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-12-08 18:06:49.732 | 	authorizer.class.name = 
2025-12-08 18:06:49.732 | 	auto.create.topics.enable = true
2025-12-08 18:06:49.732 | 	auto.include.jmx.reporter = true
2025-12-08 18:06:49.732 | 	auto.leader.rebalance.enable = true
2025-12-08 18:06:49.732 | 	background.threads = 10
2025-12-08 18:06:49.732 | 	broker.heartbeat.interval.ms = 2000
2025-12-08 18:06:49.732 | 	broker.id = 1
2025-12-08 18:06:49.732 | 	broker.id.generation.enable = true
2025-12-08 18:06:49.732 | 	broker.rack = null
2025-12-08 18:06:49.732 | 	broker.session.timeout.ms = 9000
2025-12-08 18:06:49.732 | 	client.quota.callback.class = null
2025-12-08 18:06:49.732 | 	compression.type = producer
2025-12-08 18:06:49.732 | 	connection.failed.authentication.delay.ms = 100
2025-12-08 18:06:49.732 | 	connections.max.idle.ms = 600000
2025-12-08 18:06:49.732 | 	connections.max.reauth.ms = 0
2025-12-08 18:06:49.732 | 	control.plane.listener.name = null
2025-12-08 18:06:49.732 | 	controlled.shutdown.enable = true
2025-12-08 18:06:49.732 | 	controlled.shutdown.max.retries = 3
2025-12-08 18:06:49.732 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-12-08 18:06:49.732 | 	controller.listener.names = null
2025-12-08 18:06:49.732 | 	controller.quorum.append.linger.ms = 25
2025-12-08 18:06:49.732 | 	controller.quorum.election.backoff.max.ms = 1000
2025-12-08 18:06:49.732 | 	controller.quorum.election.timeout.ms = 1000
2025-12-08 18:06:49.732 | 	controller.quorum.fetch.timeout.ms = 2000
2025-12-08 18:06:49.732 | 	controller.quorum.request.timeout.ms = 2000
2025-12-08 18:06:49.732 | 	controller.quorum.retry.backoff.ms = 20
2025-12-08 18:06:49.732 | 	controller.quorum.voters = []
2025-12-08 18:06:49.732 | 	controller.quota.window.num = 11
2025-12-08 18:06:49.732 | 	controller.quota.window.size.seconds = 1
2025-12-08 18:06:49.732 | 	controller.socket.timeout.ms = 30000
2025-12-08 18:06:49.732 | 	create.topic.policy.class.name = null
2025-12-08 18:06:49.732 | 	default.replication.factor = 1
2025-12-08 18:06:49.732 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-12-08 18:06:49.732 | 	delegation.token.expiry.time.ms = 86400000
2025-12-08 18:06:49.732 | 	delegation.token.master.key = null
2025-12-08 18:06:49.732 | 	delegation.token.max.lifetime.ms = 604800000
2025-12-08 18:06:49.732 | 	delegation.token.secret.key = null
2025-12-08 18:06:49.732 | 	delete.records.purgatory.purge.interval.requests = 1
2025-12-08 18:06:49.732 | 	delete.topic.enable = true
2025-12-08 18:06:49.732 | 	early.start.listeners = null
2025-12-08 18:06:49.732 | 	fetch.max.bytes = 57671680
2025-12-08 18:06:49.732 | 	fetch.purgatory.purge.interval.requests = 1000
2025-12-08 18:06:49.732 | 	group.initial.rebalance.delay.ms = 3000
2025-12-08 18:06:49.732 | 	group.max.session.timeout.ms = 1800000
2025-12-08 18:06:49.732 | 	group.max.size = 2147483647
2025-12-08 18:06:49.732 | 	group.min.session.timeout.ms = 6000
2025-12-08 18:06:49.732 | 	initial.broker.registration.timeout.ms = 60000
2025-12-08 18:06:49.732 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-12-08 18:06:49.732 | 	inter.broker.protocol.version = 3.4-IV0
2025-12-08 18:06:49.732 | 	kafka.metrics.polling.interval.secs = 10
2025-12-08 18:06:49.732 | 	kafka.metrics.reporters = []
2025-12-08 18:06:49.732 | 	leader.imbalance.check.interval.seconds = 300
2025-12-08 18:06:49.732 | 	leader.imbalance.per.broker.percentage = 10
2025-12-08 18:06:49.732 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-12-08 18:06:49.732 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-12-08 18:06:49.732 | 	log.cleaner.backoff.ms = 15000
2025-12-08 18:06:49.732 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-12-08 18:06:49.732 | 	log.cleaner.delete.retention.ms = 86400000
2025-12-08 18:06:49.732 | 	log.cleaner.enable = true
2025-12-08 18:06:49.732 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-12-08 18:06:49.732 | 	log.cleaner.io.buffer.size = 524288
2025-12-08 18:06:49.732 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-12-08 18:06:49.732 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-12-08 18:06:49.732 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-12-08 18:06:49.732 | 	log.cleaner.min.compaction.lag.ms = 0
2025-12-08 18:06:49.732 | 	log.cleaner.threads = 1
2025-12-08 18:06:49.732 | 	log.cleanup.policy = [delete]
2025-12-08 18:06:49.732 | 	log.dir = /tmp/kafka-logs
2025-12-08 18:06:49.732 | 	log.dirs = /var/lib/kafka/data
2025-12-08 18:06:49.732 | 	log.flush.interval.messages = 9223372036854775807
2025-12-08 18:06:49.732 | 	log.flush.interval.ms = null
2025-12-08 18:06:49.732 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-12-08 18:06:49.732 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-12-08 18:06:49.732 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-12-08 18:06:49.732 | 	log.index.interval.bytes = 4096
2025-12-08 18:06:49.732 | 	log.index.size.max.bytes = 10485760
2025-12-08 18:06:49.732 | 	log.message.downconversion.enable = true
2025-12-08 18:06:49.732 | 	log.message.format.version = 3.0-IV1
2025-12-08 18:06:49.732 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-12-08 18:06:49.732 | 	log.message.timestamp.type = CreateTime
2025-12-08 18:06:49.732 | 	log.preallocate = false
2025-12-08 18:06:49.732 | 	log.retention.bytes = -1
2025-12-08 18:06:49.732 | 	log.retention.check.interval.ms = 300000
2025-12-08 18:06:49.732 | 	log.retention.hours = 168
2025-12-08 18:06:49.732 | 	log.retention.minutes = null
2025-12-08 18:06:49.732 | 	log.retention.ms = null
2025-12-08 18:06:49.732 | 	log.roll.hours = 168
2025-12-08 18:06:49.732 | 	log.roll.jitter.hours = 0
2025-12-08 18:06:49.732 | 	log.roll.jitter.ms = null
2025-12-08 18:06:49.732 | 	log.roll.ms = null
2025-12-08 18:06:49.732 | 	log.segment.bytes = 1073741824
2025-12-08 18:06:49.732 | 	log.segment.delete.delay.ms = 60000
2025-12-08 18:06:49.732 | 	max.connection.creation.rate = 2147483647
2025-12-08 18:06:49.733 | 	max.connections = 2147483647
2025-12-08 18:06:49.733 | 	max.connections.per.ip = 2147483647
2025-12-08 18:06:49.733 | 	max.connections.per.ip.overrides = 
2025-12-08 18:06:49.733 | 	max.incremental.fetch.session.cache.slots = 1000
2025-12-08 18:06:49.733 | 	message.max.bytes = 1048588
2025-12-08 18:06:49.733 | 	metadata.log.dir = null
2025-12-08 18:06:49.733 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-12-08 18:06:49.733 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-12-08 18:06:49.733 | 	metadata.log.segment.bytes = 1073741824
2025-12-08 18:06:49.733 | 	metadata.log.segment.min.bytes = 8388608
2025-12-08 18:06:49.733 | 	metadata.log.segment.ms = 604800000
2025-12-08 18:06:49.733 | 	metadata.max.idle.interval.ms = 500
2025-12-08 18:06:49.733 | 	metadata.max.retention.bytes = 104857600
2025-12-08 18:06:49.733 | 	metadata.max.retention.ms = 604800000
2025-12-08 18:06:49.733 | 	metric.reporters = []
2025-12-08 18:06:49.733 | 	metrics.num.samples = 2
2025-12-08 18:06:49.733 | 	metrics.recording.level = INFO
2025-12-08 18:06:49.733 | 	metrics.sample.window.ms = 30000
2025-12-08 18:06:49.733 | 	min.insync.replicas = 1
2025-12-08 18:06:49.733 | 	node.id = 1
2025-12-08 18:06:49.733 | 	num.io.threads = 8
2025-12-08 18:06:49.733 | 	num.network.threads = 3
2025-12-08 18:06:49.733 | 	num.partitions = 1
2025-12-08 18:06:49.733 | 	num.recovery.threads.per.data.dir = 1
2025-12-08 18:06:49.733 | 	num.replica.alter.log.dirs.threads = null
2025-12-08 18:06:49.733 | 	num.replica.fetchers = 1
2025-12-08 18:06:49.733 | 	offset.metadata.max.bytes = 4096
2025-12-08 18:06:49.733 | 	offsets.commit.required.acks = -1
2025-12-08 18:06:49.733 | 	offsets.commit.timeout.ms = 5000
2025-12-08 18:06:49.733 | 	offsets.load.buffer.size = 5242880
2025-12-08 18:06:49.733 | 	offsets.retention.check.interval.ms = 600000
2025-12-08 18:06:49.733 | 	offsets.retention.minutes = 10080
2025-12-08 18:06:49.733 | 	offsets.topic.compression.codec = 0
2025-12-08 18:06:49.733 | 	offsets.topic.num.partitions = 50
2025-12-08 18:06:49.733 | 	offsets.topic.replication.factor = 1
2025-12-08 18:06:49.733 | 	offsets.topic.segment.bytes = 104857600
2025-12-08 18:06:49.733 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-12-08 18:06:49.733 | 	password.encoder.iterations = 4096
2025-12-08 18:06:49.733 | 	password.encoder.key.length = 128
2025-12-08 18:06:49.733 | 	password.encoder.keyfactory.algorithm = null
2025-12-08 18:06:49.733 | 	password.encoder.old.secret = null
2025-12-08 18:06:49.733 | 	password.encoder.secret = null
2025-12-08 18:06:49.733 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-12-08 18:06:49.733 | 	process.roles = []
2025-12-08 18:06:49.733 | 	producer.id.expiration.check.interval.ms = 600000
2025-12-08 18:06:49.733 | 	producer.id.expiration.ms = 86400000
2025-12-08 18:06:49.733 | 	producer.purgatory.purge.interval.requests = 1000
2025-12-08 18:06:49.733 | 	queued.max.request.bytes = -1
2025-12-08 18:06:49.733 | 	queued.max.requests = 500
2025-12-08 18:06:49.733 | 	quota.window.num = 11
2025-12-08 18:06:49.733 | 	quota.window.size.seconds = 1
2025-12-08 18:06:49.733 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-12-08 18:06:49.733 | 	remote.log.manager.task.interval.ms = 30000
2025-12-08 18:06:49.733 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-12-08 18:06:49.733 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-12-08 18:06:49.733 | 	remote.log.manager.task.retry.jitter = 0.2
2025-12-08 18:06:49.733 | 	remote.log.manager.thread.pool.size = 10
2025-12-08 18:06:49.733 | 	remote.log.metadata.manager.class.name = null
2025-12-08 18:06:49.733 | 	remote.log.metadata.manager.class.path = null
2025-12-08 18:06:49.733 | 	remote.log.metadata.manager.impl.prefix = null
2025-12-08 18:06:49.733 | 	remote.log.metadata.manager.listener.name = null
2025-12-08 18:06:49.733 | 	remote.log.reader.max.pending.tasks = 100
2025-12-08 18:06:49.733 | 	remote.log.reader.threads = 10
2025-12-08 18:06:49.733 | 	remote.log.storage.manager.class.name = null
2025-12-08 18:06:49.733 | 	remote.log.storage.manager.class.path = null
2025-12-08 18:06:49.733 | 	remote.log.storage.manager.impl.prefix = null
2025-12-08 18:06:49.733 | 	remote.log.storage.system.enable = false
2025-12-08 18:06:49.733 | 	replica.fetch.backoff.ms = 1000
2025-12-08 18:06:49.733 | 	replica.fetch.max.bytes = 1048576
2025-12-08 18:06:49.733 | 	replica.fetch.min.bytes = 1
2025-12-08 18:06:49.733 | 	replica.fetch.response.max.bytes = 10485760
2025-12-08 18:06:49.733 | 	replica.fetch.wait.max.ms = 500
2025-12-08 18:06:49.733 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-12-08 18:06:49.733 | 	replica.lag.time.max.ms = 30000
2025-12-08 18:06:49.733 | 	replica.selector.class = null
2025-12-08 18:06:49.733 | 	replica.socket.receive.buffer.bytes = 65536
2025-12-08 18:06:49.733 | 	replica.socket.timeout.ms = 30000
2025-12-08 18:06:49.733 | 	replication.quota.window.num = 11
2025-12-08 18:06:49.733 | 	replication.quota.window.size.seconds = 1
2025-12-08 18:06:49.733 | 	request.timeout.ms = 30000
2025-12-08 18:06:49.733 | 	reserved.broker.max.id = 1000
2025-12-08 18:06:49.733 | 	sasl.client.callback.handler.class = null
2025-12-08 18:06:49.733 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-12-08 18:06:49.733 | 	sasl.jaas.config = null
2025-12-08 18:06:49.733 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-12-08 18:06:49.733 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-12-08 18:06:49.733 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-12-08 18:06:49.733 | 	sasl.kerberos.service.name = null
2025-12-08 18:06:49.733 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-12-08 18:06:49.733 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-12-08 18:06:49.733 | 	sasl.login.callback.handler.class = null
2025-12-08 18:06:49.733 | 	sasl.login.class = null
2025-12-08 18:06:49.733 | 	sasl.login.connect.timeout.ms = null
2025-12-08 18:06:49.733 | 	sasl.login.read.timeout.ms = null
2025-12-08 18:06:49.733 | 	sasl.login.refresh.buffer.seconds = 300
2025-12-08 18:06:49.733 | 	sasl.login.refresh.min.period.seconds = 60
2025-12-08 18:06:49.733 | 	sasl.login.refresh.window.factor = 0.8
2025-12-08 18:06:49.733 | 	sasl.login.refresh.window.jitter = 0.05
2025-12-08 18:06:49.733 | 	sasl.login.retry.backoff.max.ms = 10000
2025-12-08 18:06:49.733 | 	sasl.login.retry.backoff.ms = 100
2025-12-08 18:06:49.733 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-12-08 18:06:49.733 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.expected.audience = null
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.expected.issuer = null
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-12-08 18:06:49.733 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-12-08 18:06:49.741 | 	sasl.oauthbearer.scope.claim.name = scope
2025-12-08 18:06:49.741 | 	sasl.oauthbearer.sub.claim.name = sub
2025-12-08 18:06:49.741 | 	sasl.oauthbearer.token.endpoint.url = null
2025-12-08 18:06:49.741 | 	sasl.server.callback.handler.class = null
2025-12-08 18:06:49.741 | 	sasl.server.max.receive.size = 524288
2025-12-08 18:06:49.741 | 	security.inter.broker.protocol = PLAINTEXT
2025-12-08 18:06:49.741 | 	security.providers = null
2025-12-08 18:06:49.741 | 	socket.connection.setup.timeout.max.ms = 30000
2025-12-08 18:06:49.742 | 	socket.connection.setup.timeout.ms = 10000
2025-12-08 18:06:49.742 | 	socket.listen.backlog.size = 50
2025-12-08 18:06:49.742 | 	socket.receive.buffer.bytes = 102400
2025-12-08 18:06:49.742 | 	socket.request.max.bytes = 104857600
2025-12-08 18:06:49.742 | 	socket.send.buffer.bytes = 102400
2025-12-08 18:06:49.742 | 	ssl.cipher.suites = []
2025-12-08 18:06:49.742 | 	ssl.client.auth = none
2025-12-08 18:06:49.742 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-12-08 18:06:49.742 | 	ssl.endpoint.identification.algorithm = https
2025-12-08 18:06:49.742 | 	ssl.engine.factory.class = null
2025-12-08 18:06:49.742 | 	ssl.key.password = null
2025-12-08 18:06:49.742 | 	ssl.keymanager.algorithm = SunX509
2025-12-08 18:06:49.742 | 	ssl.keystore.certificate.chain = null
2025-12-08 18:06:49.742 | 	ssl.keystore.key = null
2025-12-08 18:06:49.742 | 	ssl.keystore.location = null
2025-12-08 18:06:49.742 | 	ssl.keystore.password = null
2025-12-08 18:06:49.742 | 	ssl.keystore.type = JKS
2025-12-08 18:06:49.742 | 	ssl.principal.mapping.rules = DEFAULT
2025-12-08 18:06:49.742 | 	ssl.protocol = TLSv1.3
2025-12-08 18:06:49.742 | 	ssl.provider = null
2025-12-08 18:06:49.742 | 	ssl.secure.random.implementation = null
2025-12-08 18:06:49.742 | 	ssl.trustmanager.algorithm = PKIX
2025-12-08 18:06:49.742 | 	ssl.truststore.certificates = null
2025-12-08 18:06:49.742 | 	ssl.truststore.location = null
2025-12-08 18:06:49.742 | 	ssl.truststore.password = null
2025-12-08 18:06:49.742 | 	ssl.truststore.type = JKS
2025-12-08 18:06:49.742 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-12-08 18:06:49.742 | 	transaction.max.timeout.ms = 900000
2025-12-08 18:06:49.742 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-12-08 18:06:49.742 | 	transaction.state.log.load.buffer.size = 5242880
2025-12-08 18:06:49.742 | 	transaction.state.log.min.isr = 1
2025-12-08 18:06:49.742 | 	transaction.state.log.num.partitions = 50
2025-12-08 18:06:49.742 | 	transaction.state.log.replication.factor = 1
2025-12-08 18:06:49.742 | 	transaction.state.log.segment.bytes = 104857600
2025-12-08 18:06:49.742 | 	transactional.id.expiration.ms = 604800000
2025-12-08 18:06:49.742 | 	unclean.leader.election.enable = false
2025-12-08 18:06:49.742 | 	zookeeper.clientCnxnSocket = null
2025-12-08 18:06:49.742 | 	zookeeper.connect = zookeeper:2181
2025-12-08 18:06:49.742 | 	zookeeper.connection.timeout.ms = null
2025-12-08 18:06:49.742 | 	zookeeper.max.in.flight.requests = 10
2025-12-08 18:06:49.742 | 	zookeeper.metadata.migration.enable = false
2025-12-08 18:06:49.742 | 	zookeeper.session.timeout.ms = 18000
2025-12-08 18:06:49.742 | 	zookeeper.set.acl = false
2025-12-08 18:06:49.742 | 	zookeeper.ssl.cipher.suites = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.client.enable = false
2025-12-08 18:06:49.742 | 	zookeeper.ssl.crl.enable = false
2025-12-08 18:06:49.742 | 	zookeeper.ssl.enabled.protocols = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-12-08 18:06:49.742 | 	zookeeper.ssl.keystore.location = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.keystore.password = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.keystore.type = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.ocsp.enable = false
2025-12-08 18:06:49.742 | 	zookeeper.ssl.protocol = TLSv1.2
2025-12-08 18:06:49.742 | 	zookeeper.ssl.truststore.location = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.truststore.password = null
2025-12-08 18:06:49.742 | 	zookeeper.ssl.truststore.type = null
2025-12-08 18:06:49.742 |  (kafka.server.KafkaConfig)
2025-12-08 18:06:50.098 | [2025-12-08 12:36:50,078] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:06:50.112 | [2025-12-08 12:36:50,079] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:06:50.112 | [2025-12-08 12:36:50,112] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:06:50.139 | [2025-12-08 12:36:50,139] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:06:50.483 | [2025-12-08 12:36:50,483] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:50.494 | [2025-12-08 12:36:50,493] INFO Skipping recovery for all logs in /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-12-08 18:06:51.218 | [2025-12-08 12:36:51,215] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.371 | [2025-12-08 12:36:51,362] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 573ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.422 | [2025-12-08 12:36:51,422] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.440 | [2025-12-08 12:36:51,440] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 66ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.464 | [2025-12-08 12:36:51,464] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.496 | [2025-12-08 12:36:51,496] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.537 | [2025-12-08 12:36:51,537] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.543 | [2025-12-08 12:36:51,543] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.562 | [2025-12-08 12:36:51,562] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.600 | [2025-12-08 12:36:51,600] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.714 | [2025-12-08 12:36:51,714] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.726 | [2025-12-08 12:36:51,723] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 122ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.765 | [2025-12-08 12:36:51,765] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.778 | [2025-12-08 12:36:51,777] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.817 | [2025-12-08 12:36:51,816] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.850 | [2025-12-08 12:36:51,850] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.890 | [2025-12-08 12:36:51,890] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.909 | [2025-12-08 12:36:51,907] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 57ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:51.947 | [2025-12-08 12:36:51,946] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:51.959 | [2025-12-08 12:36:51,959] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 49ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.007 | [2025-12-08 12:36:52,002] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.013 | [2025-12-08 12:36:52,013] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.040 | [2025-12-08 12:36:52,040] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.046 | [2025-12-08 12:36:52,046] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.089 | [2025-12-08 12:36:52,089] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.109 | [2025-12-08 12:36:52,109] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.160 | [2025-12-08 12:36:52,159] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.180 | [2025-12-08 12:36:52,180] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 58ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.199 | [2025-12-08 12:36:52,198] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.205 | [2025-12-08 12:36:52,205] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.252 | [2025-12-08 12:36:52,252] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.259 | [2025-12-08 12:36:52,259] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 53ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.293 | [2025-12-08 12:36:52,293] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.299 | [2025-12-08 12:36:52,299] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.339 | [2025-12-08 12:36:52,339] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.344 | [2025-12-08 12:36:52,344] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.356 | [2025-12-08 12:36:52,356] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.360 | [2025-12-08 12:36:52,360] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.393 | [2025-12-08 12:36:52,393] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.432 | [2025-12-08 12:36:52,431] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 70ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.467 | [2025-12-08 12:36:52,467] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.482 | [2025-12-08 12:36:52,482] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.526 | [2025-12-08 12:36:52,526] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.542 | [2025-12-08 12:36:52,542] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 60ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.593 | [2025-12-08 12:36:52,593] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.599 | [2025-12-08 12:36:52,599] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.622 | [2025-12-08 12:36:52,622] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.635 | [2025-12-08 12:36:52,635] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.663 | [2025-12-08 12:36:52,662] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.666 | [2025-12-08 12:36:52,666] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.685 | [2025-12-08 12:36:52,685] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.694 | [2025-12-08 12:36:52,693] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.709 | [2025-12-08 12:36:52,709] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.723 | [2025-12-08 12:36:52,723] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.786 | [2025-12-08 12:36:52,785] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.812 | [2025-12-08 12:36:52,811] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 87ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.861 | [2025-12-08 12:36:52,861] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.878 | [2025-12-08 12:36:52,873] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 54ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.897 | [2025-12-08 12:36:52,897] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.904 | [2025-12-08 12:36:52,904] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.929 | [2025-12-08 12:36:52,929] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.944 | [2025-12-08 12:36:52,943] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.955 | [2025-12-08 12:36:52,955] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.958 | [2025-12-08 12:36:52,958] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:52.978 | [2025-12-08 12:36:52,977] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:52.997 | [2025-12-08 12:36:52,996] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.046 | [2025-12-08 12:36:53,043] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.054 | [2025-12-08 12:36:53,054] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 57ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.115 | [2025-12-08 12:36:53,115] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.127 | [2025-12-08 12:36:53,126] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.161 | [2025-12-08 12:36:53,161] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.166 | [2025-12-08 12:36:53,165] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.208 | [2025-12-08 12:36:53,207] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.211 | [2025-12-08 12:36:53,210] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.331 | [2025-12-08 12:36:53,326] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.363 | [2025-12-08 12:36:53,361] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 150ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.464 | [2025-12-08 12:36:53,459] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.464 | [2025-12-08 12:36:53,462] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 100ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.527 | [2025-12-08 12:36:53,526] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.536 | [2025-12-08 12:36:53,536] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 74ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.709 | [2025-12-08 12:36:53,703] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.709 | [2025-12-08 12:36:53,703] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.709 | [2025-12-08 12:36:53,709] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/__consumer_offsets-8/00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
2025-12-08 18:06:53.796 | [2025-12-08 12:36:53,792] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Producer state recovery took 88ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.820 | [2025-12-08 12:36:53,811] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 275ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.853 | [2025-12-08 12:36:53,845] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.872 | [2025-12-08 12:36:53,870] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 59ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:53.976 | [2025-12-08 12:36:53,973] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.981 | [2025-12-08 12:36:53,977] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
2025-12-08 18:06:53.981 | [2025-12-08 12:36:53,978] INFO [ProducerStateManager partition=booking-email-0] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/booking-email-0/00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
2025-12-08 18:06:54.043 | [2025-12-08 12:36:54,039] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Producer state recovery took 61ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.058 | [2025-12-08 12:36:54,057] INFO Completed load of Log(dir=/var/lib/kafka/data/booking-email-0, topicId=ZZs51CcXT3m5RospnghyvA, topic=booking-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 186ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.092 | [2025-12-08 12:36:54,091] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.105 | [2025-12-08 12:36:54,105] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.135 | [2025-12-08 12:36:54,135] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.147 | [2025-12-08 12:36:54,147] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.168 | [2025-12-08 12:36:54,167] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.186 | [2025-12-08 12:36:54,186] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.227 | [2025-12-08 12:36:54,225] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.231 | [2025-12-08 12:36:54,231] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.266 | [2025-12-08 12:36:54,265] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.269 | [2025-12-08 12:36:54,268] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 37ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.347 | [2025-12-08 12:36:54,346] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.354 | [2025-12-08 12:36:54,353] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 83ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.367 | [2025-12-08 12:36:54,367] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.370 | [2025-12-08 12:36:54,369] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.410 | [2025-12-08 12:36:54,410] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 18:06:54.414 | [2025-12-08 12:36:54,414] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 18:06:54.422 | [2025-12-08 12:36:54,422] INFO Loaded 51 logs in 3939ms. (kafka.log.LogManager)
2025-12-08 18:06:54.423 | [2025-12-08 12:36:54,423] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-12-08 18:06:54.426 | [2025-12-08 12:36:54,426] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-12-08 18:06:54.482 | [2025-12-08 12:36:54,482] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-12-08 18:06:54.854 | [2025-12-08 12:36:54,851] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
2025-12-08 18:06:55.041 | [2025-12-08 12:36:55,041] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 18:06:55.185 | [2025-12-08 12:36:55,185] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-12-08 18:06:55.427 | [2025-12-08 12:36:55,427] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:06:58.176 | [2025-12-08 12:36:58,176] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-08 18:06:58.231 | [2025-12-08 12:36:58,231] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-12-08 18:06:58.553 | [2025-12-08 12:36:58,552] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-12-08 18:06:58.583 | [2025-12-08 12:36:58,583] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-08 18:06:58.587 | [2025-12-08 12:36:58,587] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-12-08 18:06:58.614 | [2025-12-08 12:36:58,614] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-12-08 18:06:58.838 | [2025-12-08 12:36:58,821] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:06:58.986 | [2025-12-08 12:36:58,981] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:06:59.053 | [2025-12-08 12:36:59,032] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:06:59.076 | [2025-12-08 12:36:59,075] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:06:59.087 | [2025-12-08 12:36:59,086] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:06:59.238 | [2025-12-08 12:36:59,231] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 18:06:59.516 | [2025-12-08 12:36:59,516] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-12-08 18:06:59.673 | [2025-12-08 12:36:59,672] INFO Stat of the created znode at /brokers/ids/1 is: 161,161,1765197419582,1765197419582,1,0,0,72060092415344641,270,0,161
2025-12-08 18:06:59.673 |  (kafka.zk.KafkaZkClient)
2025-12-08 18:06:59.691 | [2025-12-08 12:36:59,691] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 161 (kafka.zk.KafkaZkClient)
2025-12-08 18:07:00.243 | [2025-12-08 12:37:00,240] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 18:07:00.284 | [2025-12-08 12:37:00,282] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:07:00.372 | [2025-12-08 12:37:00,371] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:07:00.374 | [2025-12-08 12:37:00,371] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:07:00.532 | [2025-12-08 12:37:00,532] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 2 and epoch zk version is now 2 (kafka.controller.KafkaController)
2025-12-08 18:07:00.552 | [2025-12-08 12:37:00,542] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:00.598 | [2025-12-08 12:37:00,596] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-12-08 18:07:00.618 | [2025-12-08 12:37:00,617] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-12-08 18:07:00.630 | [2025-12-08 12:37:00,628] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-12-08 18:07:00.657 | [2025-12-08 12:37:00,653] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-12-08 18:07:00.754 | [2025-12-08 12:37:00,753] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 161) (kafka.controller.KafkaController)
2025-12-08 18:07:00.762 | [2025-12-08 12:37:00,757] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:00.848 | [2025-12-08 12:37:00,847] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-08 18:07:01.026 | [2025-12-08 12:37:01,026] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 18:07:01.143 | [2025-12-08 12:37:01,143] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-12-08 18:07:01.163 | [2025-12-08 12:37:01,160] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 18:07:01.253 | [2025-12-08 12:37:01,253] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 18:07:01.298 | [2025-12-08 12:37:01,298] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-12-08 18:07:01.299 | [2025-12-08 12:37:01,299] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-12-08 18:07:01.301 | [2025-12-08 12:37:01,300] INFO [Controller id=1] Current list of topics in the cluster: HashSet(booking-email, __consumer_offsets) (kafka.controller.KafkaController)
2025-12-08 18:07:01.301 | [2025-12-08 12:37:01,301] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-12-08 18:07:01.341 | [2025-12-08 12:37:01,341] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-12-08 18:07:01.359 | [2025-12-08 12:37:01,359] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-12-08 18:07:01.360 | [2025-12-08 12:37:01,359] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-12-08 18:07:01.360 | [2025-12-08 12:37:01,360] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-12-08 18:07:01.361 | [2025-12-08 12:37:01,360] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-12-08 18:07:01.429 | [2025-12-08 12:37:01,429] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-12-08 18:07:01.453 | [2025-12-08 12:37:01,435] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-12-08 18:07:01.524 | [2025-12-08 12:37:01,524] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-12-08 18:07:01.556 | [2025-12-08 12:37:01,556] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-08 18:07:01.572 | [2025-12-08 12:37:01,572] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-12-08 18:07:01.786 | [2025-12-08 12:37:01,785] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:07:01.834 | [2025-12-08 12:37:01,814] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.840 | [2025-12-08 12:37:01,840] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.866 | [2025-12-08 12:37:01,866] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.871 | [2025-12-08 12:37:01,867] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.873 | [2025-12-08 12:37:01,872] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.874 | [2025-12-08 12:37:01,874] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.875 | [2025-12-08 12:37:01,874] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.875 | [2025-12-08 12:37:01,875] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.875 | [2025-12-08 12:37:01,875] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.876 | [2025-12-08 12:37:01,876] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.876 | [2025-12-08 12:37:01,876] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.876 | [2025-12-08 12:37:01,876] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.877 | [2025-12-08 12:37:01,877] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.877 | [2025-12-08 12:37:01,877] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.885 | [2025-12-08 12:37:01,884] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.886 | [2025-12-08 12:37:01,886] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.888 | [2025-12-08 12:37:01,888] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.890 | [2025-12-08 12:37:01,890] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.890 | [2025-12-08 12:37:01,890] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.891 | [2025-12-08 12:37:01,890] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.891 | [2025-12-08 12:37:01,891] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:01.891 | [2025-12-08 12:37:01,891] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.204 | [2025-12-08 12:37:01,892] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.207 | [2025-12-08 12:37:02,207] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.208 | [2025-12-08 12:37:02,207] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.208 | [2025-12-08 12:37:02,208] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.208 | [2025-12-08 12:37:02,208] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition booking-email-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.222 | [2025-12-08 12:37:02,221] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.223 | [2025-12-08 12:37:02,223] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.223 | [2025-12-08 12:37:02,223] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.224 | [2025-12-08 12:37:02,223] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.224 | [2025-12-08 12:37:02,224] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.224 | [2025-12-08 12:37:02,224] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.253 | [2025-12-08 12:37:02,253] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.254 | [2025-12-08 12:37:02,253] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.256 | [2025-12-08 12:37:02,255] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.256 | [2025-12-08 12:37:02,256] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.311 | [2025-12-08 12:37:02,311] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.372 | [2025-12-08 12:37:02,372] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.373 | [2025-12-08 12:37:02,372] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.373 | [2025-12-08 12:37:02,373] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.373 | [2025-12-08 12:37:02,373] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.374 | [2025-12-08 12:37:02,373] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.376 | [2025-12-08 12:37:02,375] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.376 | [2025-12-08 12:37:02,376] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.376 | [2025-12-08 12:37:02,376] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.376 | [2025-12-08 12:37:02,376] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.377 | [2025-12-08 12:37:02,377] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.377 | [2025-12-08 12:37:02,377] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.377 | [2025-12-08 12:37:02,377] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.378 | [2025-12-08 12:37:02,378] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 18:07:02.448 | [2025-12-08 12:37:02,447] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 18:07:02.471 | [2025-12-08 12:37:02,471] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 18:07:02.472 | [2025-12-08 12:37:02,472] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 18:07:02.472 | [2025-12-08 12:37:02,472] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 18:07:02.472 | [2025-12-08 12:37:02,472] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 18:07:02.472 | [2025-12-08 12:37:02,472] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 18:07:02.473 | [2025-12-08 12:37:02,472] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 18:07:02.473 | [2025-12-08 12:37:02,473] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 18:07:02.473 | [2025-12-08 12:37:02,473] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 18:07:02.473 | [2025-12-08 12:37:02,473] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 18:07:02.473 | [2025-12-08 12:37:02,473] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 18:07:02.474 | [2025-12-08 12:37:02,473] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 18:07:02.474 | [2025-12-08 12:37:02,474] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 18:07:02.474 | [2025-12-08 12:37:02,474] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 18:07:02.474 | [2025-12-08 12:37:02,474] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 18:07:02.474 | [2025-12-08 12:37:02,474] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 18:07:02.474 | [2025-12-08 12:37:02,474] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 18:07:02.475 | [2025-12-08 12:37:02,475] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 18:07:02.475 | [2025-12-08 12:37:02,475] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 18:07:02.475 | [2025-12-08 12:37:02,475] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 18:07:02.475 | [2025-12-08 12:37:02,475] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 18:07:02.475 | [2025-12-08 12:37:02,475] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 18:07:02.476 | [2025-12-08 12:37:02,476] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 18:07:02.482 | [2025-12-08 12:37:02,476] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 18:07:02.482 | [2025-12-08 12:37:02,480] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 18:07:02.482 | [2025-12-08 12:37:02,480] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 18:07:02.482 | [2025-12-08 12:37:02,480] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 18:07:02.482 | [2025-12-08 12:37:02,481] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 18:07:02.482 | [2025-12-08 12:37:02,481] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 18:07:02.491 | [2025-12-08 12:37:02,481] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 18:07:02.491 | [2025-12-08 12:37:02,491] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 18:07:02.491 | [2025-12-08 12:37:02,491] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,491] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 18:07:02.492 | [2025-12-08 12:37:02,492] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 18:07:02.493 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition booking-email-0 (state.change.logger)
2025-12-08 18:07:02.493 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 18:07:02.493 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 18:07:02.493 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 18:07:02.493 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 18:07:02.493 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 18:07:02.494 | [2025-12-08 12:37:02,493] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 18:07:02.494 | [2025-12-08 12:37:02,494] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 18:07:02.494 | [2025-12-08 12:37:02,494] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 18:07:02.494 | [2025-12-08 12:37:02,494] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 18:07:02.512 | [2025-12-08 12:37:02,511] INFO [Controller id=1 epoch=2] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-12-08 18:07:02.535 | [2025-12-08 12:37:02,532] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-12-08 18:07:02.553 | [2025-12-08 12:37:02,553] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-08 18:07:02.577 | [2025-12-08 12:37:02,569] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=booking-email,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-12-08 18:07:02.579 | [2025-12-08 12:37:02,570] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-12-08 18:07:02.590 | [2025-12-08 12:37:02,589] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 18:07:02.591 | [2025-12-08 12:37:02,591] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-12-08 18:07:02.596 | [2025-12-08 12:37:02,594] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, booking-email-0 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-12-08 18:07:02.597 | [2025-12-08 12:37:02,595] INFO [Controller id=1] Ready to serve as the new controller with epoch 2 (kafka.controller.KafkaController)
2025-12-08 18:07:02.661 | [2025-12-08 12:37:02,660] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-12-08 18:07:02.662 | [2025-12-08 12:37:02,662] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-12-08 18:07:02.663 | [2025-12-08 12:37:02,663] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-12-08 18:07:02.679 | [2025-12-08 12:37:02,678] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-12-08 18:07:02.680 | [2025-12-08 12:37:02,680] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-12-08 18:07:02.719 | [2025-12-08 12:37:02,719] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-12-08 18:07:02.790 | [2025-12-08 12:37:02,789] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-12-08 18:07:02.988 | [2025-12-08 12:37:02,987] INFO Kafka version: 7.4.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 18:07:02.988 | [2025-12-08 12:37:02,988] INFO Kafka commitId: 30969fa33c185e880b9e02044761dfaac013151d (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 18:07:02.988 | [2025-12-08 12:37:02,988] INFO Kafka startTimeMs: 1765197422863 (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 18:07:02.994 | [2025-12-08 12:37:02,994] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-12-08 18:07:03.245 | [2025-12-08 12:37:03,245] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:07:03.246 | [2025-12-08 12:37:03,246] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:07:03.285 | [2025-12-08 12:37:03,284] TRACE [Controller id=1 epoch=2] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 18:07:03.296 | [2025-12-08 12:37:03,296] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-12-08 18:07:03.298 | [2025-12-08 12:37:03,298] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.298 | [2025-12-08 12:37:03,298] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.298 | [2025-12-08 12:37:03,298] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.298 | [2025-12-08 12:37:03,298] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.298 | [2025-12-08 12:37:03,298] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.299 | [2025-12-08 12:37:03,299] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.299 | [2025-12-08 12:37:03,299] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.299 | [2025-12-08 12:37:03,299] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.299 | [2025-12-08 12:37:03,299] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.299 | [2025-12-08 12:37:03,299] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.299 | [2025-12-08 12:37:03,299] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.300 | [2025-12-08 12:37:03,300] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.300 | [2025-12-08 12:37:03,300] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.303 | [2025-12-08 12:37:03,302] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.303 | [2025-12-08 12:37:03,303] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.303 | [2025-12-08 12:37:03,303] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.303 | [2025-12-08 12:37:03,303] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.303 | [2025-12-08 12:37:03,303] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.304 | [2025-12-08 12:37:03,303] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.304 | [2025-12-08 12:37:03,304] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.304 | [2025-12-08 12:37:03,304] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.304 | [2025-12-08 12:37:03,304] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.304 | [2025-12-08 12:37:03,304] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.304 | [2025-12-08 12:37:03,304] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,304] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,305] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,305] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,305] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,305] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,305] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.305 | [2025-12-08 12:37:03,305] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.306 | [2025-12-08 12:37:03,306] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.307 | [2025-12-08 12:37:03,307] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.307 | [2025-12-08 12:37:03,307] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.307 | [2025-12-08 12:37:03,307] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.307 | [2025-12-08 12:37:03,307] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.307 | [2025-12-08 12:37:03,307] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.308 | [2025-12-08 12:37:03,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.308 | [2025-12-08 12:37:03,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.308 | [2025-12-08 12:37:03,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.308 | [2025-12-08 12:37:03,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.308 | [2025-12-08 12:37:03,308] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.309 | [2025-12-08 12:37:03,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.309 | [2025-12-08 12:37:03,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.309 | [2025-12-08 12:37:03,309] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,572] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 18:07:03.573 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,573] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,574] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 18:07:03.577 | [2025-12-08 12:37:03,577] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, booking-email-0, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-12-08 18:07:03.592 | [2025-12-08 12:37:03,592] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 2 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-12-08 18:07:03.798 | [2025-12-08 12:37:03,794] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:03.830 | [2025-12-08 12:37:03,826] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.107 | [2025-12-08 12:37:04,091] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.107 | [2025-12-08 12:37:04,091] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.209 | [2025-12-08 12:37:04,209] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.230 | [2025-12-08 12:37:04,230] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.350 | [2025-12-08 12:37:04,349] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.350 | [2025-12-08 12:37:04,350] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.445 | [2025-12-08 12:37:04,439] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.445 | [2025-12-08 12:37:04,440] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.538 | [2025-12-08 12:37:04,537] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.538 | [2025-12-08 12:37:04,538] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.562 | [2025-12-08 12:37:04,562] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.563 | [2025-12-08 12:37:04,563] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.579 | [2025-12-08 12:37:04,579] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.579 | [2025-12-08 12:37:04,579] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.588 | [2025-12-08 12:37:04,588] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.589 | [2025-12-08 12:37:04,588] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.607 | [2025-12-08 12:37:04,607] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.608 | [2025-12-08 12:37:04,607] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.621 | [2025-12-08 12:37:04,621] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.621 | [2025-12-08 12:37:04,621] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.631 | [2025-12-08 12:37:04,627] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.631 | [2025-12-08 12:37:04,628] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.638 | [2025-12-08 12:37:04,637] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.638 | [2025-12-08 12:37:04,638] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.648 | [2025-12-08 12:37:04,647] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.648 | [2025-12-08 12:37:04,648] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.655 | [2025-12-08 12:37:04,655] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.656 | [2025-12-08 12:37:04,655] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.692 | [2025-12-08 12:37:04,691] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.692 | [2025-12-08 12:37:04,692] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.709 | [2025-12-08 12:37:04,709] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.709 | [2025-12-08 12:37:04,709] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.719 | [2025-12-08 12:37:04,718] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.719 | [2025-12-08 12:37:04,719] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.731 | [2025-12-08 12:37:04,731] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.731 | [2025-12-08 12:37:04,731] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.778 | [2025-12-08 12:37:04,768] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.778 | [2025-12-08 12:37:04,768] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.853 | [2025-12-08 12:37:04,853] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.853 | [2025-12-08 12:37:04,853] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.868 | [2025-12-08 12:37:04,868] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.869 | [2025-12-08 12:37:04,868] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.882 | [2025-12-08 12:37:04,882] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.883 | [2025-12-08 12:37:04,882] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.891 | [2025-12-08 12:37:04,890] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.891 | [2025-12-08 12:37:04,891] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.908 | [2025-12-08 12:37:04,908] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.908 | [2025-12-08 12:37:04,908] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.918 | [2025-12-08 12:37:04,917] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.918 | [2025-12-08 12:37:04,918] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.924 | [2025-12-08 12:37:04,924] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.924 | [2025-12-08 12:37:04,924] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.932 | [2025-12-08 12:37:04,931] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.932 | [2025-12-08 12:37:04,932] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.939 | [2025-12-08 12:37:04,938] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.939 | [2025-12-08 12:37:04,939] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.952 | [2025-12-08 12:37:04,952] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.952 | [2025-12-08 12:37:04,952] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.967 | [2025-12-08 12:37:04,967] INFO [Partition booking-email-0 broker=1] Log loaded for partition booking-email-0 with initial high watermark 1 (kafka.cluster.Partition)
2025-12-08 18:07:04.967 | [2025-12-08 12:37:04,967] INFO [Broker id=1] Leader booking-email-0 with topic id Some(ZZs51CcXT3m5RospnghyvA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.968 | [2025-12-08 12:37:04,967] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.968 | [2025-12-08 12:37:04,968] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.976 | [2025-12-08 12:37:04,976] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.976 | [2025-12-08 12:37:04,976] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.983 | [2025-12-08 12:37:04,983] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.983 | [2025-12-08 12:37:04,983] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.990 | [2025-12-08 12:37:04,990] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 4 (kafka.cluster.Partition)
2025-12-08 18:07:04.991 | [2025-12-08 12:37:04,990] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 4 with partition epoch 0, high watermark 4, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.991 | [2025-12-08 12:37:04,990] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.991 | [2025-12-08 12:37:04,991] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:04.997 | [2025-12-08 12:37:04,997] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:04.997 | [2025-12-08 12:37:04,997] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.004 | [2025-12-08 12:37:05,004] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.004 | [2025-12-08 12:37:05,004] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.014 | [2025-12-08 12:37:05,013] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.014 | [2025-12-08 12:37:05,014] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.027 | [2025-12-08 12:37:05,025] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.027 | [2025-12-08 12:37:05,026] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.037 | [2025-12-08 12:37:05,036] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.037 | [2025-12-08 12:37:05,037] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.061 | [2025-12-08 12:37:05,060] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.061 | [2025-12-08 12:37:05,060] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.076 | [2025-12-08 12:37:05,074] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.076 | [2025-12-08 12:37:05,075] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.083 | [2025-12-08 12:37:05,083] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.086 | [2025-12-08 12:37:05,086] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.115 | [2025-12-08 12:37:05,114] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.123 | [2025-12-08 12:37:05,121] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.165 | [2025-12-08 12:37:05,157] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.165 | [2025-12-08 12:37:05,158] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.174 | [2025-12-08 12:37:05,173] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.174 | [2025-12-08 12:37:05,173] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.206 | [2025-12-08 12:37:05,205] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.222 | [2025-12-08 12:37:05,221] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.255 | [2025-12-08 12:37:05,252] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.255 | [2025-12-08 12:37:05,252] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.291 | [2025-12-08 12:37:05,288] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.292 | [2025-12-08 12:37:05,289] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.324 | [2025-12-08 12:37:05,322] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 18:07:05.324 | [2025-12-08 12:37:05,322] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 18:07:05.412 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,412] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 18:07:05.413 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,413] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 18:07:05.414 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,415] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,415] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,415] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,415] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,415] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 18:07:05.415 | [2025-12-08 12:37:05,415] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 18:07:05.468 | [2025-12-08 12:37:05,429] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.471 | [2025-12-08 12:37:05,470] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.523 | [2025-12-08 12:37:05,522] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.523 | [2025-12-08 12:37:05,523] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.523 | [2025-12-08 12:37:05,523] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.523 | [2025-12-08 12:37:05,523] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,523] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,523] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,523] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,523] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.524 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,524] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,524] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.525 | [2025-12-08 12:37:05,525] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.526 | [2025-12-08 12:37:05,525] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.526 | [2025-12-08 12:37:05,526] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.528 | [2025-12-08 12:37:05,527] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,559] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,560] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,561] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,561] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,561] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,532] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 59 milliseconds for epoch 0, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,562] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 39 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,562] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,562] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,562] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,563] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,563] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.563 | [2025-12-08 12:37:05,563] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 39 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.564 | [2025-12-08 12:37:05,564] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 40 milliseconds for epoch 0, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.564 | [2025-12-08 12:37:05,564] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 40 milliseconds for epoch 0, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.564 | [2025-12-08 12:37:05,564] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 40 milliseconds for epoch 0, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.582 | [2025-12-08 12:37:05,581] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 57 milliseconds for epoch 0, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.583 | [2025-12-08 12:37:05,583] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 59 milliseconds for epoch 0, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,562] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.584 | [2025-12-08 12:37:05,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.585 | [2025-12-08 12:37:05,585] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.586 | [2025-12-08 12:37:05,585] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.618 | [2025-12-08 12:37:05,618] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 93 milliseconds for epoch 0, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.619 | [2025-12-08 12:37:05,619] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 95 milliseconds for epoch 0, of which 95 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.619 | [2025-12-08 12:37:05,619] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 95 milliseconds for epoch 0, of which 95 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.622 | [2025-12-08 12:37:05,621] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 97 milliseconds for epoch 0, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.622 | [2025-12-08 12:37:05,622] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 97 milliseconds for epoch 0, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.622 | [2025-12-08 12:37:05,622] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 97 milliseconds for epoch 0, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.623 | [2025-12-08 12:37:05,622] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 97 milliseconds for epoch 0, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.623 | [2025-12-08 12:37:05,623] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 98 milliseconds for epoch 0, of which 98 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.624 | [2025-12-08 12:37:05,623] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 98 milliseconds for epoch 0, of which 98 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.624 | [2025-12-08 12:37:05,624] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 99 milliseconds for epoch 0, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.624 | [2025-12-08 12:37:05,624] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 99 milliseconds for epoch 0, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.625 | [2025-12-08 12:37:05,625] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 100 milliseconds for epoch 0, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.625 | [2025-12-08 12:37:05,625] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 99 milliseconds for epoch 0, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.627 | [2025-12-08 12:37:05,627] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 67 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.629 | [2025-12-08 12:37:05,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 69 milliseconds for epoch 0, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.634 | [2025-12-08 12:37:05,634] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 74 milliseconds for epoch 0, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.635 | [2025-12-08 12:37:05,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 75 milliseconds for epoch 0, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.635 | [2025-12-08 12:37:05,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 75 milliseconds for epoch 0, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.635 | [2025-12-08 12:37:05,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 75 milliseconds for epoch 0, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.636 | [2025-12-08 12:37:05,635] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 75 milliseconds for epoch 0, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.637 | [2025-12-08 12:37:05,628] INFO [Broker id=1] Finished LeaderAndIsr request in 2303ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-12-08 18:07:05.661 | [2025-12-08 12:37:05,661] TRACE [Controller id=1 epoch=2] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=s1of94BtTGS8K-UMhA2LCA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=ZZs51CcXT3m5RospnghyvA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 18:07:05.681 | [2025-12-08 12:37:05,681] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition booking-email-0 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.681 | [2025-12-08 12:37:05,681] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.682 | [2025-12-08 12:37:05,681] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.682 | [2025-12-08 12:37:05,682] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.682 | [2025-12-08 12:37:05,682] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.682 | [2025-12-08 12:37:05,682] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.688 | [2025-12-08 12:37:05,687] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.688 | [2025-12-08 12:37:05,688] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.688 | [2025-12-08 12:37:05,688] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.688 | [2025-12-08 12:37:05,688] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,688] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.689 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.690 | [2025-12-08 12:37:05,689] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.690 | [2025-12-08 12:37:05,690] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.690 | [2025-12-08 12:37:05,690] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.691 | [2025-12-08 12:37:05,691] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.691 | [2025-12-08 12:37:05,691] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.692 | [2025-12-08 12:37:05,692] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.692 | [2025-12-08 12:37:05,692] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.692 | [2025-12-08 12:37:05,692] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.693 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.693 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.693 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.693 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.693 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.693 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,693] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,694] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,694] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,694] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,694] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,694] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.694 | [2025-12-08 12:37:05,694] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.695 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.696 | [2025-12-08 12:37:05,695] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.696 | [2025-12-08 12:37:05,696] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.696 | [2025-12-08 12:37:05,696] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.696 | [2025-12-08 12:37:05,696] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.696 | [2025-12-08 12:37:05,696] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.733 | [2025-12-08 12:37:05,732] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
2025-12-08 18:07:05.735 | [2025-12-08 12:37:05,734] TRACE [Controller id=1 epoch=2] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 18:07:05.797 | [2025-12-08 12:37:05,797] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-12-08 18:07:05.840 | [2025-12-08 12:37:05,840] INFO [GroupCoordinator 1]: Loading group metadata for email-group with generation 2 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:05.841 | [2025-12-08 12:37:05,840] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 280 milliseconds for epoch 0, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.841 | [2025-12-08 12:37:05,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 281 milliseconds for epoch 0, of which 281 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.841 | [2025-12-08 12:37:05,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 280 milliseconds for epoch 0, of which 280 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.841 | [2025-12-08 12:37:05,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 280 milliseconds for epoch 0, of which 280 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.842 | [2025-12-08 12:37:05,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 257 milliseconds for epoch 0, of which 257 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.842 | [2025-12-08 12:37:05,842] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 258 milliseconds for epoch 0, of which 258 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.842 | [2025-12-08 12:37:05,842] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 258 milliseconds for epoch 0, of which 258 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.842 | [2025-12-08 12:37:05,842] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 258 milliseconds for epoch 0, of which 258 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.849 | [2025-12-08 12:37:05,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 265 milliseconds for epoch 0, of which 264 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.850 | [2025-12-08 12:37:05,850] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 266 milliseconds for epoch 0, of which 265 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.851 | [2025-12-08 12:37:05,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 266 milliseconds for epoch 0, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.853 | [2025-12-08 12:37:05,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 268 milliseconds for epoch 0, of which 268 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.854 | [2025-12-08 12:37:05,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 268 milliseconds for epoch 0, of which 268 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.854 | [2025-12-08 12:37:05,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 269 milliseconds for epoch 0, of which 269 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.854 | [2025-12-08 12:37:05,854] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 269 milliseconds for epoch 0, of which 269 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.856 | [2025-12-08 12:37:05,856] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 271 milliseconds for epoch 0, of which 269 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:05.857 | [2025-12-08 12:37:05,857] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 272 milliseconds for epoch 0, of which 271 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 18:07:07.736 | [2025-12-08 12:37:07,733] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 18:07:07.736 | [2025-12-08 12:37:07,734] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 18:07:07.750 | [2025-12-08 12:37:07,748] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 18:07:07.752 | [2025-12-08 12:37:07,751] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 18:07:13.065 | [2025-12-08 12:37:13,065] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Empty state. Created a new member id consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:13.085 | [2025-12-08 12:37:13,085] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 2 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:16.093 | [2025-12-08 12:37:16,093] INFO [GroupCoordinator 1]: Stabilized group email-group generation 3 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:07:16.126 | [2025-12-08 12:37:16,125] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854 for group email-group for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:12:07.724 | [2025-12-08 12:42:07,724] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 18:12:07.724 | [2025-12-08 12:42:07,724] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 18:12:07.726 | [2025-12-08 12:42:07,726] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 18:12:07.726 | [2025-12-08 12:42:07,726] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 18:13:35.472 | [2025-12-08 12:43:35,472] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 3 (__consumer_offsets-8) (reason: Removing member consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:13:35.474 | [2025-12-08 12:43:35,474] INFO [GroupCoordinator 1]: Group email-group with generation 4 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:13:35.485 | [2025-12-08 12:43:35,484] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.7, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:13:39.847 | [2025-12-08 12:43:39,846] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-08 18:13:39.851 | [2025-12-08 12:43:39,850] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-12-08 18:13:39.852 | [2025-12-08 12:43:39,852] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-12-08 18:13:39.876 | [2025-12-08 12:43:39,875] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-12-08 18:13:39.876 | [2025-12-08 12:43:39,876] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-12-08 18:13:39.877 | [2025-12-08 12:43:39,876] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-12-08 18:13:39.883 | [2025-12-08 12:43:39,883] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 18:13:39.886 | [2025-12-08 12:43:39,885] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),booking-email-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-12-08 18:13:39.889 | [2025-12-08 12:43:39,889] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
2025-12-08 18:13:39.899 | [2025-12-08 12:43:39,898] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 18:13:39.900 | [2025-12-08 12:43:39,900] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 18:13:39.901 | [2025-12-08 12:43:39,900] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 18:13:39.902 | [2025-12-08 12:43:39,902] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-12-08 18:13:39.923 | [2025-12-08 12:43:39,923] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-12-08 18:13:39.924 | [2025-12-08 12:43:39,924] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-12-08 18:13:39.929 | [2025-12-08 12:43:39,929] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-12-08 18:13:39.937 | [2025-12-08 12:43:39,936] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.939 | [2025-12-08 12:43:39,939] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.939 | [2025-12-08 12:43:39,939] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.940 | [2025-12-08 12:43:39,940] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-12-08 18:13:39.942 | [2025-12-08 12:43:39,941] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.942 | [2025-12-08 12:43:39,942] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.942 | [2025-12-08 12:43:39,942] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.948 | [2025-12-08 12:43:39,947] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 18:13:39.950 | [2025-12-08 12:43:39,949] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-12-08 18:13:39.950 | [2025-12-08 12:43:39,950] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 18:13:39.950 | [2025-12-08 12:43:39,950] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 18:13:39.950 | [2025-12-08 12:43:39,950] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 18:13:39.952 | [2025-12-08 12:43:39,952] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 18:13:39.952 | [2025-12-08 12:43:39,952] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:13:39.954 | [2025-12-08 12:43:39,953] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.955 | [2025-12-08 12:43:39,954] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.955 | [2025-12-08 12:43:39,954] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.955 | [2025-12-08 12:43:39,955] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.956 | [2025-12-08 12:43:39,956] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.956 | [2025-12-08 12:43:39,956] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.957 | [2025-12-08 12:43:39,957] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 18:13:39.958 | [2025-12-08 12:43:39,958] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-12-08 18:13:39.959 | [2025-12-08 12:43:39,958] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 18:13:39.960 | [2025-12-08 12:43:39,960] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 18:13:39.960 | [2025-12-08 12:43:39,960] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 18:13:39.961 | [2025-12-08 12:43:39,960] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-12-08 18:13:39.964 | [2025-12-08 12:43:39,964] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-12-08 18:13:39.965 | [2025-12-08 12:43:39,965] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-12-08 18:13:39.966 | [2025-12-08 12:43:39,965] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-12-08 18:13:39.966 | [2025-12-08 12:43:39,966] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.966 | [2025-12-08 12:43:39,966] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.966 | [2025-12-08 12:43:39,966] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.967 | [2025-12-08 12:43:39,966] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.968 | [2025-12-08 12:43:39,968] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.968 | [2025-12-08 12:43:39,968] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.969 | [2025-12-08 12:43:39,969] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.970 | [2025-12-08 12:43:39,970] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.970 | [2025-12-08 12:43:39,970] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.971 | [2025-12-08 12:43:39,971] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.972 | [2025-12-08 12:43:39,972] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.972 | [2025-12-08 12:43:39,972] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 18:13:39.986 | [2025-12-08 12:43:39,986] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-12-08 18:13:39.987 | [2025-12-08 12:43:39,987] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:13:39.987 | [2025-12-08 12:43:39,987] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:13:39.987 | [2025-12-08 12:43:39,987] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:13:39.993 | [2025-12-08 12:43:39,992] INFO Broker to controller channel manager for alterPartition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-12-08 18:13:39.993 | [2025-12-08 12:43:39,993] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:13:39.994 | [2025-12-08 12:43:39,993] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:13:39.994 | [2025-12-08 12:43:39,993] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-12-08 18:13:39.996 | [2025-12-08 12:43:39,996] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-12-08 18:13:39.999 | [2025-12-08 12:43:39,998] INFO Shutting down. (kafka.log.LogManager)
2025-12-08 18:13:40.002 | [2025-12-08 12:43:40,001] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-12-08 18:13:40.002 | [2025-12-08 12:43:40,002] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner)
2025-12-08 18:13:40.003 | [2025-12-08 12:43:40,002] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner)
2025-12-08 18:13:40.003 | [2025-12-08 12:43:40,002] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner)
2025-12-08 18:13:40.134 | [2025-12-08 12:43:40,134] INFO [ProducerStateManager partition=__consumer_offsets-8] Wrote producer snapshot at offset 6 with 0 producer ids in 8 ms. (kafka.log.ProducerStateManager)
2025-12-08 18:13:40.377 | [2025-12-08 12:43:40,377] INFO Shutdown complete. (kafka.log.LogManager)
2025-12-08 18:13:40.377 | [2025-12-08 12:43:40,377] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 18:13:40.378 | [2025-12-08 12:43:40,378] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 18:13:40.378 | [2025-12-08 12:43:40,378] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 18:13:40.379 | [2025-12-08 12:43:40,379] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-12-08 18:13:40.381 | [2025-12-08 12:43:40,381] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-08 18:13:40.383 | [2025-12-08 12:43:40,383] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-12-08 18:13:40.384 | [2025-12-08 12:43:40,384] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-12-08 18:13:40.386 | [2025-12-08 12:43:40,385] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-12-08 18:13:40.386 | [2025-12-08 12:43:40,386] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-12-08 18:13:40.386 | [2025-12-08 12:43:40,386] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-12-08 18:13:40.390 | [2025-12-08 12:43:40,390] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-12-08 18:13:40.391 | [2025-12-08 12:43:40,390] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 18:13:40.391 | [2025-12-08 12:43:40,391] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 18:13:40.392 | [2025-12-08 12:43:40,391] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 18:13:40.393 | [2025-12-08 12:43:40,392] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 18:13:40.510 | [2025-12-08 12:43:40,510] INFO Session: 0x1000245b2e60001 closed (org.apache.zookeeper.ZooKeeper)
2025-12-08 18:13:40.510 | [2025-12-08 12:43:40,510] INFO EventThread shut down for session: 0x1000245b2e60001 (org.apache.zookeeper.ClientCnxn)
2025-12-08 18:13:40.512 | [2025-12-08 12:43:40,512] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 18:13:40.513 | [2025-12-08 12:43:40,513] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.516 | [2025-12-08 12:43:40,516] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.516 | [2025-12-08 12:43:40,516] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.516 | [2025-12-08 12:43:40,516] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.517 | [2025-12-08 12:43:40,517] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.517 | [2025-12-08 12:43:40,517] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.517 | [2025-12-08 12:43:40,517] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.517 | [2025-12-08 12:43:40,517] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.517 | [2025-12-08 12:43:40,517] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.517 | [2025-12-08 12:43:40,517] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.518 | [2025-12-08 12:43:40,518] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.518 | [2025-12-08 12:43:40,518] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 18:13:40.519 | [2025-12-08 12:43:40,519] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
2025-12-08 18:13:40.561 | [2025-12-08 12:43:40,560] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
2025-12-08 18:13:40.562 | [2025-12-08 12:43:40,562] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
2025-12-08 18:13:40.562 | [2025-12-08 12:43:40,562] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
2025-12-08 18:13:40.565 | [2025-12-08 12:43:40,564] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
2025-12-08 18:13:40.567 | [2025-12-08 12:43:40,567] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
2025-12-08 18:13:40.569 | [2025-12-08 12:43:40,569] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 18:13:40.570 | [2025-12-08 12:43:40,570] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
2025-12-08 21:34:12.561 | ===> User
2025-12-08 21:34:12.565 | uid=0(root) gid=0(root) groups=0(root)
2025-12-08 21:34:12.565 | ===> Configuring ...
2025-12-08 21:34:12.570 | Running in Zookeeper mode...
2025-12-08 21:34:37.282 | ===> Running preflight checks ... 
2025-12-08 21:34:37.329 | ===> Check if /var/lib/kafka/data is writable ...
2025-12-08 21:34:41.702 | ===> Check if Zookeeper is healthy ...
2025-12-08 21:34:52.537 | [2025-12-08 16:04:52,511] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.537 | [2025-12-08 16:04:52,512] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,512] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,540] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,540] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,540] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-clients-7.4.0-ccs.jar:/usr/share/java/cp-base-new/kafka_2.13-7.4.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.11.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.4.0-ccs.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/kafka-raft-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.2-1.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.4.0-ccs.jar:/usr/share/java/cp-base-new/snappy-java-1.1.8.4.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/common-utils-7.4.0.jar:/usr/share/java/cp-base-new/kafka-metadata-7.4.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/logredactor-1.0.11.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/utility-belt-7.4.0.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.4.0-ccs.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.4.0.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/kafka-server-common-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/jose4j-0.7.9.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.6.0.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,540] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,540] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,540] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:os.memory.max=1932MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.554 | [2025-12-08 16:04:52,541] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.585 | [2025-12-08 16:04:52,581] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@646be2c3 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:34:52.790 | [2025-12-08 16:04:52,788] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-08 21:34:53.057 | [2025-12-08 16:04:53,056] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-08 21:34:53.250 | [2025-12-08 16:04:53,236] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:53.887 | [2025-12-08 16:04:53,883] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:53.887 | [2025-12-08 16:04:53,884] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:54.237 | [2025-12-08 16:04:54,218] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:54.237 | java.net.ConnectException: Connection refused
2025-12-08 21:34:54.237 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:34:54.237 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:34:54.237 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:34:54.237 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:34:55.356 | [2025-12-08 16:04:55,355] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:55.356 | [2025-12-08 16:04:55,356] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:55.361 | [2025-12-08 16:04:55,359] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:55.361 | java.net.ConnectException: Connection refused
2025-12-08 21:34:55.361 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:34:55.361 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:34:55.361 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:34:55.361 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:34:56.480 | [2025-12-08 16:04:56,473] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:56.480 | [2025-12-08 16:04:56,474] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:56.511 | [2025-12-08 16:04:56,475] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:56.511 | java.net.ConnectException: Connection refused
2025-12-08 21:34:56.511 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:34:56.511 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:34:56.511 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:34:56.511 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:34:57.613 | [2025-12-08 16:04:57,612] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:57.614 | [2025-12-08 16:04:57,613] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:57.615 | [2025-12-08 16:04:57,614] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:57.615 | java.net.ConnectException: Connection refused
2025-12-08 21:34:57.615 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:34:57.615 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:34:57.615 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:34:57.615 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:34:58.723 | [2025-12-08 16:04:58,722] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:58.724 | [2025-12-08 16:04:58,723] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:58.725 | [2025-12-08 16:04:58,724] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:58.725 | java.net.ConnectException: Connection refused
2025-12-08 21:34:58.725 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:34:58.725 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:34:58.725 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:34:58.725 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:34:59.867 | [2025-12-08 16:04:59,866] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:59.868 | [2025-12-08 16:04:59,868] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:59.870 | [2025-12-08 16:04:59,869] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:34:59.870 | java.net.ConnectException: Connection refused
2025-12-08 21:34:59.870 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:34:59.870 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:34:59.870 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:34:59.870 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:35:00.979 | [2025-12-08 16:05:00,977] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:00.979 | [2025-12-08 16:05:00,977] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:00.997 | [2025-12-08 16:05:00,996] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:00.997 | java.net.ConnectException: Connection refused
2025-12-08 21:35:00.997 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:35:00.997 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:35:00.997 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:35:00.997 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:35:02.120 | [2025-12-08 16:05:02,119] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:02.120 | [2025-12-08 16:05:02,119] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:02.126 | [2025-12-08 16:05:02,121] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:02.127 | java.net.ConnectException: Connection refused
2025-12-08 21:35:02.127 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-08 21:35:02.127 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-08 21:35:02.127 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-08 21:35:02.127 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:35:03.233 | [2025-12-08 16:05:03,232] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:03.233 | [2025-12-08 16:05:03,232] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:03.234 | [2025-12-08 16:05:03,233] INFO Socket connection established, initiating session, client: /172.18.0.4:48892, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:03.635 | [2025-12-08 16:05:03,634] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:03.635 | EndOfStreamException: Unable to read additional data from server sessionid 0x0, likely server has closed socket
2025-12-08 21:35:03.635 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-08 21:35:03.635 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-08 21:35:03.635 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:35:05.128 | [2025-12-08 16:05:05,127] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:05.129 | [2025-12-08 16:05:05,128] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:05.130 | [2025-12-08 16:05:05,129] INFO Socket connection established, initiating session, client: /172.18.0.4:48894, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:05.267 | [2025-12-08 16:05:05,266] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x10003048fc10000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:05.356 | [2025-12-08 16:05:05,355] WARN An exception was thrown while closing send thread for session 0x10003048fc10000. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:05.356 | EndOfStreamException: Unable to read additional data from server sessionid 0x10003048fc10000, likely server has closed socket
2025-12-08 21:35:05.356 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-08 21:35:05.356 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-08 21:35:05.356 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-08 21:35:05.466 | [2025-12-08 16:05:05,466] INFO EventThread shut down for session: 0x10003048fc10000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:05.467 | [2025-12-08 16:05:05,466] INFO Session: 0x10003048fc10000 closed (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:05.526 | Using log4j config /etc/kafka/log4j.properties
2025-12-08 21:35:06.049 | ===> Launching ... 
2025-12-08 21:35:06.096 | ===> Launching kafka ... 
2025-12-08 21:35:16.699 | [2025-12-08 16:05:16,695] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-12-08 21:35:22.552 | [2025-12-08 16:05:22,552] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-08 21:35:24.244 | [2025-12-08 16:05:24,239] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-08 21:35:24.261 | [2025-12-08 16:05:24,261] INFO starting (kafka.server.KafkaServer)
2025-12-08 21:35:24.271 | [2025-12-08 16:05:24,270] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-12-08 21:35:24.597 | [2025-12-08 16:05:24,586] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 21:35:24.707 | [2025-12-08 16:05:24,707] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.707 | [2025-12-08 16:05:24,707] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.707 | [2025-12-08 16:05:24,707] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.708 | [2025-12-08 16:05:24,708] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.708 | [2025-12-08 16:05:24,708] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.710 | [2025-12-08 16:05:24,708] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.711 | [2025-12-08 16:05:24,710] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.711 | [2025-12-08 16:05:24,711] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.711 | [2025-12-08 16:05:24,711] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.711 | [2025-12-08 16:05:24,711] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.711 | [2025-12-08 16:05:24,711] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.712 | [2025-12-08 16:05:24,712] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.712 | [2025-12-08 16:05:24,712] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.712 | [2025-12-08 16:05:24,712] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.712 | [2025-12-08 16:05:24,712] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.712 | [2025-12-08 16:05:24,712] INFO Client environment:os.memory.free=1008MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.713 | [2025-12-08 16:05:24,713] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.713 | [2025-12-08 16:05:24,713] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.760 | [2025-12-08 16:05:24,759] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3ed242a4 (org.apache.zookeeper.ZooKeeper)
2025-12-08 21:35:24.815 | [2025-12-08 16:05:24,815] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-08 21:35:24.922 | [2025-12-08 16:05:24,921] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:24.943 | [2025-12-08 16:05:24,943] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 21:35:24.978 | [2025-12-08 16:05:24,977] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:25.020 | [2025-12-08 16:05:25,019] INFO Socket connection established, initiating session, client: /172.18.0.4:51922, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:25.177 | [2025-12-08 16:05:25,177] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x10003048fc10001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-12-08 21:35:25.238 | [2025-12-08 16:05:25,237] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-08 21:35:29.319 | [2025-12-08 16:05:29,318] INFO Cluster ID = xTa4oP5DQQqhwOcnPmb7dg (kafka.server.KafkaServer)
2025-12-08 21:35:29.888 | [2025-12-08 16:05:29,883] INFO KafkaConfig values: 
2025-12-08 21:35:29.888 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-12-08 21:35:29.888 | 	alter.config.policy.class.name = null
2025-12-08 21:35:29.888 | 	alter.log.dirs.replication.quota.window.num = 11
2025-12-08 21:35:29.888 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-12-08 21:35:29.888 | 	authorizer.class.name = 
2025-12-08 21:35:29.888 | 	auto.create.topics.enable = true
2025-12-08 21:35:29.888 | 	auto.include.jmx.reporter = true
2025-12-08 21:35:29.888 | 	auto.leader.rebalance.enable = true
2025-12-08 21:35:29.888 | 	background.threads = 10
2025-12-08 21:35:29.888 | 	broker.heartbeat.interval.ms = 2000
2025-12-08 21:35:29.888 | 	broker.id = 1
2025-12-08 21:35:29.888 | 	broker.id.generation.enable = true
2025-12-08 21:35:29.888 | 	broker.rack = null
2025-12-08 21:35:29.888 | 	broker.session.timeout.ms = 9000
2025-12-08 21:35:29.888 | 	client.quota.callback.class = null
2025-12-08 21:35:29.888 | 	compression.type = producer
2025-12-08 21:35:29.888 | 	connection.failed.authentication.delay.ms = 100
2025-12-08 21:35:29.888 | 	connections.max.idle.ms = 600000
2025-12-08 21:35:29.888 | 	connections.max.reauth.ms = 0
2025-12-08 21:35:29.888 | 	control.plane.listener.name = null
2025-12-08 21:35:29.888 | 	controlled.shutdown.enable = true
2025-12-08 21:35:29.888 | 	controlled.shutdown.max.retries = 3
2025-12-08 21:35:29.888 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-12-08 21:35:29.888 | 	controller.listener.names = null
2025-12-08 21:35:29.888 | 	controller.quorum.append.linger.ms = 25
2025-12-08 21:35:29.888 | 	controller.quorum.election.backoff.max.ms = 1000
2025-12-08 21:35:29.888 | 	controller.quorum.election.timeout.ms = 1000
2025-12-08 21:35:29.888 | 	controller.quorum.fetch.timeout.ms = 2000
2025-12-08 21:35:29.888 | 	controller.quorum.request.timeout.ms = 2000
2025-12-08 21:35:29.888 | 	controller.quorum.retry.backoff.ms = 20
2025-12-08 21:35:29.888 | 	controller.quorum.voters = []
2025-12-08 21:35:29.888 | 	controller.quota.window.num = 11
2025-12-08 21:35:29.888 | 	controller.quota.window.size.seconds = 1
2025-12-08 21:35:29.888 | 	controller.socket.timeout.ms = 30000
2025-12-08 21:35:29.888 | 	create.topic.policy.class.name = null
2025-12-08 21:35:29.888 | 	default.replication.factor = 1
2025-12-08 21:35:29.888 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-12-08 21:35:29.888 | 	delegation.token.expiry.time.ms = 86400000
2025-12-08 21:35:29.888 | 	delegation.token.master.key = null
2025-12-08 21:35:29.888 | 	delegation.token.max.lifetime.ms = 604800000
2025-12-08 21:35:29.888 | 	delegation.token.secret.key = null
2025-12-08 21:35:29.888 | 	delete.records.purgatory.purge.interval.requests = 1
2025-12-08 21:35:29.888 | 	delete.topic.enable = true
2025-12-08 21:35:29.888 | 	early.start.listeners = null
2025-12-08 21:35:29.888 | 	fetch.max.bytes = 57671680
2025-12-08 21:35:29.888 | 	fetch.purgatory.purge.interval.requests = 1000
2025-12-08 21:35:29.888 | 	group.initial.rebalance.delay.ms = 3000
2025-12-08 21:35:29.888 | 	group.max.session.timeout.ms = 1800000
2025-12-08 21:35:29.888 | 	group.max.size = 2147483647
2025-12-08 21:35:29.888 | 	group.min.session.timeout.ms = 6000
2025-12-08 21:35:29.888 | 	initial.broker.registration.timeout.ms = 60000
2025-12-08 21:35:29.888 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-12-08 21:35:29.888 | 	inter.broker.protocol.version = 3.4-IV0
2025-12-08 21:35:29.888 | 	kafka.metrics.polling.interval.secs = 10
2025-12-08 21:35:29.888 | 	kafka.metrics.reporters = []
2025-12-08 21:35:29.888 | 	leader.imbalance.check.interval.seconds = 300
2025-12-08 21:35:29.888 | 	leader.imbalance.per.broker.percentage = 10
2025-12-08 21:35:29.888 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-12-08 21:35:29.888 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-12-08 21:35:29.888 | 	log.cleaner.backoff.ms = 15000
2025-12-08 21:35:29.888 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-12-08 21:35:29.888 | 	log.cleaner.delete.retention.ms = 86400000
2025-12-08 21:35:29.888 | 	log.cleaner.enable = true
2025-12-08 21:35:29.888 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-12-08 21:35:29.888 | 	log.cleaner.io.buffer.size = 524288
2025-12-08 21:35:29.888 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-12-08 21:35:29.888 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-12-08 21:35:29.888 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-12-08 21:35:29.888 | 	log.cleaner.min.compaction.lag.ms = 0
2025-12-08 21:35:29.888 | 	log.cleaner.threads = 1
2025-12-08 21:35:29.888 | 	log.cleanup.policy = [delete]
2025-12-08 21:35:29.889 | 	log.dir = /tmp/kafka-logs
2025-12-08 21:35:29.889 | 	log.dirs = /var/lib/kafka/data
2025-12-08 21:35:29.889 | 	log.flush.interval.messages = 9223372036854775807
2025-12-08 21:35:29.889 | 	log.flush.interval.ms = null
2025-12-08 21:35:29.889 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-12-08 21:35:29.889 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-12-08 21:35:29.889 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-12-08 21:35:29.889 | 	log.index.interval.bytes = 4096
2025-12-08 21:35:29.889 | 	log.index.size.max.bytes = 10485760
2025-12-08 21:35:29.889 | 	log.message.downconversion.enable = true
2025-12-08 21:35:29.889 | 	log.message.format.version = 3.0-IV1
2025-12-08 21:35:29.889 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-12-08 21:35:29.889 | 	log.message.timestamp.type = CreateTime
2025-12-08 21:35:29.889 | 	log.preallocate = false
2025-12-08 21:35:29.889 | 	log.retention.bytes = -1
2025-12-08 21:35:29.889 | 	log.retention.check.interval.ms = 300000
2025-12-08 21:35:29.889 | 	log.retention.hours = 168
2025-12-08 21:35:29.889 | 	log.retention.minutes = null
2025-12-08 21:35:29.889 | 	log.retention.ms = null
2025-12-08 21:35:29.889 | 	log.roll.hours = 168
2025-12-08 21:35:29.889 | 	log.roll.jitter.hours = 0
2025-12-08 21:35:29.889 | 	log.roll.jitter.ms = null
2025-12-08 21:35:29.889 | 	log.roll.ms = null
2025-12-08 21:35:29.889 | 	log.segment.bytes = 1073741824
2025-12-08 21:35:29.889 | 	log.segment.delete.delay.ms = 60000
2025-12-08 21:35:29.889 | 	max.connection.creation.rate = 2147483647
2025-12-08 21:35:29.889 | 	max.connections = 2147483647
2025-12-08 21:35:29.889 | 	max.connections.per.ip = 2147483647
2025-12-08 21:35:29.889 | 	max.connections.per.ip.overrides = 
2025-12-08 21:35:29.889 | 	max.incremental.fetch.session.cache.slots = 1000
2025-12-08 21:35:29.889 | 	message.max.bytes = 1048588
2025-12-08 21:35:29.889 | 	metadata.log.dir = null
2025-12-08 21:35:29.889 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-12-08 21:35:29.889 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-12-08 21:35:29.889 | 	metadata.log.segment.bytes = 1073741824
2025-12-08 21:35:29.889 | 	metadata.log.segment.min.bytes = 8388608
2025-12-08 21:35:29.889 | 	metadata.log.segment.ms = 604800000
2025-12-08 21:35:29.889 | 	metadata.max.idle.interval.ms = 500
2025-12-08 21:35:29.889 | 	metadata.max.retention.bytes = 104857600
2025-12-08 21:35:29.889 | 	metadata.max.retention.ms = 604800000
2025-12-08 21:35:29.889 | 	metric.reporters = []
2025-12-08 21:35:29.889 | 	metrics.num.samples = 2
2025-12-08 21:35:29.889 | 	metrics.recording.level = INFO
2025-12-08 21:35:29.889 | 	metrics.sample.window.ms = 30000
2025-12-08 21:35:29.889 | 	min.insync.replicas = 1
2025-12-08 21:35:29.889 | 	node.id = 1
2025-12-08 21:35:29.889 | 	num.io.threads = 8
2025-12-08 21:35:29.889 | 	num.network.threads = 3
2025-12-08 21:35:29.889 | 	num.partitions = 1
2025-12-08 21:35:29.889 | 	num.recovery.threads.per.data.dir = 1
2025-12-08 21:35:29.889 | 	num.replica.alter.log.dirs.threads = null
2025-12-08 21:35:29.889 | 	num.replica.fetchers = 1
2025-12-08 21:35:29.889 | 	offset.metadata.max.bytes = 4096
2025-12-08 21:35:29.889 | 	offsets.commit.required.acks = -1
2025-12-08 21:35:29.889 | 	offsets.commit.timeout.ms = 5000
2025-12-08 21:35:29.889 | 	offsets.load.buffer.size = 5242880
2025-12-08 21:35:29.889 | 	offsets.retention.check.interval.ms = 600000
2025-12-08 21:35:29.889 | 	offsets.retention.minutes = 10080
2025-12-08 21:35:29.889 | 	offsets.topic.compression.codec = 0
2025-12-08 21:35:29.889 | 	offsets.topic.num.partitions = 50
2025-12-08 21:35:29.889 | 	offsets.topic.replication.factor = 1
2025-12-08 21:35:29.889 | 	offsets.topic.segment.bytes = 104857600
2025-12-08 21:35:29.889 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-12-08 21:35:29.889 | 	password.encoder.iterations = 4096
2025-12-08 21:35:29.889 | 	password.encoder.key.length = 128
2025-12-08 21:35:29.889 | 	password.encoder.keyfactory.algorithm = null
2025-12-08 21:35:29.889 | 	password.encoder.old.secret = null
2025-12-08 21:35:29.889 | 	password.encoder.secret = null
2025-12-08 21:35:29.889 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-12-08 21:35:29.889 | 	process.roles = []
2025-12-08 21:35:29.889 | 	producer.id.expiration.check.interval.ms = 600000
2025-12-08 21:35:29.889 | 	producer.id.expiration.ms = 86400000
2025-12-08 21:35:29.889 | 	producer.purgatory.purge.interval.requests = 1000
2025-12-08 21:35:29.889 | 	queued.max.request.bytes = -1
2025-12-08 21:35:29.889 | 	queued.max.requests = 500
2025-12-08 21:35:29.889 | 	quota.window.num = 11
2025-12-08 21:35:29.889 | 	quota.window.size.seconds = 1
2025-12-08 21:35:29.889 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-12-08 21:35:29.889 | 	remote.log.manager.task.interval.ms = 30000
2025-12-08 21:35:29.889 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-12-08 21:35:29.889 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-12-08 21:35:29.889 | 	remote.log.manager.task.retry.jitter = 0.2
2025-12-08 21:35:29.889 | 	remote.log.manager.thread.pool.size = 10
2025-12-08 21:35:29.889 | 	remote.log.metadata.manager.class.name = null
2025-12-08 21:35:29.889 | 	remote.log.metadata.manager.class.path = null
2025-12-08 21:35:29.889 | 	remote.log.metadata.manager.impl.prefix = null
2025-12-08 21:35:29.889 | 	remote.log.metadata.manager.listener.name = null
2025-12-08 21:35:29.889 | 	remote.log.reader.max.pending.tasks = 100
2025-12-08 21:35:29.889 | 	remote.log.reader.threads = 10
2025-12-08 21:35:29.889 | 	remote.log.storage.manager.class.name = null
2025-12-08 21:35:29.889 | 	remote.log.storage.manager.class.path = null
2025-12-08 21:35:29.889 | 	remote.log.storage.manager.impl.prefix = null
2025-12-08 21:35:29.889 | 	remote.log.storage.system.enable = false
2025-12-08 21:35:29.889 | 	replica.fetch.backoff.ms = 1000
2025-12-08 21:35:29.889 | 	replica.fetch.max.bytes = 1048576
2025-12-08 21:35:29.889 | 	replica.fetch.min.bytes = 1
2025-12-08 21:35:29.889 | 	replica.fetch.response.max.bytes = 10485760
2025-12-08 21:35:29.889 | 	replica.fetch.wait.max.ms = 500
2025-12-08 21:35:29.889 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-12-08 21:35:29.889 | 	replica.lag.time.max.ms = 30000
2025-12-08 21:35:29.889 | 	replica.selector.class = null
2025-12-08 21:35:29.889 | 	replica.socket.receive.buffer.bytes = 65536
2025-12-08 21:35:29.889 | 	replica.socket.timeout.ms = 30000
2025-12-08 21:35:29.889 | 	replication.quota.window.num = 11
2025-12-08 21:35:29.889 | 	replication.quota.window.size.seconds = 1
2025-12-08 21:35:29.889 | 	request.timeout.ms = 30000
2025-12-08 21:35:29.889 | 	reserved.broker.max.id = 1000
2025-12-08 21:35:29.889 | 	sasl.client.callback.handler.class = null
2025-12-08 21:35:29.889 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-12-08 21:35:29.889 | 	sasl.jaas.config = null
2025-12-08 21:35:29.889 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-12-08 21:35:29.889 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-12-08 21:35:29.889 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-12-08 21:35:29.889 | 	sasl.kerberos.service.name = null
2025-12-08 21:35:29.889 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-12-08 21:35:29.889 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-12-08 21:35:29.890 | 	sasl.login.callback.handler.class = null
2025-12-08 21:35:29.890 | 	sasl.login.class = null
2025-12-08 21:35:29.890 | 	sasl.login.connect.timeout.ms = null
2025-12-08 21:35:29.890 | 	sasl.login.read.timeout.ms = null
2025-12-08 21:35:29.890 | 	sasl.login.refresh.buffer.seconds = 300
2025-12-08 21:35:29.890 | 	sasl.login.refresh.min.period.seconds = 60
2025-12-08 21:35:29.890 | 	sasl.login.refresh.window.factor = 0.8
2025-12-08 21:35:29.890 | 	sasl.login.refresh.window.jitter = 0.05
2025-12-08 21:35:29.890 | 	sasl.login.retry.backoff.max.ms = 10000
2025-12-08 21:35:29.890 | 	sasl.login.retry.backoff.ms = 100
2025-12-08 21:35:29.890 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-12-08 21:35:29.890 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.expected.audience = null
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.expected.issuer = null
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.scope.claim.name = scope
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.sub.claim.name = sub
2025-12-08 21:35:29.890 | 	sasl.oauthbearer.token.endpoint.url = null
2025-12-08 21:35:29.890 | 	sasl.server.callback.handler.class = null
2025-12-08 21:35:29.890 | 	sasl.server.max.receive.size = 524288
2025-12-08 21:35:29.890 | 	security.inter.broker.protocol = PLAINTEXT
2025-12-08 21:35:29.890 | 	security.providers = null
2025-12-08 21:35:29.890 | 	socket.connection.setup.timeout.max.ms = 30000
2025-12-08 21:35:29.890 | 	socket.connection.setup.timeout.ms = 10000
2025-12-08 21:35:29.892 | 	socket.listen.backlog.size = 50
2025-12-08 21:35:29.893 | 	socket.receive.buffer.bytes = 102400
2025-12-08 21:35:29.893 | 	socket.request.max.bytes = 104857600
2025-12-08 21:35:29.893 | 	socket.send.buffer.bytes = 102400
2025-12-08 21:35:29.893 | 	ssl.cipher.suites = []
2025-12-08 21:35:29.893 | 	ssl.client.auth = none
2025-12-08 21:35:29.893 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-12-08 21:35:29.893 | 	ssl.endpoint.identification.algorithm = https
2025-12-08 21:35:29.893 | 	ssl.engine.factory.class = null
2025-12-08 21:35:29.893 | 	ssl.key.password = null
2025-12-08 21:35:29.893 | 	ssl.keymanager.algorithm = SunX509
2025-12-08 21:35:29.893 | 	ssl.keystore.certificate.chain = null
2025-12-08 21:35:29.893 | 	ssl.keystore.key = null
2025-12-08 21:35:29.893 | 	ssl.keystore.location = null
2025-12-08 21:35:29.893 | 	ssl.keystore.password = null
2025-12-08 21:35:29.893 | 	ssl.keystore.type = JKS
2025-12-08 21:35:29.893 | 	ssl.principal.mapping.rules = DEFAULT
2025-12-08 21:35:29.893 | 	ssl.protocol = TLSv1.3
2025-12-08 21:35:29.893 | 	ssl.provider = null
2025-12-08 21:35:29.893 | 	ssl.secure.random.implementation = null
2025-12-08 21:35:29.893 | 	ssl.trustmanager.algorithm = PKIX
2025-12-08 21:35:29.893 | 	ssl.truststore.certificates = null
2025-12-08 21:35:29.893 | 	ssl.truststore.location = null
2025-12-08 21:35:29.893 | 	ssl.truststore.password = null
2025-12-08 21:35:29.893 | 	ssl.truststore.type = JKS
2025-12-08 21:35:29.893 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-12-08 21:35:29.893 | 	transaction.max.timeout.ms = 900000
2025-12-08 21:35:29.893 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-12-08 21:35:29.893 | 	transaction.state.log.load.buffer.size = 5242880
2025-12-08 21:35:29.893 | 	transaction.state.log.min.isr = 1
2025-12-08 21:35:29.893 | 	transaction.state.log.num.partitions = 50
2025-12-08 21:35:29.893 | 	transaction.state.log.replication.factor = 1
2025-12-08 21:35:29.893 | 	transaction.state.log.segment.bytes = 104857600
2025-12-08 21:35:29.893 | 	transactional.id.expiration.ms = 604800000
2025-12-08 21:35:29.893 | 	unclean.leader.election.enable = false
2025-12-08 21:35:29.893 | 	zookeeper.clientCnxnSocket = null
2025-12-08 21:35:29.893 | 	zookeeper.connect = zookeeper:2181
2025-12-08 21:35:29.893 | 	zookeeper.connection.timeout.ms = null
2025-12-08 21:35:29.893 | 	zookeeper.max.in.flight.requests = 10
2025-12-08 21:35:29.893 | 	zookeeper.metadata.migration.enable = false
2025-12-08 21:35:29.893 | 	zookeeper.session.timeout.ms = 18000
2025-12-08 21:35:29.893 | 	zookeeper.set.acl = false
2025-12-08 21:35:29.893 | 	zookeeper.ssl.cipher.suites = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.client.enable = false
2025-12-08 21:35:29.894 | 	zookeeper.ssl.crl.enable = false
2025-12-08 21:35:29.894 | 	zookeeper.ssl.enabled.protocols = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-12-08 21:35:29.894 | 	zookeeper.ssl.keystore.location = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.keystore.password = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.keystore.type = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.ocsp.enable = false
2025-12-08 21:35:29.894 | 	zookeeper.ssl.protocol = TLSv1.2
2025-12-08 21:35:29.894 | 	zookeeper.ssl.truststore.location = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.truststore.password = null
2025-12-08 21:35:29.894 | 	zookeeper.ssl.truststore.type = null
2025-12-08 21:35:29.894 |  (kafka.server.KafkaConfig)
2025-12-08 21:35:30.659 | [2025-12-08 16:05:30,659] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 21:35:30.667 | [2025-12-08 16:05:30,662] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 21:35:30.667 | [2025-12-08 16:05:30,665] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 21:35:30.752 | [2025-12-08 16:05:30,748] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-08 21:35:31.367 | [2025-12-08 16:05:31,366] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:31.388 | [2025-12-08 16:05:31,388] INFO Skipping recovery for all logs in /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-12-08 21:35:33.388 | [2025-12-08 16:05:33,387] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:33.631 | [2025-12-08 16:05:33,616] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 2039ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:33.698 | [2025-12-08 16:05:33,697] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:33.729 | [2025-12-08 16:05:33,729] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 98ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:33.787 | [2025-12-08 16:05:33,787] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:33.801 | [2025-12-08 16:05:33,801] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 68ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:33.877 | [2025-12-08 16:05:33,877] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:33.891 | [2025-12-08 16:05:33,890] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 88ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:33.927 | [2025-12-08 16:05:33,927] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:33.994 | [2025-12-08 16:05:33,994] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 99ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.122 | [2025-12-08 16:05:34,122] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.169 | [2025-12-08 16:05:34,169] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 174ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.251 | [2025-12-08 16:05:34,250] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.297 | [2025-12-08 16:05:34,290] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 120ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.366 | [2025-12-08 16:05:34,365] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.395 | [2025-12-08 16:05:34,395] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 95ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.431 | [2025-12-08 16:05:34,430] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.476 | [2025-12-08 16:05:34,475] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.519 | [2025-12-08 16:05:34,516] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.587 | [2025-12-08 16:05:34,586] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 107ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.664 | [2025-12-08 16:05:34,663] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.699 | [2025-12-08 16:05:34,698] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 109ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.757 | [2025-12-08 16:05:34,755] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.779 | [2025-12-08 16:05:34,777] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.866 | [2025-12-08 16:05:34,865] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.883 | [2025-12-08 16:05:34,882] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 104ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:34.934 | [2025-12-08 16:05:34,934] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:34.947 | [2025-12-08 16:05:34,947] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 64ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.156 | [2025-12-08 16:05:35,156] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.201 | [2025-12-08 16:05:35,181] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 227ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.248 | [2025-12-08 16:05:35,247] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.266 | [2025-12-08 16:05:35,265] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 72ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.339 | [2025-12-08 16:05:35,338] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.360 | [2025-12-08 16:05:35,360] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.476 | [2025-12-08 16:05:35,475] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.486 | [2025-12-08 16:05:35,485] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 124ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.555 | [2025-12-08 16:05:35,555] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.565 | [2025-12-08 16:05:35,565] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.631 | [2025-12-08 16:05:35,630] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.637 | [2025-12-08 16:05:35,637] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.725 | [2025-12-08 16:05:35,725] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.747 | [2025-12-08 16:05:35,747] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 109ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.798 | [2025-12-08 16:05:35,797] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.850 | [2025-12-08 16:05:35,849] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 89ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.907 | [2025-12-08 16:05:35,907] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:35.916 | [2025-12-08 16:05:35,915] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:35.975 | [2025-12-08 16:05:35,975] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.034 | [2025-12-08 16:05:36,022] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 106ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.072 | [2025-12-08 16:05:36,072] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.083 | [2025-12-08 16:05:36,083] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 61ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.146 | [2025-12-08 16:05:36,146] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.160 | [2025-12-08 16:05:36,160] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 76ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.203 | [2025-12-08 16:05:36,203] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.230 | [2025-12-08 16:05:36,230] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.264 | [2025-12-08 16:05:36,264] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.272 | [2025-12-08 16:05:36,271] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 41ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.366 | [2025-12-08 16:05:36,366] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.396 | [2025-12-08 16:05:36,396] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 110ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.445 | [2025-12-08 16:05:36,445] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.453 | [2025-12-08 16:05:36,453] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.480 | [2025-12-08 16:05:36,479] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.486 | [2025-12-08 16:05:36,485] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.507 | [2025-12-08 16:05:36,507] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.527 | [2025-12-08 16:05:36,526] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.650 | [2025-12-08 16:05:36,649] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.660 | [2025-12-08 16:05:36,659] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 132ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.782 | [2025-12-08 16:05:36,782] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.820 | [2025-12-08 16:05:36,800] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 141ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:36.981 | [2025-12-08 16:05:36,981] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:36.996 | [2025-12-08 16:05:36,995] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 174ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.156 | [2025-12-08 16:05:37,156] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.174 | [2025-12-08 16:05:37,174] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 178ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.345 | [2025-12-08 16:05:37,345] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.354 | [2025-12-08 16:05:37,353] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 179ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.402 | [2025-12-08 16:05:37,401] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.424 | [2025-12-08 16:05:37,424] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 69ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.446 | [2025-12-08 16:05:37,446] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.454 | [2025-12-08 16:05:37,454] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.496 | [2025-12-08 16:05:37,495] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.511 | [2025-12-08 16:05:37,511] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.632 | [2025-12-08 16:05:37,631] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-8/00000000000000000004.snapshot (kafka.log.SnapshotFile)
2025-12-08 21:35:37.640 | [2025-12-08 16:05:37,639] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.641 | [2025-12-08 16:05:37,640] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.649 | [2025-12-08 16:05:37,649] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/__consumer_offsets-8/00000000000000000006.snapshot,6)' (kafka.log.ProducerStateManager)
2025-12-08 21:35:37.705 | [2025-12-08 16:05:37,705] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Producer state recovery took 63ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.714 | [2025-12-08 16:05:37,714] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments in 203ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.755 | [2025-12-08 16:05:37,754] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.759 | [2025-12-08 16:05:37,758] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 44ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:37.841 | [2025-12-08 16:05:37,839] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.841 | [2025-12-08 16:05:37,840] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.841 | [2025-12-08 16:05:37,841] INFO [ProducerStateManager partition=booking-email-0] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/booking-email-0/00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
2025-12-08 21:35:37.895 | [2025-12-08 16:05:37,891] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Producer state recovery took 51ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
2025-12-08 21:35:37.909 | [2025-12-08 16:05:37,908] INFO Completed load of Log(dir=/var/lib/kafka/data/booking-email-0, topicId=ZZs51CcXT3m5RospnghyvA, topic=booking-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 148ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.006 | [2025-12-08 16:05:38,005] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.020 | [2025-12-08 16:05:38,015] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 65ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.124 | [2025-12-08 16:05:38,123] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.173 | [2025-12-08 16:05:38,172] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 157ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.257 | [2025-12-08 16:05:38,251] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.271 | [2025-12-08 16:05:38,271] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 98ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.362 | [2025-12-08 16:05:38,358] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.379 | [2025-12-08 16:05:38,373] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 102ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.431 | [2025-12-08 16:05:38,429] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.443 | [2025-12-08 16:05:38,443] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 63ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.460 | [2025-12-08 16:05:38,459] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.524 | [2025-12-08 16:05:38,524] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.636 | [2025-12-08 16:05:38,631] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.767 | [2025-12-08 16:05:38,767] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 202ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.897 | [2025-12-08 16:05:38,891] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-08 21:35:38.898 | [2025-12-08 16:05:38,896] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 129ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-08 21:35:38.965 | [2025-12-08 16:05:38,965] INFO Loaded 51 logs in 7596ms. (kafka.log.LogManager)
2025-12-08 21:35:38.968 | [2025-12-08 16:05:38,967] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-12-08 21:35:39.027 | [2025-12-08 16:05:39,016] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-12-08 21:35:39.155 | [2025-12-08 16:05:39,154] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-12-08 21:35:39.688 | [2025-12-08 16:05:39,687] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
2025-12-08 21:35:39.848 | [2025-12-08 16:05:39,845] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 21:35:40.097 | [2025-12-08 16:05:40,096] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-12-08 21:35:40.420 | [2025-12-08 16:05:40,420] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-08 21:35:52.785 | [2025-12-08 16:05:52,781] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-08 21:35:52.918 | [2025-12-08 16:05:52,906] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-12-08 21:35:53.341 | [2025-12-08 16:05:53,332] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-12-08 21:35:53.341 | [2025-12-08 16:05:53,334] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-08 21:35:53.363 | [2025-12-08 16:05:53,363] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-12-08 21:35:53.457 | [2025-12-08 16:05:53,449] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-12-08 21:35:53.531 | [2025-12-08 16:05:53,530] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-08 21:35:53.808 | [2025-12-08 16:05:53,808] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:53.850 | [2025-12-08 16:05:53,849] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:53.869 | [2025-12-08 16:05:53,868] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:53.873 | [2025-12-08 16:05:53,871] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:54.131 | [2025-12-08 16:05:54,129] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 21:35:54.765 | [2025-12-08 16:05:54,763] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-12-08 21:35:54.954 | [2025-12-08 16:05:54,953] INFO Stat of the created znode at /brokers/ids/1 is: 182,182,1765209954896,1765209954896,1,0,0,72060912164470785,270,0,182
2025-12-08 21:35:54.954 |  (kafka.zk.KafkaZkClient)
2025-12-08 21:35:54.956 | [2025-12-08 16:05:54,955] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 182 (kafka.zk.KafkaZkClient)
2025-12-08 21:35:55.715 | [2025-12-08 16:05:55,709] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 21:35:55.811 | [2025-12-08 16:05:55,810] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:56.021 | [2025-12-08 16:05:56,020] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:56.060 | [2025-12-08 16:05:56,025] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:56.122 | [2025-12-08 16:05:56,121] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 3 and epoch zk version is now 3 (kafka.controller.KafkaController)
2025-12-08 21:35:56.129 | [2025-12-08 16:05:56,129] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-12-08 21:35:56.159 | [2025-12-08 16:05:56,158] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-12-08 21:35:56.236 | [2025-12-08 16:05:56,235] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-12-08 21:35:56.240 | [2025-12-08 16:05:56,237] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:35:56.256 | [2025-12-08 16:05:56,251] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-12-08 21:35:56.464 | [2025-12-08 16:05:56,463] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 182) (kafka.controller.KafkaController)
2025-12-08 21:35:56.481 | [2025-12-08 16:05:56,466] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:35:56.677 | [2025-12-08 16:05:56,677] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-08 21:35:56.729 | [2025-12-08 16:05:56,728] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 21:35:56.771 | [2025-12-08 16:05:56,771] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 21:35:56.871 | [2025-12-08 16:05:56,871] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 21:35:57.436 | [2025-12-08 16:05:57,435] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-12-08 21:35:57.541 | [2025-12-08 16:05:57,537] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-12-08 21:35:57.541 | [2025-12-08 16:05:57,541] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-12-08 21:35:57.542 | [2025-12-08 16:05:57,542] INFO [Controller id=1] Current list of topics in the cluster: HashSet(booking-email, __consumer_offsets) (kafka.controller.KafkaController)
2025-12-08 21:35:57.551 | [2025-12-08 16:05:57,550] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-12-08 21:35:57.564 | [2025-12-08 16:05:57,562] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-12-08 21:35:57.697 | [2025-12-08 16:05:57,696] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 21:35:57.703 | [2025-12-08 16:05:57,703] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-12-08 21:35:57.717 | [2025-12-08 16:05:57,717] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-12-08 21:35:57.718 | [2025-12-08 16:05:57,718] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-12-08 21:35:57.721 | [2025-12-08 16:05:57,720] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-12-08 21:35:57.726 | [2025-12-08 16:05:57,726] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-12-08 21:35:57.760 | [2025-12-08 16:05:57,749] INFO [Controller id=1 epoch=3] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-12-08 21:35:58.281 | [2025-12-08 16:05:58,280] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-12-08 21:35:58.424 | [2025-12-08 16:05:58,424] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-08 21:35:58.449 | [2025-12-08 16:05:58,448] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-12-08 21:35:58.552 | [2025-12-08 16:05:58,551] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 21:35:58.798 | [2025-12-08 16:05:58,798] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.839 | [2025-12-08 16:05:58,838] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.841 | [2025-12-08 16:05:58,841] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.859 | [2025-12-08 16:05:58,859] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.886 | [2025-12-08 16:05:58,886] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.887 | [2025-12-08 16:05:58,887] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.888 | [2025-12-08 16:05:58,887] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.888 | [2025-12-08 16:05:58,888] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.889 | [2025-12-08 16:05:58,888] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.889 | [2025-12-08 16:05:58,889] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.890 | [2025-12-08 16:05:58,890] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.890 | [2025-12-08 16:05:58,890] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.893 | [2025-12-08 16:05:58,893] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.894 | [2025-12-08 16:05:58,893] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.901 | [2025-12-08 16:05:58,900] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.919 | [2025-12-08 16:05:58,918] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.920 | [2025-12-08 16:05:58,920] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.921 | [2025-12-08 16:05:58,921] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.922 | [2025-12-08 16:05:58,921] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.922 | [2025-12-08 16:05:58,922] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.923 | [2025-12-08 16:05:58,923] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.925 | [2025-12-08 16:05:58,925] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.936 | [2025-12-08 16:05:58,931] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.940 | [2025-12-08 16:05:58,940] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.941 | [2025-12-08 16:05:58,940] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.941 | [2025-12-08 16:05:58,941] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.942 | [2025-12-08 16:05:58,941] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition booking-email-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.942 | [2025-12-08 16:05:58,942] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.943 | [2025-12-08 16:05:58,943] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.944 | [2025-12-08 16:05:58,943] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.944 | [2025-12-08 16:05:58,944] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.945 | [2025-12-08 16:05:58,945] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.945 | [2025-12-08 16:05:58,945] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.946 | [2025-12-08 16:05:58,946] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.949 | [2025-12-08 16:05:58,949] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.950 | [2025-12-08 16:05:58,950] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.950 | [2025-12-08 16:05:58,950] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.952 | [2025-12-08 16:05:58,951] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.953 | [2025-12-08 16:05:58,953] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.967 | [2025-12-08 16:05:58,965] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.967 | [2025-12-08 16:05:58,966] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.968 | [2025-12-08 16:05:58,966] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.970 | [2025-12-08 16:05:58,969] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.971 | [2025-12-08 16:05:58,971] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.973 | [2025-12-08 16:05:58,972] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.984 | [2025-12-08 16:05:58,983] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.984 | [2025-12-08 16:05:58,984] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.985 | [2025-12-08 16:05:58,985] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.985 | [2025-12-08 16:05:58,985] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.986 | [2025-12-08 16:05:58,986] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:58.988 | [2025-12-08 16:05:58,988] TRACE [Controller id=1 epoch=3] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-08 21:35:59.021 | [2025-12-08 16:05:59,021] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-12-08 21:35:59.118 | [2025-12-08 16:05:59,118] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 21:35:59.127 | [2025-12-08 16:05:59,126] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 21:35:59.127 | [2025-12-08 16:05:59,127] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 21:35:59.127 | [2025-12-08 16:05:59,127] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 21:35:59.128 | [2025-12-08 16:05:59,128] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 21:35:59.129 | [2025-12-08 16:05:59,129] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,129] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,129] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,129] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,129] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,130] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,130] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,130] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 21:35:59.130 | [2025-12-08 16:05:59,130] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 21:35:59.141 | [2025-12-08 16:05:59,131] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,141] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,142] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,142] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,142] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 21:35:59.143 | [2025-12-08 16:05:59,142] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 21:35:59.144 | [2025-12-08 16:05:59,142] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 21:35:59.144 | [2025-12-08 16:05:59,142] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 21:35:59.144 | [2025-12-08 16:05:59,143] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 21:35:59.144 | [2025-12-08 16:05:59,143] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 21:35:59.160 | [2025-12-08 16:05:59,159] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 21:35:59.160 | [2025-12-08 16:05:59,160] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 21:35:59.160 | [2025-12-08 16:05:59,160] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 21:35:59.160 | [2025-12-08 16:05:59,160] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 21:35:59.169 | [2025-12-08 16:05:59,169] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 21:35:59.170 | [2025-12-08 16:05:59,170] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 21:35:59.170 | [2025-12-08 16:05:59,170] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 21:35:59.170 | [2025-12-08 16:05:59,170] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 21:35:59.172 | [2025-12-08 16:05:59,171] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 21:35:59.250 | [2025-12-08 16:05:59,250] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 21:35:59.250 | [2025-12-08 16:05:59,250] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition booking-email-0 (state.change.logger)
2025-12-08 21:35:59.250 | [2025-12-08 16:05:59,250] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 21:35:59.251 | [2025-12-08 16:05:59,251] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 21:35:59.251 | [2025-12-08 16:05:59,251] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 21:35:59.251 | [2025-12-08 16:05:59,251] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 21:35:59.251 | [2025-12-08 16:05:59,251] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 21:35:59.252 | [2025-12-08 16:05:59,252] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 21:35:59.252 | [2025-12-08 16:05:59,252] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 21:35:59.254 | [2025-12-08 16:05:59,252] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 21:35:59.255 | [2025-12-08 16:05:59,254] TRACE [Controller id=1 epoch=3] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 21:35:59.308 | [2025-12-08 16:05:59,308] INFO Kafka version: 7.4.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 21:35:59.309 | [2025-12-08 16:05:59,308] INFO Kafka commitId: 30969fa33c185e880b9e02044761dfaac013151d (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 21:35:59.309 | [2025-12-08 16:05:59,308] INFO Kafka startTimeMs: 1765209959155 (org.apache.kafka.common.utils.AppInfoParser)
2025-12-08 21:35:59.314 | [2025-12-08 16:05:59,312] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-12-08 21:35:59.472 | [2025-12-08 16:05:59,470] INFO [Controller id=1 epoch=3] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-12-08 21:35:59.589 | [2025-12-08 16:05:59,589] INFO [Controller id=1 epoch=3] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-12-08 21:35:59.594 | [2025-12-08 16:05:59,591] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-08 21:35:59.635 | [2025-12-08 16:05:59,634] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=booking-email,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-12-08 21:35:59.640 | [2025-12-08 16:05:59,639] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-12-08 21:35:59.716 | [2025-12-08 16:05:59,715] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-12-08 21:35:59.733 | [2025-12-08 16:05:59,725] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, booking-email-0 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-12-08 21:35:59.760 | [2025-12-08 16:05:59,760] INFO [Controller id=1] Ready to serve as the new controller with epoch 3 (kafka.controller.KafkaController)
2025-12-08 21:35:59.885 | [2025-12-08 16:05:59,885] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-12-08 21:35:59.886 | [2025-12-08 16:05:59,886] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-12-08 21:35:59.887 | [2025-12-08 16:05:59,887] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-12-08 21:35:59.888 | [2025-12-08 16:05:59,888] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-12-08 21:35:59.908 | [2025-12-08 16:05:59,907] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-12-08 21:35:59.964 | [2025-12-08 16:05:59,921] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-08 21:35:59.983 | [2025-12-08 16:05:59,983] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-08 21:36:00.147 | [2025-12-08 16:06:00,147] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-12-08 21:36:00.670 | [2025-12-08 16:06:00,651] TRACE [Controller id=1 epoch=3] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 21:36:00.985 | [2025-12-08 16:06:00,977] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-12-08 21:36:01.033 | [2025-12-08 16:06:01,024] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,026] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,039] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,040] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,040] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,040] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,040] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,040] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,040] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,041] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,041] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.047 | [2025-12-08 16:06:01,041] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.095 | [2025-12-08 16:06:01,094] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,095] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,108] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,108] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,108] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,109] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,109] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,109] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,109] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.111 | [2025-12-08 16:06:01,109] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.126 | [2025-12-08 16:06:01,109] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,125] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,125] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,126] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,126] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,126] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,126] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.127 | [2025-12-08 16:06:01,126] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.135 | [2025-12-08 16:06:01,127] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.144 | [2025-12-08 16:06:01,144] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.145 | [2025-12-08 16:06:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.145 | [2025-12-08 16:06:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.145 | [2025-12-08 16:06:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.146 | [2025-12-08 16:06:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.146 | [2025-12-08 16:06:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.146 | [2025-12-08 16:06:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.147 | [2025-12-08 16:06:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.147 | [2025-12-08 16:06:01,147] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.147 | [2025-12-08 16:06:01,147] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.147 | [2025-12-08 16:06:01,147] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.148 | [2025-12-08 16:06:01,148] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.161 | [2025-12-08 16:06:01,160] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.161 | [2025-12-08 16:06:01,160] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.161 | [2025-12-08 16:06:01,160] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.161 | [2025-12-08 16:06:01,161] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.161 | [2025-12-08 16:06:01,161] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.161 | [2025-12-08 16:06:01,161] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.162 | [2025-12-08 16:06:01,161] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:01.162 | [2025-12-08 16:06:01,162] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 3 (state.change.logger)
2025-12-08 21:36:02.148 | [2025-12-08 16:06:02,148] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 21:36:02.163 | [2025-12-08 16:06:02,162] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 21:36:02.171 | [2025-12-08 16:06:02,171] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 21:36:02.173 | [2025-12-08 16:06:02,172] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 21:36:02.177 | [2025-12-08 16:06:02,175] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 21:36:02.177 | [2025-12-08 16:06:02,177] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 21:36:02.178 | [2025-12-08 16:06:02,177] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 21:36:02.178 | [2025-12-08 16:06:02,178] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 21:36:02.178 | [2025-12-08 16:06:02,178] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 21:36:02.178 | [2025-12-08 16:06:02,178] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 21:36:02.179 | [2025-12-08 16:06:02,178] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 21:36:02.179 | [2025-12-08 16:06:02,179] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 21:36:02.180 | [2025-12-08 16:06:02,179] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 21:36:02.180 | [2025-12-08 16:06:02,180] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 21:36:02.181 | [2025-12-08 16:06:02,181] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 21:36:02.181 | [2025-12-08 16:06:02,181] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 21:36:02.182 | [2025-12-08 16:06:02,181] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 21:36:02.182 | [2025-12-08 16:06:02,182] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 21:36:02.182 | [2025-12-08 16:06:02,182] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 21:36:02.182 | [2025-12-08 16:06:02,182] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 21:36:02.183 | [2025-12-08 16:06:02,183] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 21:36:02.196 | [2025-12-08 16:06:02,195] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 21:36:02.196 | [2025-12-08 16:06:02,196] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 21:36:02.196 | [2025-12-08 16:06:02,196] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 21:36:02.197 | [2025-12-08 16:06:02,197] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 21:36:02.197 | [2025-12-08 16:06:02,197] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 21:36:02.197 | [2025-12-08 16:06:02,197] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 21:36:02.197 | [2025-12-08 16:06:02,197] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 21:36:02.198 | [2025-12-08 16:06:02,198] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 21:36:02.198 | [2025-12-08 16:06:02,198] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 21:36:02.198 | [2025-12-08 16:06:02,198] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-08 21:36:02.199 | [2025-12-08 16:06:02,198] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 21:36:02.199 | [2025-12-08 16:06:02,199] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 21:36:02.199 | [2025-12-08 16:06:02,199] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 21:36:02.213 | [2025-12-08 16:06:02,212] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 21:36:02.213 | [2025-12-08 16:06:02,213] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 21:36:02.214 | [2025-12-08 16:06:02,213] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 21:36:02.214 | [2025-12-08 16:06:02,214] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 21:36:02.214 | [2025-12-08 16:06:02,214] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 21:36:02.214 | [2025-12-08 16:06:02,214] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 21:36:02.214 | [2025-12-08 16:06:02,214] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 21:36:02.215 | [2025-12-08 16:06:02,215] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 21:36:02.216 | [2025-12-08 16:06:02,216] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 21:36:02.216 | [2025-12-08 16:06:02,216] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 21:36:02.216 | [2025-12-08 16:06:02,216] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 21:36:02.228 | [2025-12-08 16:06:02,227] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 21:36:02.228 | [2025-12-08 16:06:02,228] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 21:36:02.229 | [2025-12-08 16:06:02,228] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 21:36:02.229 | [2025-12-08 16:06:02,229] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 21:36:02.229 | [2025-12-08 16:06:02,229] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 21:36:02.230 | [2025-12-08 16:06:02,229] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 3 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 21:36:02.246 | [2025-12-08 16:06:02,246] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, booking-email-0, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-12-08 21:36:02.248 | [2025-12-08 16:06:02,248] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 3 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-12-08 21:36:02.362 | [2025-12-08 16:06:02,361] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:02.379 | [2025-12-08 16:06:02,378] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:02.594 | [2025-12-08 16:06:02,594] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:02.595 | [2025-12-08 16:06:02,595] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:02.771 | [2025-12-08 16:06:02,771] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:02.772 | [2025-12-08 16:06:02,772] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:02.960 | [2025-12-08 16:06:02,960] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:02.961 | [2025-12-08 16:06:02,960] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.085 | [2025-12-08 16:06:03,084] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.086 | [2025-12-08 16:06:03,085] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.130 | [2025-12-08 16:06:03,129] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.131 | [2025-12-08 16:06:03,131] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.258 | [2025-12-08 16:06:03,258] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.259 | [2025-12-08 16:06:03,259] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.422 | [2025-12-08 16:06:03,422] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.423 | [2025-12-08 16:06:03,422] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.562 | [2025-12-08 16:06:03,561] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.563 | [2025-12-08 16:06:03,563] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.677 | [2025-12-08 16:06:03,677] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.678 | [2025-12-08 16:06:03,677] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.761 | [2025-12-08 16:06:03,746] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.775 | [2025-12-08 16:06:03,773] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.853 | [2025-12-08 16:06:03,852] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.870 | [2025-12-08 16:06:03,869] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.906 | [2025-12-08 16:06:03,902] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.906 | [2025-12-08 16:06:03,903] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.935 | [2025-12-08 16:06:03,934] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.935 | [2025-12-08 16:06:03,935] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:03.957 | [2025-12-08 16:06:03,957] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:03.968 | [2025-12-08 16:06:03,958] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.002 | [2025-12-08 16:06:03,999] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.002 | [2025-12-08 16:06:04,001] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.028 | [2025-12-08 16:06:04,025] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.030 | [2025-12-08 16:06:04,026] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.063 | [2025-12-08 16:06:04,048] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.063 | [2025-12-08 16:06:04,048] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.068 | [2025-12-08 16:06:04,067] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.068 | [2025-12-08 16:06:04,068] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.086 | [2025-12-08 16:06:04,085] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.087 | [2025-12-08 16:06:04,085] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.129 | [2025-12-08 16:06:04,127] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.129 | [2025-12-08 16:06:04,128] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.142 | [2025-12-08 16:06:04,137] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.142 | [2025-12-08 16:06:04,137] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.152 | [2025-12-08 16:06:04,151] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.152 | [2025-12-08 16:06:04,152] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.169 | [2025-12-08 16:06:04,168] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.170 | [2025-12-08 16:06:04,170] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.184 | [2025-12-08 16:06:04,181] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.184 | [2025-12-08 16:06:04,182] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.195 | [2025-12-08 16:06:04,195] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.196 | [2025-12-08 16:06:04,196] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.210 | [2025-12-08 16:06:04,210] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.213 | [2025-12-08 16:06:04,211] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.222 | [2025-12-08 16:06:04,222] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.222 | [2025-12-08 16:06:04,222] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.238 | [2025-12-08 16:06:04,237] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.238 | [2025-12-08 16:06:04,237] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.250 | [2025-12-08 16:06:04,247] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.250 | [2025-12-08 16:06:04,248] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.266 | [2025-12-08 16:06:04,265] INFO [Partition booking-email-0 broker=1] Log loaded for partition booking-email-0 with initial high watermark 1 (kafka.cluster.Partition)
2025-12-08 21:36:04.266 | [2025-12-08 16:06:04,266] INFO [Broker id=1] Leader booking-email-0 with topic id Some(ZZs51CcXT3m5RospnghyvA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.268 | [2025-12-08 16:06:04,267] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.273 | [2025-12-08 16:06:04,268] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.293 | [2025-12-08 16:06:04,292] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.293 | [2025-12-08 16:06:04,293] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.331 | [2025-12-08 16:06:04,331] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.333 | [2025-12-08 16:06:04,332] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.356 | [2025-12-08 16:06:04,356] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 6 (kafka.cluster.Partition)
2025-12-08 21:36:04.361 | [2025-12-08 16:06:04,361] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 6 with partition epoch 0, high watermark 6, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.362 | [2025-12-08 16:06:04,362] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.371 | [2025-12-08 16:06:04,368] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.400 | [2025-12-08 16:06:04,399] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.401 | [2025-12-08 16:06:04,400] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.416 | [2025-12-08 16:06:04,415] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.426 | [2025-12-08 16:06:04,425] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.439 | [2025-12-08 16:06:04,438] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.439 | [2025-12-08 16:06:04,439] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.449 | [2025-12-08 16:06:04,449] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.452 | [2025-12-08 16:06:04,451] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.466 | [2025-12-08 16:06:04,466] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.466 | [2025-12-08 16:06:04,466] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.476 | [2025-12-08 16:06:04,475] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.486 | [2025-12-08 16:06:04,485] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.505 | [2025-12-08 16:06:04,504] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.505 | [2025-12-08 16:06:04,505] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.521 | [2025-12-08 16:06:04,521] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.521 | [2025-12-08 16:06:04,521] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.532 | [2025-12-08 16:06:04,531] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.532 | [2025-12-08 16:06:04,532] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.543 | [2025-12-08 16:06:04,540] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.544 | [2025-12-08 16:06:04,543] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.555 | [2025-12-08 16:06:04,555] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.556 | [2025-12-08 16:06:04,556] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.581 | [2025-12-08 16:06:04,580] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.581 | [2025-12-08 16:06:04,581] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.593 | [2025-12-08 16:06:04,593] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.594 | [2025-12-08 16:06:04,594] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.608 | [2025-12-08 16:06:04,608] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.609 | [2025-12-08 16:06:04,609] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.622 | [2025-12-08 16:06:04,622] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-08 21:36:04.622 | [2025-12-08 16:06:04,622] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,640] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,641] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,642] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,643] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-08 21:36:04.644 | [2025-12-08 16:06:04,644] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-08 21:36:04.645 | [2025-12-08 16:06:04,645] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 3 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-08 21:36:04.686 | [2025-12-08 16:06:04,678] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.692 | [2025-12-08 16:06:04,692] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.706 | [2025-12-08 16:06:04,706] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.706 | [2025-12-08 16:06:04,706] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.707 | [2025-12-08 16:06:04,707] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,707] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.708 | [2025-12-08 16:06:04,708] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,708] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,709] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,709] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,709] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,709] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,709] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.709 | [2025-12-08 16:06:04,709] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.710 | [2025-12-08 16:06:04,709] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.710 | [2025-12-08 16:06:04,710] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.710 | [2025-12-08 16:06:04,710] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.710 | [2025-12-08 16:06:04,710] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.710 | [2025-12-08 16:06:04,710] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.710 | [2025-12-08 16:06:04,710] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.711 | [2025-12-08 16:06:04,711] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.711 | [2025-12-08 16:06:04,711] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.711 | [2025-12-08 16:06:04,711] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.711 | [2025-12-08 16:06:04,711] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.711 | [2025-12-08 16:06:04,711] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.712 | [2025-12-08 16:06:04,711] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.712 | [2025-12-08 16:06:04,712] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.712 | [2025-12-08 16:06:04,712] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.712 | [2025-12-08 16:06:04,712] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.713 | [2025-12-08 16:06:04,712] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.713 | [2025-12-08 16:06:04,713] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.713 | [2025-12-08 16:06:04,713] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,713] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,713] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,713] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,714] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,714] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,714] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,715] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.716 | [2025-12-08 16:06:04,716] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.717 | [2025-12-08 16:06:04,717] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.718 | [2025-12-08 16:06:04,717] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.718 | [2025-12-08 16:06:04,718] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.718 | [2025-12-08 16:06:04,718] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.718 | [2025-12-08 16:06:04,718] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.718 | [2025-12-08 16:06:04,718] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.718 | [2025-12-08 16:06:04,718] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.725 | [2025-12-08 16:06:04,718] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.725 | [2025-12-08 16:06:04,725] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.726 | [2025-12-08 16:06:04,726] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,726] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.727 | [2025-12-08 16:06:04,727] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.728 | [2025-12-08 16:06:04,728] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.728 | [2025-12-08 16:06:04,728] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.728 | [2025-12-08 16:06:04,728] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.728 | [2025-12-08 16:06:04,728] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.728 | [2025-12-08 16:06:04,728] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:04.728 | [2025-12-08 16:06:04,728] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.755 | [2025-12-08 16:06:04,755] INFO [Broker id=1] Finished LeaderAndIsr request in 3832ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-12-08 21:36:04.833 | [2025-12-08 16:06:04,800] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 80 milliseconds for epoch 0, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.834 | [2025-12-08 16:06:04,833] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 127 milliseconds for epoch 0, of which 127 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.834 | [2025-12-08 16:06:04,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 127 milliseconds for epoch 0, of which 127 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.834 | [2025-12-08 16:06:04,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 127 milliseconds for epoch 0, of which 127 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.835 | [2025-12-08 16:06:04,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 128 milliseconds for epoch 0, of which 127 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.841 | [2025-12-08 16:06:04,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 133 milliseconds for epoch 0, of which 127 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.842 | [2025-12-08 16:06:04,842] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 134 milliseconds for epoch 0, of which 133 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.843 | [2025-12-08 16:06:04,842] TRACE [Controller id=1 epoch=3] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=s1of94BtTGS8K-UMhA2LCA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=ZZs51CcXT3m5RospnghyvA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 135 milliseconds for epoch 0, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 135 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,844] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 135 milliseconds for epoch 0, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,845] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 136 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,845] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 137 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,847] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 136 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,847] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.848 | [2025-12-08 16:06:04,847] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 135 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.849 | [2025-12-08 16:06:04,848] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.849 | [2025-12-08 16:06:04,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.849 | [2025-12-08 16:06:04,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.849 | [2025-12-08 16:06:04,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.850 | [2025-12-08 16:06:04,850] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 136 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.850 | [2025-12-08 16:06:04,850] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.851 | [2025-12-08 16:06:04,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 135 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.851 | [2025-12-08 16:06:04,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.851 | [2025-12-08 16:06:04,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.851 | [2025-12-08 16:06:04,851] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 135 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.852 | [2025-12-08 16:06:04,852] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 136 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.852 | [2025-12-08 16:06:04,852] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.852 | [2025-12-08 16:06:04,852] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 136 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.853 | [2025-12-08 16:06:04,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 136 milliseconds for epoch 0, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:04.935 | [2025-12-08 16:06:04,907] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition booking-email-0 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,935] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,935] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,935] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,935] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.936 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,936] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.937 | [2025-12-08 16:06:04,937] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.941 | [2025-12-08 16:06:04,941] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 3 with correlation id 2 (state.change.logger)
2025-12-08 21:36:04.951 | [2025-12-08 16:06:04,951] TRACE [Controller id=1 epoch=3] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-08 21:36:05.101 | [2025-12-08 16:06:05,099] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-12-08 21:36:05.150 | [2025-12-08 16:06:05,150] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 21:36:05.151 | [2025-12-08 16:06:05,151] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 21:36:05.154 | [2025-12-08 16:06:05,154] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.7, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 3. (kafka.coordinator.group.GroupMetadata$)
2025-12-08 21:36:05.173 | [2025-12-08 16:06:05,173] INFO [GroupCoordinator 1]: Loading group metadata for email-group with generation 4 (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:05.178 | [2025-12-08 16:06:05,177] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 21:36:05.181 | [2025-12-08 16:06:05,180] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 21:36:05.186 | [2025-12-08 16:06:05,185] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 468 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.186 | [2025-12-08 16:06:05,186] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 469 milliseconds for epoch 0, of which 469 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.187 | [2025-12-08 16:06:05,186] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 468 milliseconds for epoch 0, of which 468 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.187 | [2025-12-08 16:06:05,187] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 469 milliseconds for epoch 0, of which 469 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.187 | [2025-12-08 16:06:05,187] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 469 milliseconds for epoch 0, of which 469 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.188 | [2025-12-08 16:06:05,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 463 milliseconds for epoch 0, of which 462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.188 | [2025-12-08 16:06:05,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 462 milliseconds for epoch 0, of which 462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.189 | [2025-12-08 16:06:05,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 462 milliseconds for epoch 0, of which 462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.189 | [2025-12-08 16:06:05,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 463 milliseconds for epoch 0, of which 463 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.189 | [2025-12-08 16:06:05,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 463 milliseconds for epoch 0, of which 463 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.190 | [2025-12-08 16:06:05,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 463 milliseconds for epoch 0, of which 462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.190 | [2025-12-08 16:06:05,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 463 milliseconds for epoch 0, of which 463 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.190 | [2025-12-08 16:06:05,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 463 milliseconds for epoch 0, of which 463 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.195 | [2025-12-08 16:06:05,191] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 464 milliseconds for epoch 0, of which 464 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.195 | [2025-12-08 16:06:05,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 466 milliseconds for epoch 0, of which 465 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.195 | [2025-12-08 16:06:05,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 466 milliseconds for epoch 0, of which 466 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:05.195 | [2025-12-08 16:06:05,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 467 milliseconds for epoch 0, of which 467 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-08 21:36:12.876 | [2025-12-08 16:06:12,875] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Empty state. Created a new member id consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:12.901 | [2025-12-08 16:06:12,900] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 4 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:15.907 | [2025-12-08 16:06:15,906] INFO [GroupCoordinator 1]: Stabilized group email-group generation 5 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:36:15.935 | [2025-12-08 16:06:15,935] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 21:41:05.141 | [2025-12-08 16:11:05,140] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 21:41:05.141 | [2025-12-08 16:11:05,141] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 21:41:05.142 | [2025-12-08 16:11:05,142] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 21:41:05.142 | [2025-12-08 16:11:05,142] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 21:46:05.091 | [2025-12-08 16:16:05,090] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 21:46:05.091 | [2025-12-08 16:16:05,090] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 21:46:05.094 | [2025-12-08 16:16:05,094] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 21:46:05.094 | [2025-12-08 16:16:05,094] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 21:51:05.026 | [2025-12-08 16:21:05,026] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 21:51:05.026 | [2025-12-08 16:21:05,026] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 21:51:05.028 | [2025-12-08 16:21:05,028] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 21:51:05.028 | [2025-12-08 16:21:05,028] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 21:56:04.957 | [2025-12-08 16:26:04,956] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 21:56:04.957 | [2025-12-08 16:26:04,956] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 21:56:04.961 | [2025-12-08 16:26:04,960] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 21:56:04.961 | [2025-12-08 16:26:04,961] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 21:56:44.596 | [2025-12-08 16:26:44,595] DEBUG [Controller id=1] Read current producerId block ProducerIdsBlock(assignedBrokerId=1, firstProducerId=0, size=1000), Zk path version 1 (kafka.controller.KafkaController)
2025-12-08 21:56:44.612 | [2025-12-08 16:26:44,612] INFO [Controller id=1] Acquired new producerId block ProducerIdsBlock(assignedBrokerId=1, firstProducerId=1000, size=1000) by writing to Zk with path version 2 (kafka.controller.KafkaController)
2025-12-08 22:01:04.898 | [2025-12-08 16:31:04,898] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:01:04.898 | [2025-12-08 16:31:04,898] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:01:04.901 | [2025-12-08 16:31:04,900] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:01:04.901 | [2025-12-08 16:31:04,901] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:06:04.859 | [2025-12-08 16:36:04,858] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:06:04.859 | [2025-12-08 16:36:04,858] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:06:04.861 | [2025-12-08 16:36:04,861] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:06:04.861 | [2025-12-08 16:36:04,861] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:06:44.673 | [2025-12-08 16:36:44,673] INFO [BrokerToControllerChannelManager broker=1 name=forwarding] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
2025-12-08 22:11:04.818 | [2025-12-08 16:41:04,817] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:11:04.818 | [2025-12-08 16:41:04,818] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:11:04.828 | [2025-12-08 16:41:04,827] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:11:04.834 | [2025-12-08 16:41:04,834] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:16:04.794 | [2025-12-08 16:46:04,794] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:16:04.794 | [2025-12-08 16:46:04,794] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:16:04.795 | [2025-12-08 16:46:04,795] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:16:04.795 | [2025-12-08 16:46:04,795] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:21:04.751 | [2025-12-08 16:51:04,751] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:21:04.751 | [2025-12-08 16:51:04,751] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:21:04.752 | [2025-12-08 16:51:04,752] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:21:04.752 | [2025-12-08 16:51:04,752] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:26:04.698 | [2025-12-08 16:56:04,697] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:26:04.698 | [2025-12-08 16:56:04,697] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:26:04.699 | [2025-12-08 16:56:04,699] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:26:04.699 | [2025-12-08 16:56:04,699] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:31:04.650 | [2025-12-08 17:01:04,649] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:31:04.650 | [2025-12-08 17:01:04,649] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:31:04.652 | [2025-12-08 17:01:04,652] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:31:04.652 | [2025-12-08 17:01:04,652] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:32:35.466 | [2025-12-08 17:02:35,466] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Stable state. Created a new member id consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:35.480 | [2025-12-08 17:02:35,480] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 5 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:38.030 | [2025-12-08 17:02:38,029] INFO [GroupCoordinator 1]: Stabilized group email-group generation 6 (__consumer_offsets-8) with 2 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:38.063 | [2025-12-08 17:02:38,063] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 6. The group has 2 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:48.081 | [2025-12-08 17:02:48,081] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Stable state. Created a new member id consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:48.096 | [2025-12-08 17:02:48,095] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 6 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:50.128 | [2025-12-08 17:02:50,127] INFO [GroupCoordinator 1]: Stabilized group email-group generation 7 (__consumer_offsets-8) with 3 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:50.132 | [2025-12-08 17:02:50,132] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 7. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:56.027 | [2025-12-08 17:02:56,027] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Stable state. Created a new member id consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:56.036 | [2025-12-08 17:02:56,035] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 7 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:56.197 | [2025-12-08 17:02:56,196] INFO [GroupCoordinator 1]: Stabilized group email-group generation 8 (__consumer_offsets-8) with 4 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:56.230 | [2025-12-08 17:02:56,210] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 8. The group has 4 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:56.594 | [2025-12-08 17:02:56,594] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 8 (__consumer_offsets-8) (reason: Removing member consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:56.597 | [2025-12-08 17:02:56,597] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:59.223 | [2025-12-08 17:02:59,223] INFO [GroupCoordinator 1]: Stabilized group email-group generation 9 (__consumer_offsets-8) with 3 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:32:59.226 | [2025-12-08 17:02:59,226] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 9. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:02.348 | [2025-12-08 17:03:02,348] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 9 (__consumer_offsets-8) (reason: Removing member consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:02.348 | [2025-12-08 17:03:02,348] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:05.230 | [2025-12-08 17:03:05,230] INFO [GroupCoordinator 1]: Stabilized group email-group generation 10 (__consumer_offsets-8) with 2 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:05.232 | [2025-12-08 17:03:05,232] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 10. The group has 2 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:05.387 | [2025-12-08 17:03:05,387] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 10 (__consumer_offsets-8) (reason: Removing member consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:05.387 | [2025-12-08 17:03:05,387] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:08.236 | [2025-12-08 17:03:08,235] INFO [GroupCoordinator 1]: Stabilized group email-group generation 11 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:33:08.238 | [2025-12-08 17:03:08,238] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 11. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:36:04.606 | [2025-12-08 17:06:04,606] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:36:04.606 | [2025-12-08 17:06:04,606] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:36:04.609 | [2025-12-08 17:06:04,608] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:36:04.609 | [2025-12-08 17:06:04,608] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:41:04.571 | [2025-12-08 17:11:04,570] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:41:04.572 | [2025-12-08 17:11:04,571] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:41:04.575 | [2025-12-08 17:11:04,574] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:41:04.575 | [2025-12-08 17:11:04,574] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:46:04.539 | [2025-12-08 17:16:04,538] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:46:04.539 | [2025-12-08 17:16:04,539] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:46:04.540 | [2025-12-08 17:16:04,539] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:46:04.540 | [2025-12-08 17:16:04,539] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:50:30.273 | [2025-12-08 17:20:30,273] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Stable state. Created a new member id consumer-email-group-1-e32a0e2d-0f8d-451c-bfee-292c36149bb1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:30.283 | [2025-12-08 17:20:30,282] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 11 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-e32a0e2d-0f8d-451c-bfee-292c36149bb1 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-e32a0e2d-0f8d-451c-bfee-292c36149bb1) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:32.701 | [2025-12-08 17:20:32,700] INFO [GroupCoordinator 1]: Stabilized group email-group generation 12 (__consumer_offsets-8) with 2 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:32.716 | [2025-12-08 17:20:32,716] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 12. The group has 2 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:43.034 | [2025-12-08 17:20:43,033] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Stable state. Created a new member id consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:43.045 | [2025-12-08 17:20:43,045] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 12 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:44.744 | [2025-12-08 17:20:44,744] INFO [GroupCoordinator 1]: Stabilized group email-group generation 13 (__consumer_offsets-8) with 3 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:44.748 | [2025-12-08 17:20:44,747] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 13. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:50.968 | [2025-12-08 17:20:50,967] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Stable state. Created a new member id consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:50.974 | [2025-12-08 17:20:50,974] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 13 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:51.520 | [2025-12-08 17:20:51,519] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-1-e32a0e2d-0f8d-451c-bfee-292c36149bb1, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:53.774 | [2025-12-08 17:20:53,773] INFO [GroupCoordinator 1]: Stabilized group email-group generation 14 (__consumer_offsets-8) with 3 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:53.775 | [2025-12-08 17:20:53,775] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 14. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:57.311 | [2025-12-08 17:20:57,311] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 14 (__consumer_offsets-8) (reason: Removing member consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:57.311 | [2025-12-08 17:20:57,311] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:59.791 | [2025-12-08 17:20:59,791] INFO [GroupCoordinator 1]: Stabilized group email-group generation 15 (__consumer_offsets-8) with 2 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:50:59.794 | [2025-12-08 17:20:59,794] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 15. The group has 2 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:00.359 | [2025-12-08 17:21:00,359] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 15 (__consumer_offsets-8) (reason: Removing member consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:00.359 | [2025-12-08 17:21:00,359] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:02.796 | [2025-12-08 17:21:02,796] INFO [GroupCoordinator 1]: Stabilized group email-group generation 16 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:02.799 | [2025-12-08 17:21:02,798] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 for group email-group for generation 16. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:04.503 | [2025-12-08 17:21:04,502] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-08 22:51:04.503 | [2025-12-08 17:21:04,502] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-08 22:51:04.505 | [2025-12-08 17:21:04,505] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-08 22:51:04.505 | [2025-12-08 17:21:04,505] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-08 22:51:49.747 | [2025-12-08 17:21:49,747] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 16 (__consumer_offsets-8) (reason: Removing member consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:49.764 | [2025-12-08 17:21:49,763] INFO [GroupCoordinator 1]: Group email-group with generation 17 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:49.768 | [2025-12-08 17:21:49,768] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:54.299 | [2025-12-08 17:21:54,296] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-08 22:51:54.329 | [2025-12-08 17:21:54,328] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
2025-12-08 22:51:54.335 | [2025-12-08 17:21:54,335] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
2025-12-08 22:51:54.431 | [2025-12-08 17:21:54,430] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
2025-12-08 22:51:54.433 | [2025-12-08 17:21:54,432] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
2025-12-08 22:51:54.434 | [2025-12-08 17:21:54,434] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
2025-12-08 22:51:54.462 | [2025-12-08 17:21:54,462] INFO [Controller id=1 epoch=3] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-12-08 22:51:54.476 | [2025-12-08 17:21:54,475] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),booking-email-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
2025-12-08 22:51:54.509 | [2025-12-08 17:21:54,508] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 93ms (kafka.server.KafkaServer)
2025-12-08 22:51:54.552 | [2025-12-08 17:21:54,551] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 22:51:54.555 | [2025-12-08 17:21:54,554] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 22:51:54.556 | [2025-12-08 17:21:54,554] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-08 22:51:54.558 | [2025-12-08 17:21:54,558] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
2025-12-08 22:51:54.662 | [2025-12-08 17:21:54,662] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
2025-12-08 22:51:54.665 | [2025-12-08 17:21:54,664] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
2025-12-08 22:51:54.669 | [2025-12-08 17:21:54,669] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
2025-12-08 22:51:54.680 | [2025-12-08 17:21:54,679] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.688 | [2025-12-08 17:21:54,687] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.688 | [2025-12-08 17:21:54,687] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.691 | [2025-12-08 17:21:54,691] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
2025-12-08 22:51:54.696 | [2025-12-08 17:21:54,696] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.702 | [2025-12-08 17:21:54,701] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.702 | [2025-12-08 17:21:54,701] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.710 | [2025-12-08 17:21:54,709] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 22:51:54.715 | [2025-12-08 17:21:54,714] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
2025-12-08 22:51:54.715 | [2025-12-08 17:21:54,715] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 22:51:54.716 | [2025-12-08 17:21:54,715] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 22:51:54.716 | [2025-12-08 17:21:54,715] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-08 22:51:54.720 | [2025-12-08 17:21:54,720] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-08 22:51:54.721 | [2025-12-08 17:21:54,721] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:54.724 | [2025-12-08 17:21:54,723] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.729 | [2025-12-08 17:21:54,728] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.729 | [2025-12-08 17:21:54,728] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.730 | [2025-12-08 17:21:54,730] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.771 | [2025-12-08 17:21:54,770] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.771 | [2025-12-08 17:21:54,770] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.773 | [2025-12-08 17:21:54,772] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-08 22:51:54.777 | [2025-12-08 17:21:54,776] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
2025-12-08 22:51:54.785 | [2025-12-08 17:21:54,783] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 22:51:54.788 | [2025-12-08 17:21:54,787] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 22:51:54.788 | [2025-12-08 17:21:54,787] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-08 22:51:54.791 | [2025-12-08 17:21:54,790] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
2025-12-08 22:51:54.796 | [2025-12-08 17:21:54,795] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
2025-12-08 22:51:54.797 | [2025-12-08 17:21:54,796] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
2025-12-08 22:51:54.799 | [2025-12-08 17:21:54,798] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
2025-12-08 22:51:54.799 | [2025-12-08 17:21:54,799] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.799 | [2025-12-08 17:21:54,799] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.800 | [2025-12-08 17:21:54,799] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.800 | [2025-12-08 17:21:54,800] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.804 | [2025-12-08 17:21:54,804] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.804 | [2025-12-08 17:21:54,804] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.805 | [2025-12-08 17:21:54,805] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.808 | [2025-12-08 17:21:54,808] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.808 | [2025-12-08 17:21:54,808] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.810 | [2025-12-08 17:21:54,810] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.814 | [2025-12-08 17:21:54,813] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.814 | [2025-12-08 17:21:54,813] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-08 22:51:54.831 | [2025-12-08 17:21:54,831] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
2025-12-08 22:51:54.833 | [2025-12-08 17:21:54,833] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-12-08 22:51:54.834 | [2025-12-08 17:21:54,833] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-12-08 22:51:54.834 | [2025-12-08 17:21:54,834] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-12-08 22:51:54.841 | [2025-12-08 17:21:54,840] INFO Broker to controller channel manager for alterPartition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-12-08 22:51:54.841 | [2025-12-08 17:21:54,841] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
2025-12-08 22:51:54.843 | [2025-12-08 17:21:54,842] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
2025-12-08 22:51:54.843 | [2025-12-08 17:21:54,843] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
2025-12-08 22:51:54.846 | [2025-12-08 17:21:54,845] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
2025-12-08 22:51:54.848 | [2025-12-08 17:21:54,848] INFO Shutting down. (kafka.log.LogManager)
2025-12-08 22:51:54.853 | [2025-12-08 17:21:54,852] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
2025-12-08 22:51:54.853 | [2025-12-08 17:21:54,853] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner)
2025-12-08 22:51:54.855 | [2025-12-08 17:21:54,855] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner)
2025-12-08 22:51:54.855 | [2025-12-08 17:21:54,855] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner)
2025-12-08 22:51:55.036 | [2025-12-08 17:21:55,035] INFO [ProducerStateManager partition=booking-email-0] Wrote producer snapshot at offset 171 with 2 producer ids in 18 ms. (kafka.log.ProducerStateManager)
2025-12-08 22:51:55.057 | [2025-12-08 17:21:55,057] INFO [ProducerStateManager partition=__consumer_offsets-8] Wrote producer snapshot at offset 98 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
2025-12-08 22:51:55.248 | [2025-12-08 17:21:55,248] INFO Shutdown complete. (kafka.log.LogManager)
2025-12-08 22:51:55.249 | [2025-12-08 17:21:55,248] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 22:51:55.250 | [2025-12-08 17:21:55,250] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 22:51:55.250 | [2025-12-08 17:21:55,250] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-08 22:51:55.252 | [2025-12-08 17:21:55,251] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
2025-12-08 22:51:55.252 | [2025-12-08 17:21:55,252] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-08 22:51:55.256 | [2025-12-08 17:21:55,256] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
2025-12-08 22:51:55.258 | [2025-12-08 17:21:55,258] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
2025-12-08 22:51:55.262 | [2025-12-08 17:21:55,261] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
2025-12-08 22:51:55.264 | [2025-12-08 17:21:55,264] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
2025-12-08 22:51:55.265 | [2025-12-08 17:21:55,264] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
2025-12-08 22:51:55.270 | [2025-12-08 17:21:55,269] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
2025-12-08 22:51:55.271 | [2025-12-08 17:21:55,271] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 22:51:55.275 | [2025-12-08 17:21:55,274] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 22:51:55.275 | [2025-12-08 17:21:55,274] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-08 22:51:55.277 | [2025-12-08 17:21:55,277] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
2025-12-09 07:32:46.480 | ===> User
2025-12-09 07:32:46.483 | uid=0(root) gid=0(root) groups=0(root)
2025-12-09 07:32:46.483 | ===> Configuring ...
2025-12-09 07:32:46.491 | Running in Zookeeper mode...
2025-12-09 07:32:56.607 | ===> Running preflight checks ... 
2025-12-09 07:32:56.723 | ===> Check if /var/lib/kafka/data is writable ...
2025-12-09 07:32:58.411 | ===> Check if Zookeeper is healthy ...
2025-12-09 07:33:02.829 | [2025-12-09 02:03:02,828] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.836 | [2025-12-09 02:03:02,829] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.836 | [2025-12-09 02:03:02,836] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.837 | [2025-12-09 02:03:02,837] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.837 | [2025-12-09 02:03:02,837] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,837] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-clients-7.4.0-ccs.jar:/usr/share/java/cp-base-new/kafka_2.13-7.4.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.11.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.4.0-ccs.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/kafka-raft-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.2-1.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.4.0-ccs.jar:/usr/share/java/cp-base-new/snappy-java-1.1.8.4.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/common-utils-7.4.0.jar:/usr/share/java/cp-base-new/kafka-metadata-7.4.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/logredactor-1.0.11.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/utility-belt-7.4.0.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.4.0-ccs.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.4.0.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/kafka-server-common-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/jose4j-0.7.9.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.6.0.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.838 | [2025-12-09 02:03:02,838] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.839 | [2025-12-09 02:03:02,838] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.839 | [2025-12-09 02:03:02,838] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.839 | [2025-12-09 02:03:02,839] INFO Client environment:os.memory.max=1932MB (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.839 | [2025-12-09 02:03:02,839] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.862 | [2025-12-09 02:03:02,861] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@646be2c3 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:02.916 | [2025-12-09 02:03:02,915] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-09 07:33:03.054 | [2025-12-09 02:03:03,054] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-09 07:33:03.120 | [2025-12-09 02:03:03,118] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:03.220 | [2025-12-09 02:03:03,217] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:03.220 | [2025-12-09 02:03:03,218] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:03.262 | [2025-12-09 02:03:03,257] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:03.263 | java.net.ConnectException: Connection refused
2025-12-09 07:33:03.263 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:03.263 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:03.263 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:03.263 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:04.378 | [2025-12-09 02:03:04,376] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:04.378 | [2025-12-09 02:03:04,376] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:04.381 | [2025-12-09 02:03:04,379] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:04.381 | java.net.ConnectException: Connection refused
2025-12-09 07:33:04.381 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:04.381 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:04.381 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:04.381 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:05.486 | [2025-12-09 02:03:05,483] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:05.486 | [2025-12-09 02:03:05,484] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:05.516 | [2025-12-09 02:03:05,488] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:05.516 | java.net.ConnectException: Connection refused
2025-12-09 07:33:05.516 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:05.516 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:05.516 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:05.516 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:06.621 | [2025-12-09 02:03:06,620] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:06.621 | [2025-12-09 02:03:06,620] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:06.631 | [2025-12-09 02:03:06,622] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:06.631 | java.net.ConnectException: Connection refused
2025-12-09 07:33:06.631 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:06.631 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:06.631 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:06.631 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:07.768 | [2025-12-09 02:03:07,768] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:07.768 | [2025-12-09 02:03:07,768] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:07.780 | [2025-12-09 02:03:07,779] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:07.780 | java.net.ConnectException: Connection refused
2025-12-09 07:33:07.780 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:07.780 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:07.780 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:07.780 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:08.896 | [2025-12-09 02:03:08,896] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:08.896 | [2025-12-09 02:03:08,896] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:08.904 | [2025-12-09 02:03:08,904] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:08.905 | java.net.ConnectException: Connection refused
2025-12-09 07:33:08.905 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:08.905 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:08.905 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:08.905 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:10.037 | [2025-12-09 02:03:10,023] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:10.050 | [2025-12-09 02:03:10,049] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:10.065 | [2025-12-09 02:03:10,064] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:10.065 | java.net.ConnectException: Connection refused
2025-12-09 07:33:10.065 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:10.065 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:10.065 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:10.065 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:11.191 | [2025-12-09 02:03:11,183] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:11.196 | [2025-12-09 02:03:11,183] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:11.206 | [2025-12-09 02:03:11,186] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:11.207 | java.net.ConnectException: Connection refused
2025-12-09 07:33:11.207 | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2025-12-09 07:33:11.207 | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
2025-12-09 07:33:11.207 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
2025-12-09 07:33:11.207 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:12.353 | [2025-12-09 02:03:12,318] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:12.353 | [2025-12-09 02:03:12,319] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:12.353 | [2025-12-09 02:03:12,323] INFO Socket connection established, initiating session, client: /172.18.0.4:49886, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:12.702 | [2025-12-09 02:03:12,701] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:12.702 | EndOfStreamException: Unable to read additional data from server sessionid 0x0, likely server has closed socket
2025-12-09 07:33:12.702 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-09 07:33:12.702 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-09 07:33:12.702 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:14.347 | [2025-12-09 02:03:14,347] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:14.348 | [2025-12-09 02:03:14,347] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:14.349 | [2025-12-09 02:03:14,349] INFO Socket connection established, initiating session, client: /172.18.0.4:49898, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:14.475 | [2025-12-09 02:03:14,475] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x100037778930000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:14.802 | [2025-12-09 02:03:14,801] WARN An exception was thrown while closing send thread for session 0x100037778930000. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:14.802 | EndOfStreamException: Unable to read additional data from server sessionid 0x100037778930000, likely server has closed socket
2025-12-09 07:33:14.802 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
2025-12-09 07:33:14.802 | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
2025-12-09 07:33:14.802 | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-12-09 07:33:14.945 | [2025-12-09 02:03:14,944] INFO EventThread shut down for session: 0x100037778930000 (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:14.946 | [2025-12-09 02:03:14,945] INFO Session: 0x100037778930000 closed (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:15.048 | Using log4j config /etc/kafka/log4j.properties
2025-12-09 07:33:15.323 | ===> Launching ... 
2025-12-09 07:33:15.367 | ===> Launching kafka ... 
2025-12-09 07:33:24.611 | [2025-12-09 02:03:24,606] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
2025-12-09 07:33:29.894 | [2025-12-09 02:03:29,893] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
2025-12-09 07:33:31.541 | [2025-12-09 02:03:31,533] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-12-09 07:33:31.556 | [2025-12-09 02:03:31,556] INFO starting (kafka.server.KafkaServer)
2025-12-09 07:33:31.573 | [2025-12-09 02:03:31,572] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
2025-12-09 07:33:31.774 | [2025-12-09 02:03:31,773] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
2025-12-09 07:33:31.972 | [2025-12-09 02:03:31,971] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.972 | [2025-12-09 02:03:31,972] INFO Client environment:host.name=1b5d41578a05 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.973 | [2025-12-09 02:03:31,972] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.973 | [2025-12-09 02:03:31,973] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.973 | [2025-12-09 02:03:31,973] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.975 | [2025-12-09 02:03:31,973] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.975 | [2025-12-09 02:03:31,973] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.975 | [2025-12-09 02:03:31,974] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.975 | [2025-12-09 02:03:31,974] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.976 | [2025-12-09 02:03:31,975] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.976 | [2025-12-09 02:03:31,976] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.976 | [2025-12-09 02:03:31,976] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.976 | [2025-12-09 02:03:31,976] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.977 | [2025-12-09 02:03:31,976] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.977 | [2025-12-09 02:03:31,977] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.977 | [2025-12-09 02:03:31,977] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.977 | [2025-12-09 02:03:31,977] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:31.977 | [2025-12-09 02:03:31,977] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:32.004 | [2025-12-09 02:03:32,004] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@63a270c9 (org.apache.zookeeper.ZooKeeper)
2025-12-09 07:33:32.089 | [2025-12-09 02:03:32,089] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
2025-12-09 07:33:32.167 | [2025-12-09 02:03:32,167] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:32.208 | [2025-12-09 02:03:32,207] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-09 07:33:32.243 | [2025-12-09 02:03:32,242] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:32.270 | [2025-12-09 02:03:32,270] INFO Socket connection established, initiating session, client: /172.18.0.4:32828, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:32.409 | [2025-12-09 02:03:32,408] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x100037778930001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
2025-12-09 07:33:32.453 | [2025-12-09 02:03:32,453] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
2025-12-09 07:33:35.533 | [2025-12-09 02:03:35,532] INFO Cluster ID = xTa4oP5DQQqhwOcnPmb7dg (kafka.server.KafkaServer)
2025-12-09 07:33:35.876 | [2025-12-09 02:03:35,875] INFO KafkaConfig values: 
2025-12-09 07:33:35.876 | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
2025-12-09 07:33:35.876 | 	alter.config.policy.class.name = null
2025-12-09 07:33:35.876 | 	alter.log.dirs.replication.quota.window.num = 11
2025-12-09 07:33:35.876 | 	alter.log.dirs.replication.quota.window.size.seconds = 1
2025-12-09 07:33:35.876 | 	authorizer.class.name = 
2025-12-09 07:33:35.876 | 	auto.create.topics.enable = true
2025-12-09 07:33:35.876 | 	auto.include.jmx.reporter = true
2025-12-09 07:33:35.876 | 	auto.leader.rebalance.enable = true
2025-12-09 07:33:35.876 | 	background.threads = 10
2025-12-09 07:33:35.876 | 	broker.heartbeat.interval.ms = 2000
2025-12-09 07:33:35.876 | 	broker.id = 1
2025-12-09 07:33:35.876 | 	broker.id.generation.enable = true
2025-12-09 07:33:35.876 | 	broker.rack = null
2025-12-09 07:33:35.876 | 	broker.session.timeout.ms = 9000
2025-12-09 07:33:35.876 | 	client.quota.callback.class = null
2025-12-09 07:33:35.876 | 	compression.type = producer
2025-12-09 07:33:35.876 | 	connection.failed.authentication.delay.ms = 100
2025-12-09 07:33:35.876 | 	connections.max.idle.ms = 600000
2025-12-09 07:33:35.876 | 	connections.max.reauth.ms = 0
2025-12-09 07:33:35.876 | 	control.plane.listener.name = null
2025-12-09 07:33:35.876 | 	controlled.shutdown.enable = true
2025-12-09 07:33:35.876 | 	controlled.shutdown.max.retries = 3
2025-12-09 07:33:35.876 | 	controlled.shutdown.retry.backoff.ms = 5000
2025-12-09 07:33:35.876 | 	controller.listener.names = null
2025-12-09 07:33:35.876 | 	controller.quorum.append.linger.ms = 25
2025-12-09 07:33:35.876 | 	controller.quorum.election.backoff.max.ms = 1000
2025-12-09 07:33:35.877 | 	controller.quorum.election.timeout.ms = 1000
2025-12-09 07:33:35.877 | 	controller.quorum.fetch.timeout.ms = 2000
2025-12-09 07:33:35.877 | 	controller.quorum.request.timeout.ms = 2000
2025-12-09 07:33:35.877 | 	controller.quorum.retry.backoff.ms = 20
2025-12-09 07:33:35.877 | 	controller.quorum.voters = []
2025-12-09 07:33:35.877 | 	controller.quota.window.num = 11
2025-12-09 07:33:35.877 | 	controller.quota.window.size.seconds = 1
2025-12-09 07:33:35.877 | 	controller.socket.timeout.ms = 30000
2025-12-09 07:33:35.877 | 	create.topic.policy.class.name = null
2025-12-09 07:33:35.877 | 	default.replication.factor = 1
2025-12-09 07:33:35.877 | 	delegation.token.expiry.check.interval.ms = 3600000
2025-12-09 07:33:35.877 | 	delegation.token.expiry.time.ms = 86400000
2025-12-09 07:33:35.877 | 	delegation.token.master.key = null
2025-12-09 07:33:35.877 | 	delegation.token.max.lifetime.ms = 604800000
2025-12-09 07:33:35.877 | 	delegation.token.secret.key = null
2025-12-09 07:33:35.877 | 	delete.records.purgatory.purge.interval.requests = 1
2025-12-09 07:33:35.877 | 	delete.topic.enable = true
2025-12-09 07:33:35.877 | 	early.start.listeners = null
2025-12-09 07:33:35.877 | 	fetch.max.bytes = 57671680
2025-12-09 07:33:35.877 | 	fetch.purgatory.purge.interval.requests = 1000
2025-12-09 07:33:35.877 | 	group.initial.rebalance.delay.ms = 3000
2025-12-09 07:33:35.877 | 	group.max.session.timeout.ms = 1800000
2025-12-09 07:33:35.877 | 	group.max.size = 2147483647
2025-12-09 07:33:35.877 | 	group.min.session.timeout.ms = 6000
2025-12-09 07:33:35.877 | 	initial.broker.registration.timeout.ms = 60000
2025-12-09 07:33:35.877 | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
2025-12-09 07:33:35.877 | 	inter.broker.protocol.version = 3.4-IV0
2025-12-09 07:33:35.877 | 	kafka.metrics.polling.interval.secs = 10
2025-12-09 07:33:35.877 | 	kafka.metrics.reporters = []
2025-12-09 07:33:35.877 | 	leader.imbalance.check.interval.seconds = 300
2025-12-09 07:33:35.877 | 	leader.imbalance.per.broker.percentage = 10
2025-12-09 07:33:35.877 | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
2025-12-09 07:33:35.878 | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
2025-12-09 07:33:35.878 | 	log.cleaner.backoff.ms = 15000
2025-12-09 07:33:35.878 | 	log.cleaner.dedupe.buffer.size = 134217728
2025-12-09 07:33:35.878 | 	log.cleaner.delete.retention.ms = 86400000
2025-12-09 07:33:35.879 | 	log.cleaner.enable = true
2025-12-09 07:33:35.879 | 	log.cleaner.io.buffer.load.factor = 0.9
2025-12-09 07:33:35.879 | 	log.cleaner.io.buffer.size = 524288
2025-12-09 07:33:35.879 | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
2025-12-09 07:33:35.879 | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
2025-12-09 07:33:35.879 | 	log.cleaner.min.cleanable.ratio = 0.5
2025-12-09 07:33:35.879 | 	log.cleaner.min.compaction.lag.ms = 0
2025-12-09 07:33:35.879 | 	log.cleaner.threads = 1
2025-12-09 07:33:35.879 | 	log.cleanup.policy = [delete]
2025-12-09 07:33:35.879 | 	log.dir = /tmp/kafka-logs
2025-12-09 07:33:35.879 | 	log.dirs = /var/lib/kafka/data
2025-12-09 07:33:35.879 | 	log.flush.interval.messages = 9223372036854775807
2025-12-09 07:33:35.879 | 	log.flush.interval.ms = null
2025-12-09 07:33:35.879 | 	log.flush.offset.checkpoint.interval.ms = 60000
2025-12-09 07:33:35.879 | 	log.flush.scheduler.interval.ms = 9223372036854775807
2025-12-09 07:33:35.879 | 	log.flush.start.offset.checkpoint.interval.ms = 60000
2025-12-09 07:33:35.879 | 	log.index.interval.bytes = 4096
2025-12-09 07:33:35.879 | 	log.index.size.max.bytes = 10485760
2025-12-09 07:33:35.879 | 	log.message.downconversion.enable = true
2025-12-09 07:33:35.879 | 	log.message.format.version = 3.0-IV1
2025-12-09 07:33:35.879 | 	log.message.timestamp.difference.max.ms = 9223372036854775807
2025-12-09 07:33:35.879 | 	log.message.timestamp.type = CreateTime
2025-12-09 07:33:35.879 | 	log.preallocate = false
2025-12-09 07:33:35.879 | 	log.retention.bytes = -1
2025-12-09 07:33:35.879 | 	log.retention.check.interval.ms = 300000
2025-12-09 07:33:35.879 | 	log.retention.hours = 168
2025-12-09 07:33:35.879 | 	log.retention.minutes = null
2025-12-09 07:33:35.879 | 	log.retention.ms = null
2025-12-09 07:33:35.879 | 	log.roll.hours = 168
2025-12-09 07:33:35.879 | 	log.roll.jitter.hours = 0
2025-12-09 07:33:35.879 | 	log.roll.jitter.ms = null
2025-12-09 07:33:35.879 | 	log.roll.ms = null
2025-12-09 07:33:35.879 | 	log.segment.bytes = 1073741824
2025-12-09 07:33:35.879 | 	log.segment.delete.delay.ms = 60000
2025-12-09 07:33:35.879 | 	max.connection.creation.rate = 2147483647
2025-12-09 07:33:35.879 | 	max.connections = 2147483647
2025-12-09 07:33:35.879 | 	max.connections.per.ip = 2147483647
2025-12-09 07:33:35.879 | 	max.connections.per.ip.overrides = 
2025-12-09 07:33:35.879 | 	max.incremental.fetch.session.cache.slots = 1000
2025-12-09 07:33:35.879 | 	message.max.bytes = 1048588
2025-12-09 07:33:35.879 | 	metadata.log.dir = null
2025-12-09 07:33:35.879 | 	metadata.log.max.record.bytes.between.snapshots = 20971520
2025-12-09 07:33:35.879 | 	metadata.log.max.snapshot.interval.ms = 3600000
2025-12-09 07:33:35.879 | 	metadata.log.segment.bytes = 1073741824
2025-12-09 07:33:35.879 | 	metadata.log.segment.min.bytes = 8388608
2025-12-09 07:33:35.879 | 	metadata.log.segment.ms = 604800000
2025-12-09 07:33:35.879 | 	metadata.max.idle.interval.ms = 500
2025-12-09 07:33:35.879 | 	metadata.max.retention.bytes = 104857600
2025-12-09 07:33:35.879 | 	metadata.max.retention.ms = 604800000
2025-12-09 07:33:35.879 | 	metric.reporters = []
2025-12-09 07:33:35.879 | 	metrics.num.samples = 2
2025-12-09 07:33:35.879 | 	metrics.recording.level = INFO
2025-12-09 07:33:35.879 | 	metrics.sample.window.ms = 30000
2025-12-09 07:33:35.879 | 	min.insync.replicas = 1
2025-12-09 07:33:35.879 | 	node.id = 1
2025-12-09 07:33:35.879 | 	num.io.threads = 8
2025-12-09 07:33:35.879 | 	num.network.threads = 3
2025-12-09 07:33:35.879 | 	num.partitions = 1
2025-12-09 07:33:35.879 | 	num.recovery.threads.per.data.dir = 1
2025-12-09 07:33:35.879 | 	num.replica.alter.log.dirs.threads = null
2025-12-09 07:33:35.879 | 	num.replica.fetchers = 1
2025-12-09 07:33:35.879 | 	offset.metadata.max.bytes = 4096
2025-12-09 07:33:35.879 | 	offsets.commit.required.acks = -1
2025-12-09 07:33:35.879 | 	offsets.commit.timeout.ms = 5000
2025-12-09 07:33:35.879 | 	offsets.load.buffer.size = 5242880
2025-12-09 07:33:35.879 | 	offsets.retention.check.interval.ms = 600000
2025-12-09 07:33:35.879 | 	offsets.retention.minutes = 10080
2025-12-09 07:33:35.879 | 	offsets.topic.compression.codec = 0
2025-12-09 07:33:35.879 | 	offsets.topic.num.partitions = 50
2025-12-09 07:33:35.879 | 	offsets.topic.replication.factor = 1
2025-12-09 07:33:35.879 | 	offsets.topic.segment.bytes = 104857600
2025-12-09 07:33:35.879 | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
2025-12-09 07:33:35.879 | 	password.encoder.iterations = 4096
2025-12-09 07:33:35.879 | 	password.encoder.key.length = 128
2025-12-09 07:33:35.879 | 	password.encoder.keyfactory.algorithm = null
2025-12-09 07:33:35.879 | 	password.encoder.old.secret = null
2025-12-09 07:33:35.879 | 	password.encoder.secret = null
2025-12-09 07:33:35.879 | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
2025-12-09 07:33:35.879 | 	process.roles = []
2025-12-09 07:33:35.879 | 	producer.id.expiration.check.interval.ms = 600000
2025-12-09 07:33:35.879 | 	producer.id.expiration.ms = 86400000
2025-12-09 07:33:35.879 | 	producer.purgatory.purge.interval.requests = 1000
2025-12-09 07:33:35.879 | 	queued.max.request.bytes = -1
2025-12-09 07:33:35.880 | 	queued.max.requests = 500
2025-12-09 07:33:35.880 | 	quota.window.num = 11
2025-12-09 07:33:35.880 | 	quota.window.size.seconds = 1
2025-12-09 07:33:35.880 | 	remote.log.index.file.cache.total.size.bytes = 1073741824
2025-12-09 07:33:35.880 | 	remote.log.manager.task.interval.ms = 30000
2025-12-09 07:33:35.880 | 	remote.log.manager.task.retry.backoff.max.ms = 30000
2025-12-09 07:33:35.880 | 	remote.log.manager.task.retry.backoff.ms = 500
2025-12-09 07:33:35.880 | 	remote.log.manager.task.retry.jitter = 0.2
2025-12-09 07:33:35.880 | 	remote.log.manager.thread.pool.size = 10
2025-12-09 07:33:35.880 | 	remote.log.metadata.manager.class.name = null
2025-12-09 07:33:35.880 | 	remote.log.metadata.manager.class.path = null
2025-12-09 07:33:35.880 | 	remote.log.metadata.manager.impl.prefix = null
2025-12-09 07:33:35.880 | 	remote.log.metadata.manager.listener.name = null
2025-12-09 07:33:35.880 | 	remote.log.reader.max.pending.tasks = 100
2025-12-09 07:33:35.880 | 	remote.log.reader.threads = 10
2025-12-09 07:33:35.880 | 	remote.log.storage.manager.class.name = null
2025-12-09 07:33:35.880 | 	remote.log.storage.manager.class.path = null
2025-12-09 07:33:35.880 | 	remote.log.storage.manager.impl.prefix = null
2025-12-09 07:33:35.880 | 	remote.log.storage.system.enable = false
2025-12-09 07:33:35.880 | 	replica.fetch.backoff.ms = 1000
2025-12-09 07:33:35.880 | 	replica.fetch.max.bytes = 1048576
2025-12-09 07:33:35.880 | 	replica.fetch.min.bytes = 1
2025-12-09 07:33:35.880 | 	replica.fetch.response.max.bytes = 10485760
2025-12-09 07:33:35.880 | 	replica.fetch.wait.max.ms = 500
2025-12-09 07:33:35.880 | 	replica.high.watermark.checkpoint.interval.ms = 5000
2025-12-09 07:33:35.880 | 	replica.lag.time.max.ms = 30000
2025-12-09 07:33:35.880 | 	replica.selector.class = null
2025-12-09 07:33:35.880 | 	replica.socket.receive.buffer.bytes = 65536
2025-12-09 07:33:35.880 | 	replica.socket.timeout.ms = 30000
2025-12-09 07:33:35.880 | 	replication.quota.window.num = 11
2025-12-09 07:33:35.880 | 	replication.quota.window.size.seconds = 1
2025-12-09 07:33:35.880 | 	request.timeout.ms = 30000
2025-12-09 07:33:35.880 | 	reserved.broker.max.id = 1000
2025-12-09 07:33:35.880 | 	sasl.client.callback.handler.class = null
2025-12-09 07:33:35.880 | 	sasl.enabled.mechanisms = [GSSAPI]
2025-12-09 07:33:35.880 | 	sasl.jaas.config = null
2025-12-09 07:33:35.880 | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
2025-12-09 07:33:35.880 | 	sasl.kerberos.min.time.before.relogin = 60000
2025-12-09 07:33:35.880 | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
2025-12-09 07:33:35.880 | 	sasl.kerberos.service.name = null
2025-12-09 07:33:35.880 | 	sasl.kerberos.ticket.renew.jitter = 0.05
2025-12-09 07:33:35.880 | 	sasl.kerberos.ticket.renew.window.factor = 0.8
2025-12-09 07:33:35.880 | 	sasl.login.callback.handler.class = null
2025-12-09 07:33:35.880 | 	sasl.login.class = null
2025-12-09 07:33:35.880 | 	sasl.login.connect.timeout.ms = null
2025-12-09 07:33:35.880 | 	sasl.login.read.timeout.ms = null
2025-12-09 07:33:35.880 | 	sasl.login.refresh.buffer.seconds = 300
2025-12-09 07:33:35.880 | 	sasl.login.refresh.min.period.seconds = 60
2025-12-09 07:33:35.880 | 	sasl.login.refresh.window.factor = 0.8
2025-12-09 07:33:35.880 | 	sasl.login.refresh.window.jitter = 0.05
2025-12-09 07:33:35.880 | 	sasl.login.retry.backoff.max.ms = 10000
2025-12-09 07:33:35.880 | 	sasl.login.retry.backoff.ms = 100
2025-12-09 07:33:35.880 | 	sasl.mechanism.controller.protocol = GSSAPI
2025-12-09 07:33:35.880 | 	sasl.mechanism.inter.broker.protocol = GSSAPI
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.clock.skew.seconds = 30
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.expected.audience = null
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.expected.issuer = null
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2025-12-09 07:33:35.880 | 	sasl.oauthbearer.jwks.endpoint.url = null
2025-12-09 07:33:35.881 | 	sasl.oauthbearer.scope.claim.name = scope
2025-12-09 07:33:35.881 | 	sasl.oauthbearer.sub.claim.name = sub
2025-12-09 07:33:35.881 | 	sasl.oauthbearer.token.endpoint.url = null
2025-12-09 07:33:35.881 | 	sasl.server.callback.handler.class = null
2025-12-09 07:33:35.881 | 	sasl.server.max.receive.size = 524288
2025-12-09 07:33:35.881 | 	security.inter.broker.protocol = PLAINTEXT
2025-12-09 07:33:35.881 | 	security.providers = null
2025-12-09 07:33:35.881 | 	socket.connection.setup.timeout.max.ms = 30000
2025-12-09 07:33:35.881 | 	socket.connection.setup.timeout.ms = 10000
2025-12-09 07:33:35.881 | 	socket.listen.backlog.size = 50
2025-12-09 07:33:35.881 | 	socket.receive.buffer.bytes = 102400
2025-12-09 07:33:35.881 | 	socket.request.max.bytes = 104857600
2025-12-09 07:33:35.881 | 	socket.send.buffer.bytes = 102400
2025-12-09 07:33:35.881 | 	ssl.cipher.suites = []
2025-12-09 07:33:35.881 | 	ssl.client.auth = none
2025-12-09 07:33:35.881 | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2025-12-09 07:33:35.881 | 	ssl.endpoint.identification.algorithm = https
2025-12-09 07:33:35.881 | 	ssl.engine.factory.class = null
2025-12-09 07:33:35.881 | 	ssl.key.password = null
2025-12-09 07:33:35.881 | 	ssl.keymanager.algorithm = SunX509
2025-12-09 07:33:35.881 | 	ssl.keystore.certificate.chain = null
2025-12-09 07:33:35.881 | 	ssl.keystore.key = null
2025-12-09 07:33:35.881 | 	ssl.keystore.location = null
2025-12-09 07:33:35.881 | 	ssl.keystore.password = null
2025-12-09 07:33:35.881 | 	ssl.keystore.type = JKS
2025-12-09 07:33:35.881 | 	ssl.principal.mapping.rules = DEFAULT
2025-12-09 07:33:35.881 | 	ssl.protocol = TLSv1.3
2025-12-09 07:33:35.881 | 	ssl.provider = null
2025-12-09 07:33:35.881 | 	ssl.secure.random.implementation = null
2025-12-09 07:33:35.881 | 	ssl.trustmanager.algorithm = PKIX
2025-12-09 07:33:35.881 | 	ssl.truststore.certificates = null
2025-12-09 07:33:35.881 | 	ssl.truststore.location = null
2025-12-09 07:33:35.881 | 	ssl.truststore.password = null
2025-12-09 07:33:35.881 | 	ssl.truststore.type = JKS
2025-12-09 07:33:35.882 | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
2025-12-09 07:33:35.882 | 	transaction.max.timeout.ms = 900000
2025-12-09 07:33:35.882 | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
2025-12-09 07:33:35.882 | 	transaction.state.log.load.buffer.size = 5242880
2025-12-09 07:33:35.882 | 	transaction.state.log.min.isr = 1
2025-12-09 07:33:35.882 | 	transaction.state.log.num.partitions = 50
2025-12-09 07:33:35.882 | 	transaction.state.log.replication.factor = 1
2025-12-09 07:33:35.882 | 	transaction.state.log.segment.bytes = 104857600
2025-12-09 07:33:35.882 | 	transactional.id.expiration.ms = 604800000
2025-12-09 07:33:35.882 | 	unclean.leader.election.enable = false
2025-12-09 07:33:35.882 | 	zookeeper.clientCnxnSocket = null
2025-12-09 07:33:35.882 | 	zookeeper.connect = zookeeper:2181
2025-12-09 07:33:35.882 | 	zookeeper.connection.timeout.ms = null
2025-12-09 07:33:35.882 | 	zookeeper.max.in.flight.requests = 10
2025-12-09 07:33:35.882 | 	zookeeper.metadata.migration.enable = false
2025-12-09 07:33:35.882 | 	zookeeper.session.timeout.ms = 18000
2025-12-09 07:33:35.882 | 	zookeeper.set.acl = false
2025-12-09 07:33:35.882 | 	zookeeper.ssl.cipher.suites = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.client.enable = false
2025-12-09 07:33:35.882 | 	zookeeper.ssl.crl.enable = false
2025-12-09 07:33:35.882 | 	zookeeper.ssl.enabled.protocols = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
2025-12-09 07:33:35.882 | 	zookeeper.ssl.keystore.location = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.keystore.password = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.keystore.type = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.ocsp.enable = false
2025-12-09 07:33:35.882 | 	zookeeper.ssl.protocol = TLSv1.2
2025-12-09 07:33:35.882 | 	zookeeper.ssl.truststore.location = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.truststore.password = null
2025-12-09 07:33:35.882 | 	zookeeper.ssl.truststore.type = null
2025-12-09 07:33:35.882 |  (kafka.server.KafkaConfig)
2025-12-09 07:33:36.483 | [2025-12-09 02:03:36,456] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-09 07:33:36.513 | [2025-12-09 02:03:36,453] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-09 07:33:36.513 | [2025-12-09 02:03:36,502] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-09 07:33:36.515 | [2025-12-09 02:03:36,461] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
2025-12-09 07:33:37.443 | [2025-12-09 02:03:37,431] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:37.479 | [2025-12-09 02:03:37,477] INFO Skipping recovery for all logs in /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
2025-12-09 07:33:39.333 | [2025-12-09 02:03:39,333] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:39.569 | [2025-12-09 02:03:39,568] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-31, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 1317ms (1/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:39.617 | [2025-12-09 02:03:39,617] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:39.644 | [2025-12-09 02:03:39,643] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-38, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 74ms (2/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:39.676 | [2025-12-09 02:03:39,676] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:39.692 | [2025-12-09 02:03:39,692] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-22, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 47ms (3/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:39.741 | [2025-12-09 02:03:39,740] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:39.784 | [2025-12-09 02:03:39,784] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-20, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 90ms (4/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:39.912 | [2025-12-09 02:03:39,909] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:39.958 | [2025-12-09 02:03:39,958] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-34, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 173ms (5/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.014 | [2025-12-09 02:03:40,013] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.025 | [2025-12-09 02:03:40,025] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-0, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 66ms (6/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.072 | [2025-12-09 02:03:40,072] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.092 | [2025-12-09 02:03:40,091] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-26, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 63ms (7/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.202 | [2025-12-09 02:03:40,202] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.240 | [2025-12-09 02:03:40,240] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-45, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 147ms (8/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.353 | [2025-12-09 02:03:40,353] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.385 | [2025-12-09 02:03:40,384] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-17, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 137ms (9/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.459 | [2025-12-09 02:03:40,458] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.481 | [2025-12-09 02:03:40,481] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-27, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 96ms (10/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.526 | [2025-12-09 02:03:40,523] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.610 | [2025-12-09 02:03:40,610] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-47, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 126ms (11/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.766 | [2025-12-09 02:03:40,763] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.812 | [2025-12-09 02:03:40,783] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-43, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 173ms (12/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:40.883 | [2025-12-09 02:03:40,883] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:40.933 | [2025-12-09 02:03:40,932] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-48, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 126ms (13/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.040 | [2025-12-09 02:03:41,040] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.052 | [2025-12-09 02:03:41,051] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-39, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 125ms (14/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.129 | [2025-12-09 02:03:41,128] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.139 | [2025-12-09 02:03:41,137] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-3, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 85ms (15/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.183 | [2025-12-09 02:03:41,183] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.211 | [2025-12-09 02:03:41,209] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-30, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (16/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.322 | [2025-12-09 02:03:41,314] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.338 | [2025-12-09 02:03:41,333] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-32, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 123ms (17/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.416 | [2025-12-09 02:03:41,415] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.431 | [2025-12-09 02:03:41,431] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-21, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 97ms (18/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.448 | [2025-12-09 02:03:41,448] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.454 | [2025-12-09 02:03:41,453] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-11, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (19/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.509 | [2025-12-09 02:03:41,509] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.526 | [2025-12-09 02:03:41,525] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-14, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (20/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.580 | [2025-12-09 02:03:41,580] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.585 | [2025-12-09 02:03:41,585] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-24, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 58ms (21/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.610 | [2025-12-09 02:03:41,610] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.620 | [2025-12-09 02:03:41,620] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-41, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (22/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.725 | [2025-12-09 02:03:41,724] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.744 | [2025-12-09 02:03:41,744] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-23, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 122ms (23/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.836 | [2025-12-09 02:03:41,835] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:41.881 | [2025-12-09 02:03:41,880] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-49, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 136ms (24/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:41.990 | [2025-12-09 02:03:41,990] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.007 | [2025-12-09 02:03:42,007] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-13, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 126ms (25/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.177 | [2025-12-09 02:03:42,176] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.209 | [2025-12-09 02:03:42,209] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-37, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 201ms (26/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.330 | [2025-12-09 02:03:42,329] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.373 | [2025-12-09 02:03:42,372] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-10, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 163ms (27/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.448 | [2025-12-09 02:03:42,448] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.466 | [2025-12-09 02:03:42,466] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-46, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (28/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.506 | [2025-12-09 02:03:42,506] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.516 | [2025-12-09 02:03:42,515] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-7, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 48ms (29/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.573 | [2025-12-09 02:03:42,572] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.589 | [2025-12-09 02:03:42,588] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-18, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 73ms (30/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.697 | [2025-12-09 02:03:42,693] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.699 | [2025-12-09 02:03:42,699] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-44, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 110ms (31/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.740 | [2025-12-09 02:03:42,740] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.819 | [2025-12-09 02:03:42,816] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-16, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 104ms (32/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:42.918 | [2025-12-09 02:03:42,911] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:42.942 | [2025-12-09 02:03:42,942] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-25, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 125ms (33/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.090 | [2025-12-09 02:03:43,082] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.091 | [2025-12-09 02:03:43,089] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-12, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 147ms (34/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.202 | [2025-12-09 02:03:43,201] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.221 | [2025-12-09 02:03:43,221] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-28, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 132ms (35/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.338 | [2025-12-09 02:03:43,338] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.352 | [2025-12-09 02:03:43,352] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-33, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 130ms (36/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.395 | [2025-12-09 02:03:43,394] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.402 | [2025-12-09 02:03:43,402] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-4, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 50ms (37/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.488 | [2025-12-09 02:03:43,486] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.490 | [2025-12-09 02:03:43,490] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-19, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 88ms (38/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.605 | [2025-12-09 02:03:43,600] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.628 | [2025-12-09 02:03:43,626] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-40, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 136ms (39/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.696 | [2025-12-09 02:03:43,695] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.749 | [2025-12-09 02:03:43,749] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-35, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 122ms (40/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:43.902 | [2025-12-09 02:03:43,902] INFO Deleted producer state snapshot /var/lib/kafka/data/__consumer_offsets-8/00000000000000000006.snapshot (kafka.log.SnapshotFile)
2025-12-09 07:33:43.927 | [2025-12-09 02:03:43,927] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 98 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:43.928 | [2025-12-09 02:03:43,927] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 98 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.007 | [2025-12-09 02:03:44,006] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/__consumer_offsets-8/00000000000000000098.snapshot,98)' (kafka.log.ProducerStateManager)
2025-12-09 07:33:44.152 | [2025-12-09 02:03:44,152] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Producer state recovery took 224ms for snapshot load and 0ms for segment recovery from offset 98 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.175 | [2025-12-09 02:03:44,174] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-8, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=98) with 1 segments in 425ms (41/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:44.328 | [2025-12-09 02:03:44,327] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.362 | [2025-12-09 02:03:44,361] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-15, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 186ms (42/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:44.677 | [2025-12-09 02:03:44,673] INFO Deleted producer state snapshot /var/lib/kafka/data/booking-email-0/00000000000000000001.snapshot (kafka.log.SnapshotFile)
2025-12-09 07:33:44.678 | [2025-12-09 02:03:44,675] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Loading producer state till offset 171 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.678 | [2025-12-09 02:03:44,675] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 171 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.678 | [2025-12-09 02:03:44,675] INFO [ProducerStateManager partition=booking-email-0] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/booking-email-0/00000000000000000171.snapshot,171)' (kafka.log.ProducerStateManager)
2025-12-09 07:33:44.747 | [2025-12-09 02:03:44,744] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Producer state recovery took 69ms for snapshot load and 0ms for segment recovery from offset 171 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.792 | [2025-12-09 02:03:44,792] INFO Completed load of Log(dir=/var/lib/kafka/data/booking-email-0, topicId=ZZs51CcXT3m5RospnghyvA, topic=booking-email, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=171) with 1 segments in 430ms (43/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:44.872 | [2025-12-09 02:03:44,870] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.875 | [2025-12-09 02:03:44,875] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-42, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 83ms (44/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:44.909 | [2025-12-09 02:03:44,909] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.914 | [2025-12-09 02:03:44,914] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-36, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (45/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:44.964 | [2025-12-09 02:03:44,959] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:44.984 | [2025-12-09 02:03:44,976] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-5, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 62ms (46/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:45.051 | [2025-12-09 02:03:45,048] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:45.087 | [2025-12-09 02:03:45,087] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-6, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 110ms (47/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:45.213 | [2025-12-09 02:03:45,207] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:45.215 | [2025-12-09 02:03:45,215] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-1, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 127ms (48/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:45.252 | [2025-12-09 02:03:45,251] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:45.296 | [2025-12-09 02:03:45,296] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-9, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 77ms (49/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:45.332 | [2025-12-09 02:03:45,329] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:45.337 | [2025-12-09 02:03:45,337] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-29, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 40ms (50/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:45.467 | [2025-12-09 02:03:45,467] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2025-12-09 07:33:45.486 | [2025-12-09 02:03:45,484] INFO Completed load of Log(dir=/var/lib/kafka/data/__consumer_offsets-2, topicId=s1of94BtTGS8K-UMhA2LCA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 146ms (51/51 completed in /var/lib/kafka/data) (kafka.log.LogManager)
2025-12-09 07:33:45.569 | [2025-12-09 02:03:45,561] INFO Loaded 51 logs in 8126ms. (kafka.log.LogManager)
2025-12-09 07:33:45.569 | [2025-12-09 02:03:45,563] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
2025-12-09 07:33:45.667 | [2025-12-09 02:03:45,657] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
2025-12-09 07:33:45.849 | [2025-12-09 02:03:45,849] INFO Starting the log cleaner (kafka.log.LogCleaner)
2025-12-09 07:33:46.474 | [2025-12-09 02:03:46,461] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
2025-12-09 07:33:46.816 | [2025-12-09 02:03:46,796] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
2025-12-09 07:33:47.093 | [2025-12-09 02:03:47,090] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
2025-12-09 07:33:47.479 | [2025-12-09 02:03:47,471] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-09 07:33:52.692 | [2025-12-09 02:03:52,692] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-09 07:33:52.852 | [2025-12-09 02:03:52,851] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
2025-12-09 07:33:53.115 | [2025-12-09 02:03:53,115] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
2025-12-09 07:33:53.121 | [2025-12-09 02:03:53,118] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
2025-12-09 07:33:53.121 | [2025-12-09 02:03:53,119] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
2025-12-09 07:33:53.161 | [2025-12-09 02:03:53,160] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
2025-12-09 07:33:53.389 | [2025-12-09 02:03:53,383] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
2025-12-09 07:33:53.699 | [2025-12-09 02:03:53,697] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:53.702 | [2025-12-09 02:03:53,698] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:53.709 | [2025-12-09 02:03:53,708] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:53.712 | [2025-12-09 02:03:53,708] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:53.969 | [2025-12-09 02:03:53,968] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
2025-12-09 07:33:54.300 | [2025-12-09 02:03:54,298] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
2025-12-09 07:33:54.584 | [2025-12-09 02:03:54,584] INFO Stat of the created znode at /brokers/ids/1 is: 204,204,1765245834495,1765245834495,1,0,0,72061405696819201,270,0,204
2025-12-09 07:33:54.584 |  (kafka.zk.KafkaZkClient)
2025-12-09 07:33:54.586 | [2025-12-09 02:03:54,586] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 204 (kafka.zk.KafkaZkClient)
2025-12-09 07:33:55.089 | [2025-12-09 02:03:55,088] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
2025-12-09 07:33:55.216 | [2025-12-09 02:03:55,216] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:55.354 | [2025-12-09 02:03:55,354] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:55.392 | [2025-12-09 02:03:55,392] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 4 and epoch zk version is now 4 (kafka.controller.KafkaController)
2025-12-09 07:33:55.394 | [2025-12-09 02:03:55,393] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:55.447 | [2025-12-09 02:03:55,447] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
2025-12-09 07:33:55.540 | [2025-12-09 02:03:55,536] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
2025-12-09 07:33:55.616 | [2025-12-09 02:03:55,612] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
2025-12-09 07:33:55.617 | [2025-12-09 02:03:55,615] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:33:55.670 | [2025-12-09 02:03:55,670] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
2025-12-09 07:33:55.846 | [2025-12-09 02:03:55,846] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:33:55.917 | [2025-12-09 02:03:55,916] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 204) (kafka.controller.KafkaController)
2025-12-09 07:33:56.113 | [2025-12-09 02:03:56,110] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
2025-12-09 07:33:56.231 | [2025-12-09 02:03:56,231] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-09 07:33:56.286 | [2025-12-09 02:03:56,286] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
2025-12-09 07:33:56.437 | [2025-12-09 02:03:56,436] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
2025-12-09 07:33:56.786 | [2025-12-09 02:03:56,782] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
2025-12-09 07:33:57.421 | [2025-12-09 02:03:57,421] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
2025-12-09 07:33:57.440 | [2025-12-09 02:03:57,439] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
2025-12-09 07:33:57.456 | [2025-12-09 02:03:57,455] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
2025-12-09 07:33:57.474 | [2025-12-09 02:03:57,473] INFO [Controller id=1] Current list of topics in the cluster: HashSet(booking-email, __consumer_offsets) (kafka.controller.KafkaController)
2025-12-09 07:33:57.509 | [2025-12-09 02:03:57,509] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
2025-12-09 07:33:57.759 | [2025-12-09 02:03:57,759] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
2025-12-09 07:33:57.761 | [2025-12-09 02:03:57,761] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
2025-12-09 07:33:57.764 | [2025-12-09 02:03:57,764] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
2025-12-09 07:33:57.881 | [2025-12-09 02:03:57,880] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
2025-12-09 07:33:57.917 | [2025-12-09 02:03:57,917] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
2025-12-09 07:33:58.096 | [2025-12-09 02:03:58,042] INFO [Controller id=1 epoch=4] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
2025-12-09 07:33:58.151 | [2025-12-09 02:03:58,150] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
2025-12-09 07:33:58.377 | [2025-12-09 02:03:58,376] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
2025-12-09 07:33:58.552 | [2025-12-09 02:03:58,552] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-09 07:33:58.582 | [2025-12-09 02:03:58,581] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
2025-12-09 07:33:59.089 | [2025-12-09 02:03:59,088] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-46 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.146 | [2025-12-09 02:03:59,146] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-37 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.148 | [2025-12-09 02:03:59,147] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-8 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.148 | [2025-12-09 02:03:59,148] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-49 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.148 | [2025-12-09 02:03:59,148] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-21 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.149 | [2025-12-09 02:03:59,149] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-20 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.152 | [2025-12-09 02:03:59,151] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-17 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.152 | [2025-12-09 02:03:59,152] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-19 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.157 | [2025-12-09 02:03:59,152] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-7 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.158 | [2025-12-09 02:03:59,153] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-43 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.158 | [2025-12-09 02:03:59,153] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-30 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.158 | [2025-12-09 02:03:59,154] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-35 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.158 | [2025-12-09 02:03:59,156] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-27 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.159 | [2025-12-09 02:03:59,158] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.167 | [2025-12-09 02:03:59,167] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-40 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.168 | [2025-12-09 02:03:59,168] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-47 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.169 | [2025-12-09 02:03:59,168] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-10 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.169 | [2025-12-09 02:03:59,169] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-4 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.170 | [2025-12-09 02:03:59,170] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-31 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.178 | [2025-12-09 02:03:59,177] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-16 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.179 | [2025-12-09 02:03:59,179] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-23 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.179 | [2025-12-09 02:03:59,179] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-26 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.180 | [2025-12-09 02:03:59,180] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-39 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.183 | [2025-12-09 02:03:59,183] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-2 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.195 | [2025-12-09 02:03:59,195] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-34 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.196 | [2025-12-09 02:03:59,196] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-24 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.199 | [2025-12-09 02:03:59,199] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition booking-email-0 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.200 | [2025-12-09 02:03:59,200] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-32 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.201 | [2025-12-09 02:03:59,200] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-41 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.201 | [2025-12-09 02:03:59,201] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-5 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.202 | [2025-12-09 02:03:59,202] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-15 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.203 | [2025-12-09 02:03:59,202] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-1 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.203 | [2025-12-09 02:03:59,203] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-9 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.204 | [2025-12-09 02:03:59,204] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-45 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.204 | [2025-12-09 02:03:59,204] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-36 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.205 | [2025-12-09 02:03:59,205] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-48 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.217 | [2025-12-09 02:03:59,217] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-3 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.218 | [2025-12-09 02:03:59,217] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-18 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.229 | [2025-12-09 02:03:59,228] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-44 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.229 | [2025-12-09 02:03:59,229] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-11 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.238 | [2025-12-09 02:03:59,237] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-25 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.241 | [2025-12-09 02:03:59,240] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-29 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.242 | [2025-12-09 02:03:59,242] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-6 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.242 | [2025-12-09 02:03:59,242] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-42 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.243 | [2025-12-09 02:03:59,243] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-28 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.247 | [2025-12-09 02:03:59,246] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-12 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.256 | [2025-12-09 02:03:59,256] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-38 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.258 | [2025-12-09 02:03:59,258] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-33 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.259 | [2025-12-09 02:03:59,258] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-14 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.259 | [2025-12-09 02:03:59,259] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-13 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.261 | [2025-12-09 02:03:59,261] TRACE [Controller id=1 epoch=4] Changed state of replica 1 for partition __consumer_offsets-22 from OnlineReplica to OnlineReplica (state.change.logger)
2025-12-09 07:33:59.592 | [2025-12-09 02:03:59,591] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
2025-12-09 07:33:59.600 | [2025-12-09 02:03:59,600] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
2025-12-09 07:33:59.604 | [2025-12-09 02:03:59,603] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
2025-12-09 07:33:59.606 | [2025-12-09 02:03:59,606] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
2025-12-09 07:33:59.606 | [2025-12-09 02:03:59,606] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
2025-12-09 07:33:59.606 | [2025-12-09 02:03:59,606] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
2025-12-09 07:33:59.606 | [2025-12-09 02:03:59,606] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
2025-12-09 07:33:59.607 | [2025-12-09 02:03:59,606] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
2025-12-09 07:33:59.607 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
2025-12-09 07:33:59.607 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
2025-12-09 07:33:59.607 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,607] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,608] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,609] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,609] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,609] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
2025-12-09 07:33:59.609 | [2025-12-09 02:03:59,609] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
2025-12-09 07:33:59.610 | [2025-12-09 02:03:59,610] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
2025-12-09 07:33:59.610 | [2025-12-09 02:03:59,610] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
2025-12-09 07:33:59.610 | [2025-12-09 02:03:59,610] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
2025-12-09 07:33:59.611 | [2025-12-09 02:03:59,610] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
2025-12-09 07:33:59.616 | [2025-12-09 02:03:59,615] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
2025-12-09 07:33:59.616 | [2025-12-09 02:03:59,616] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
2025-12-09 07:33:59.616 | [2025-12-09 02:03:59,616] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
2025-12-09 07:33:59.616 | [2025-12-09 02:03:59,616] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
2025-12-09 07:33:59.616 | [2025-12-09 02:03:59,616] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
2025-12-09 07:33:59.617 | [2025-12-09 02:03:59,617] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition booking-email-0 (state.change.logger)
2025-12-09 07:33:59.617 | [2025-12-09 02:03:59,617] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
2025-12-09 07:33:59.617 | [2025-12-09 02:03:59,617] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
2025-12-09 07:33:59.617 | [2025-12-09 02:03:59,617] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
2025-12-09 07:33:59.617 | [2025-12-09 02:03:59,617] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
2025-12-09 07:33:59.618 | [2025-12-09 02:03:59,618] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
2025-12-09 07:33:59.618 | [2025-12-09 02:03:59,618] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
2025-12-09 07:33:59.618 | [2025-12-09 02:03:59,618] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
2025-12-09 07:33:59.618 | [2025-12-09 02:03:59,618] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
2025-12-09 07:33:59.627 | [2025-12-09 02:03:59,626] TRACE [Controller id=1 epoch=4] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
2025-12-09 07:33:59.745 | [2025-12-09 02:03:59,736] INFO [Controller id=1 epoch=4] Sending LeaderAndIsr request to broker 1 with 51 become-leader and 0 become-follower partitions (state.change.logger)
2025-12-09 07:33:59.761 | [2025-12-09 02:03:59,750] INFO [Controller id=1 epoch=4] Sending UpdateMetadata request to brokers HashSet(1) for 51 partitions (state.change.logger)
2025-12-09 07:33:59.776 | [2025-12-09 02:03:59,771] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
2025-12-09 07:34:00.032 | [2025-12-09 02:04:00,031] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=booking-email,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
2025-12-09 07:34:00.033 | [2025-12-09 02:04:00,033] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
2025-12-09 07:34:00.085 | [2025-12-09 02:04:00,083] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
2025-12-09 07:34:00.131 | [2025-12-09 02:04:00,130] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(__consumer_offsets-13 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, booking-email-0 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
2025-12-09 07:34:00.133 | [2025-12-09 02:04:00,132] INFO [Controller id=1] Ready to serve as the new controller with epoch 4 (kafka.controller.KafkaController)
2025-12-09 07:34:00.300 | [2025-12-09 02:04:00,217] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
2025-12-09 07:34:00.359 | [2025-12-09 02:04:00,358] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
2025-12-09 07:34:00.361 | [2025-12-09 02:04:00,360] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
2025-12-09 07:34:00.376 | [2025-12-09 02:04:00,376] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
2025-12-09 07:34:00.377 | [2025-12-09 02:04:00,377] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
2025-12-09 07:34:00.380 | [2025-12-09 02:04:00,380] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
2025-12-09 07:34:00.444 | [2025-12-09 02:04:00,443] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
2025-12-09 07:34:00.632 | [2025-12-09 02:04:00,631] INFO Kafka version: 7.4.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
2025-12-09 07:34:00.649 | [2025-12-09 02:04:00,648] INFO Kafka commitId: 30969fa33c185e880b9e02044761dfaac013151d (org.apache.kafka.common.utils.AppInfoParser)
2025-12-09 07:34:00.649 | [2025-12-09 02:04:00,648] INFO Kafka startTimeMs: 1765245840445 (org.apache.kafka.common.utils.AppInfoParser)
2025-12-09 07:34:00.679 | [2025-12-09 02:04:00,678] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
2025-12-09 07:34:00.787 | [2025-12-09 02:04:00,786] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-09 07:34:00.791 | [2025-12-09 02:04:00,789] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2025-12-09 07:34:01.010 | [2025-12-09 02:04:01,010] TRACE [Controller id=1 epoch=4] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-09 07:34:01.093 | [2025-12-09 02:04:01,093] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-12-09 07:34:01.116 | [2025-12-09 02:04:01,116] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.117 | [2025-12-09 02:04:01,116] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.117 | [2025-12-09 02:04:01,117] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.133 | [2025-12-09 02:04:01,133] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.133 | [2025-12-09 02:04:01,133] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.134 | [2025-12-09 02:04:01,133] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.134 | [2025-12-09 02:04:01,134] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.134 | [2025-12-09 02:04:01,134] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.135 | [2025-12-09 02:04:01,134] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.135 | [2025-12-09 02:04:01,135] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.135 | [2025-12-09 02:04:01,135] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.135 | [2025-12-09 02:04:01,135] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.135 | [2025-12-09 02:04:01,135] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.145 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.146 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.146 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.146 | [2025-12-09 02:04:01,145] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.146 | [2025-12-09 02:04:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.146 | [2025-12-09 02:04:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.146 | [2025-12-09 02:04:01,146] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,155] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.156 | [2025-12-09 02:04:01,156] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.157 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.159 | [2025-12-09 02:04:01,157] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 4 (state.change.logger)
2025-12-09 07:34:01.683 | [2025-12-09 02:04:01,682] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-09 07:34:01.684 | [2025-12-09 02:04:01,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-09 07:34:01.684 | [2025-12-09 02:04:01,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-09 07:34:01.684 | [2025-12-09 02:04:01,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-09 07:34:01.684 | [2025-12-09 02:04:01,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-09 07:34:01.684 | [2025-12-09 02:04:01,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,684] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-09 07:34:01.685 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,685] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-09 07:34:01.686 | [2025-12-09 02:04:01,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-09 07:34:01.687 | [2025-12-09 02:04:01,687] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-09 07:34:01.695 | [2025-12-09 02:04:01,695] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-09 07:34:01.696 | [2025-12-09 02:04:01,695] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-09 07:34:01.696 | [2025-12-09 02:04:01,696] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 4 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-09 07:34:01.699 | [2025-12-09 02:04:01,698] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, booking-email-0, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
2025-12-09 07:34:01.699 | [2025-12-09 02:04:01,699] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 4 as part of the become-leader transition for 51 partitions (state.change.logger)
2025-12-09 07:34:01.778 | [2025-12-09 02:04:01,778] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:01.782 | [2025-12-09 02:04:01,782] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:01.851 | [2025-12-09 02:04:01,851] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:01.856 | [2025-12-09 02:04:01,855] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:01.885 | [2025-12-09 02:04:01,885] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:01.887 | [2025-12-09 02:04:01,887] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:01.929 | [2025-12-09 02:04:01,929] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:01.930 | [2025-12-09 02:04:01,929] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.016 | [2025-12-09 02:04:02,016] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.026 | [2025-12-09 02:04:02,025] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.045 | [2025-12-09 02:04:02,045] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.045 | [2025-12-09 02:04:02,045] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.070 | [2025-12-09 02:04:02,070] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.070 | [2025-12-09 02:04:02,070] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.137 | [2025-12-09 02:04:02,137] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.147 | [2025-12-09 02:04:02,145] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.177 | [2025-12-09 02:04:02,177] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.177 | [2025-12-09 02:04:02,177] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.209 | [2025-12-09 02:04:02,209] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.210 | [2025-12-09 02:04:02,209] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.231 | [2025-12-09 02:04:02,231] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.231 | [2025-12-09 02:04:02,231] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.241 | [2025-12-09 02:04:02,240] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.244 | [2025-12-09 02:04:02,243] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.264 | [2025-12-09 02:04:02,264] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.265 | [2025-12-09 02:04:02,265] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.281 | [2025-12-09 02:04:02,276] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.281 | [2025-12-09 02:04:02,277] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.321 | [2025-12-09 02:04:02,321] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.321 | [2025-12-09 02:04:02,321] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.381 | [2025-12-09 02:04:02,379] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.389 | [2025-12-09 02:04:02,379] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.416 | [2025-12-09 02:04:02,416] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.423 | [2025-12-09 02:04:02,417] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.431 | [2025-12-09 02:04:02,431] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.431 | [2025-12-09 02:04:02,431] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.446 | [2025-12-09 02:04:02,446] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.447 | [2025-12-09 02:04:02,447] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.457 | [2025-12-09 02:04:02,456] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.457 | [2025-12-09 02:04:02,457] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.475 | [2025-12-09 02:04:02,474] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.475 | [2025-12-09 02:04:02,475] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.500 | [2025-12-09 02:04:02,499] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.500 | [2025-12-09 02:04:02,499] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.527 | [2025-12-09 02:04:02,527] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.536 | [2025-12-09 02:04:02,535] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.563 | [2025-12-09 02:04:02,563] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.563 | [2025-12-09 02:04:02,563] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.572 | [2025-12-09 02:04:02,572] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.574 | [2025-12-09 02:04:02,574] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.598 | [2025-12-09 02:04:02,598] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.599 | [2025-12-09 02:04:02,599] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.628 | [2025-12-09 02:04:02,628] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.628 | [2025-12-09 02:04:02,628] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.636 | [2025-12-09 02:04:02,635] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.636 | [2025-12-09 02:04:02,636] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.661 | [2025-12-09 02:04:02,661] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.661 | [2025-12-09 02:04:02,661] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.707 | [2025-12-09 02:04:02,706] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.709 | [2025-12-09 02:04:02,709] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.751 | [2025-12-09 02:04:02,751] INFO [Partition booking-email-0 broker=1] Log loaded for partition booking-email-0 with initial high watermark 171 (kafka.cluster.Partition)
2025-12-09 07:34:02.751 | [2025-12-09 02:04:02,751] INFO [Broker id=1] Leader booking-email-0 with topic id Some(ZZs51CcXT3m5RospnghyvA) starts at leader epoch 0 from offset 171 with partition epoch 0, high watermark 171, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.751 | [2025-12-09 02:04:02,751] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.751 | [2025-12-09 02:04:02,751] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.794 | [2025-12-09 02:04:02,788] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.794 | [2025-12-09 02:04:02,788] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.802 | [2025-12-09 02:04:02,802] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.802 | [2025-12-09 02:04:02,802] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.811 | [2025-12-09 02:04:02,811] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 98 (kafka.cluster.Partition)
2025-12-09 07:34:02.811 | [2025-12-09 02:04:02,811] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 98 with partition epoch 0, high watermark 98, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.812 | [2025-12-09 02:04:02,812] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.812 | [2025-12-09 02:04:02,812] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.819 | [2025-12-09 02:04:02,819] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.819 | [2025-12-09 02:04:02,819] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.830 | [2025-12-09 02:04:02,830] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.832 | [2025-12-09 02:04:02,831] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.854 | [2025-12-09 02:04:02,846] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.854 | [2025-12-09 02:04:02,852] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.869 | [2025-12-09 02:04:02,868] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.869 | [2025-12-09 02:04:02,869] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.879 | [2025-12-09 02:04:02,878] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.879 | [2025-12-09 02:04:02,879] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.886 | [2025-12-09 02:04:02,885] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.886 | [2025-12-09 02:04:02,886] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.900 | [2025-12-09 02:04:02,900] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.901 | [2025-12-09 02:04:02,901] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.915 | [2025-12-09 02:04:02,914] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.915 | [2025-12-09 02:04:02,915] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.927 | [2025-12-09 02:04:02,927] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.927 | [2025-12-09 02:04:02,927] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.934 | [2025-12-09 02:04:02,934] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.934 | [2025-12-09 02:04:02,934] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.940 | [2025-12-09 02:04:02,940] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.940 | [2025-12-09 02:04:02,940] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.947 | [2025-12-09 02:04:02,947] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.947 | [2025-12-09 02:04:02,947] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.955 | [2025-12-09 02:04:02,954] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.955 | [2025-12-09 02:04:02,955] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.971 | [2025-12-09 02:04:02,970] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.971 | [2025-12-09 02:04:02,971] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.979 | [2025-12-09 02:04:02,979] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
2025-12-09 07:34:02.980 | [2025-12-09 02:04:02,980] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(s1of94BtTGS8K-UMhA2LCA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
2025-12-09 07:34:02.988 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,988] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition booking-email-0 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
2025-12-09 07:34:02.989 | [2025-12-09 02:04:02,989] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
2025-12-09 07:34:02.990 | [2025-12-09 02:04:02,990] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 4 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
2025-12-09 07:34:03.004 | [2025-12-09 02:04:02,998] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.010 | [2025-12-09 02:04:03,009] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.036 | [2025-12-09 02:04:03,036] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 15 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.037 | [2025-12-09 02:04:03,037] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.037 | [2025-12-09 02:04:03,037] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.037 | [2025-12-09 02:04:03,037] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.037 | [2025-12-09 02:04:03,037] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.038 | [2025-12-09 02:04:03,038] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,039] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.039 | [2025-12-09 02:04:03,037] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.040 | [2025-12-09 02:04:03,040] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.043 | [2025-12-09 02:04:03,043] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.044 | [2025-12-09 02:04:03,044] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.044 | [2025-12-09 02:04:03,044] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,046] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,040] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.046 | [2025-12-09 02:04:03,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.047 | [2025-12-09 02:04:03,047] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.048 | [2025-12-09 02:04:03,048] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,048] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,049] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,049] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,049] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,049] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,049] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.049 | [2025-12-09 02:04:03,048] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 9 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.050 | [2025-12-09 02:04:03,050] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.051 | [2025-12-09 02:04:03,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.051 | [2025-12-09 02:04:03,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.051 | [2025-12-09 02:04:03,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.051 | [2025-12-09 02:04:03,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.051 | [2025-12-09 02:04:03,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.051 | [2025-12-09 02:04:03,051] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 12 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.052 | [2025-12-09 02:04:03,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.052 | [2025-12-09 02:04:03,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.053 | [2025-12-09 02:04:03,053] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.053 | [2025-12-09 02:04:03,053] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.053 | [2025-12-09 02:04:03,053] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.053 | [2025-12-09 02:04:03,053] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.053 | [2025-12-09 02:04:03,053] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.054 | [2025-12-09 02:04:03,054] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.054 | [2025-12-09 02:04:03,054] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.054 | [2025-12-09 02:04:03,054] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.054 | [2025-12-09 02:04:03,053] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.054 | [2025-12-09 02:04:03,054] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.055 | [2025-12-09 02:04:03,055] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.056 | [2025-12-09 02:04:03,056] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.056 | [2025-12-09 02:04:03,054] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.057 | [2025-12-09 02:04:03,057] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.057 | [2025-12-09 02:04:03,057] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.057 | [2025-12-09 02:04:03,057] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.057 | [2025-12-09 02:04:03,057] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.057 | [2025-12-09 02:04:03,057] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.057 | [2025-12-09 02:04:03,057] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.058 | [2025-12-09 02:04:03,058] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.059 | [2025-12-09 02:04:03,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.066 | [2025-12-09 02:04:03,066] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 19 milliseconds for epoch 0, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.069 | [2025-12-09 02:04:03,069] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 21 milliseconds for epoch 0, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.069 | [2025-12-09 02:04:03,069] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.069 | [2025-12-09 02:04:03,069] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.070 | [2025-12-09 02:04:03,069] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.070 | [2025-12-09 02:04:03,070] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.070 | [2025-12-09 02:04:03,070] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.070 | [2025-12-09 02:04:03,070] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.074 | [2025-12-09 02:04:03,070] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 21 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.074 | [2025-12-09 02:04:03,072] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 23 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.074 | [2025-12-09 02:04:03,072] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.074 | [2025-12-09 02:04:03,072] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.074 | [2025-12-09 02:04:03,072] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.074 | [2025-12-09 02:04:03,073] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.088 | [2025-12-09 02:04:03,076] INFO [Broker id=1] Finished LeaderAndIsr request in 1978ms correlationId 1 from controller 1 for 51 partitions (state.change.logger)
2025-12-09 07:34:03.088 | [2025-12-09 02:04:03,088] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.089 | [2025-12-09 02:04:03,089] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.090 | [2025-12-09 02:04:03,090] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 38 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.110 | [2025-12-09 02:04:03,108] TRACE [Controller id=1 epoch=4] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=s1of94BtTGS8K-UMhA2LCA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)]), LeaderAndIsrTopicError(topicId=ZZs51CcXT3m5RospnghyvA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-09 07:34:03.121 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition booking-email-0 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,119] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.122 | [2025-12-09 02:04:03,120] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.124 | [2025-12-09 02:04:03,123] INFO [Broker id=1] Add 51 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 4 with correlation id 2 (state.change.logger)
2025-12-09 07:34:03.156 | [2025-12-09 02:04:03,136] TRACE [Controller id=1 epoch=4] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
2025-12-09 07:34:03.249 | [2025-12-09 02:04:03,249] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-21231a7f-cdbb-4d2b-93f2-66343cdbbebd, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 1. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.287 | [2025-12-09 02:04:03,287] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-7891edec-db8a-4e84-9bc9-688e4ea74854, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.7, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 3. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.287 | [2025-12-09 02:04:03,287] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 5. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.306 | [2025-12-09 02:04:03,306] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 6. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.306 | [2025-12-09 02:04:03,306] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 6. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 7. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 7. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 7. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 8. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 8. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-ba4858f8-0954-40a0-8d29-0db041ed391c, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 8. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 8. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 9. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 9. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.307 | [2025-12-09 02:04:03,307] INFO Loaded member MemberMetadata(memberId=consumer-email-group-2-53f8737b-bbc7-48ad-af19-f5ee3a003c6c, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 9. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 10. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-3-ce826543-fbbd-44e4-a7c4-d2a5ebbbe1a8, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 10. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 11. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-e32a0e2d-0f8d-451c-bfee-292c36149bb1, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 12. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 12. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 13. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-e32a0e2d-0f8d-451c-bfee-292c36149bb1, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 13. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.308 | [2025-12-09 02:04:03,308] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 13. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.309 | [2025-12-09 02:04:03,309] INFO Loaded member MemberMetadata(memberId=consumer-email-group-2-12b19fa6-4520-46d9-a9ca-ea7ab0af047b, groupInstanceId=None, clientId=consumer-email-group-2, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 14. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.317 | [2025-12-09 02:04:03,317] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 14. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.317 | [2025-12-09 02:04:03,317] INFO Loaded member MemberMetadata(memberId=consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 14. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.317 | [2025-12-09 02:04:03,317] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 15. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.318 | [2025-12-09 02:04:03,318] INFO Loaded member MemberMetadata(memberId=consumer-email-group-3-efd82b5b-d002-485c-9b44-80cff87d34e7, groupInstanceId=None, clientId=consumer-email-group-3, clientHost=/172.18.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 15. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.319 | [2025-12-09 02:04:03,319] INFO Loaded member MemberMetadata(memberId=consumer-email-group-1-86162a5c-4c73-4e19-a452-0edd431a8695, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group email-group with generation 16. (kafka.coordinator.group.GroupMetadata$)
2025-12-09 07:34:03.323 | [2025-12-09 02:04:03,322] INFO [GroupCoordinator 1]: Loading group metadata for email-group with generation 17 (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:03.324 | [2025-12-09 02:04:03,324] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 271 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.326 | [2025-12-09 02:04:03,325] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 272 milliseconds for epoch 0, of which 271 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.326 | [2025-12-09 02:04:03,326] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 273 milliseconds for epoch 0, of which 273 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.326 | [2025-12-09 02:04:03,326] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 272 milliseconds for epoch 0, of which 272 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.329 | [2025-12-09 02:04:03,329] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 273 milliseconds for epoch 0, of which 270 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.331 | [2025-12-09 02:04:03,331] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 273 milliseconds for epoch 0, of which 272 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.332 | [2025-12-09 02:04:03,332] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 275 milliseconds for epoch 0, of which 274 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.333 | [2025-12-09 02:04:03,333] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 275 milliseconds for epoch 0, of which 274 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.333 | [2025-12-09 02:04:03,333] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 275 milliseconds for epoch 0, of which 275 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.335 | [2025-12-09 02:04:03,335] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 275 milliseconds for epoch 0, of which 275 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.336 | [2025-12-09 02:04:03,336] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 278 milliseconds for epoch 0, of which 277 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.336 | [2025-12-09 02:04:03,336] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 278 milliseconds for epoch 0, of which 278 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.336 | [2025-12-09 02:04:03,336] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 277 milliseconds for epoch 0, of which 277 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.336 | [2025-12-09 02:04:03,336] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 277 milliseconds for epoch 0, of which 277 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.336 | [2025-12-09 02:04:03,336] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 277 milliseconds for epoch 0, of which 277 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.337 | [2025-12-09 02:04:03,337] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 278 milliseconds for epoch 0, of which 278 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:03.337 | [2025-12-09 02:04:03,337] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 278 milliseconds for epoch 0, of which 278 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
2025-12-09 07:34:05.516 | [2025-12-09 02:04:05,516] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-09 07:34:05.516 | [2025-12-09 02:04:05,516] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-09 07:34:05.522 | [2025-12-09 02:04:05,522] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-09 07:34:05.524 | [2025-12-09 02:04:05,523] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
2025-12-09 07:34:08.564 | [2025-12-09 02:04:08,563] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Empty state. Created a new member id consumer-email-group-1-0ac17d90-7e87-4844-b4f2-f9d01050a771 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:08.578 | [2025-12-09 02:04:08,577] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 17 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-0ac17d90-7e87-4844-b4f2-f9d01050a771 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-0ac17d90-7e87-4844-b4f2-f9d01050a771) (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:11.578 | [2025-12-09 02:04:11,578] INFO [GroupCoordinator 1]: Stabilized group email-group generation 18 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:34:11.598 | [2025-12-09 02:04:11,598] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-0ac17d90-7e87-4844-b4f2-f9d01050a771 for group email-group for generation 18. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2025-12-09 07:39:05.471 | [2025-12-09 02:09:05,470] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-12-09 07:39:05.471 | [2025-12-09 02:09:05,470] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-12-09 07:39:05.472 | [2025-12-09 02:09:05,472] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 HashMap() (kafka.controller.KafkaController)
2025-12-09 07:39:05.472 | [2025-12-09 02:09:05,472] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)