#1 [internal] load local bake definitions
#1 reading from stdin 3.14kB done
#1 DONE 0.0s

#2 [configserver internal] load build definition from Dockerfile
#2 transferring dockerfile: 190B 0.1s done
#2 DONE 0.2s

#3 [eurekaserver internal] load build definition from Dockerfile
#3 transferring dockerfile: 188B 0.1s done
#3 DONE 0.2s

#4 [authservice internal] load build definition from Dockerfile
#4 transferring dockerfile: 220B 0.1s done
#4 DONE 0.2s

#5 [flightservice internal] load build definition from Dockerfile
#5 transferring dockerfile: 222B 0.1s done
#5 DONE 0.2s

#6 [bookingservice internal] load build definition from Dockerfile
#6 transferring dockerfile: 224B 0.1s done
#6 DONE 0.2s

#7 [apigateway internal] load build definition from Dockerfile
#7 transferring dockerfile: 218B 0.1s done
#7 DONE 0.2s

#8 [bookingservice internal] load metadata for docker.io/library/maven:3.8.5-openjdk-17
#8 ...

#9 [auth] library/maven:pull token for registry-1.docker.io
#9 DONE 0.0s

#8 [bookingservice internal] load metadata for docker.io/library/maven:3.8.5-openjdk-17
#8 DONE 4.4s

#10 [apigateway internal] load .dockerignore
#10 transferring context: 2B done
#10 DONE 0.1s

#11 [authservice internal] load .dockerignore
#11 transferring context: 2B done
#11 DONE 0.1s

#12 [eurekaserver internal] load .dockerignore
#12 transferring context: 2B done
#12 DONE 0.1s

#13 [configserver internal] load .dockerignore
#13 transferring context: 2B done
#13 DONE 0.1s

#14 [eurekaserver internal] load build context
#14 DONE 0.0s

#15 [bookingservice internal] load .dockerignore
#15 transferring context: 2B 0.0s done
#15 DONE 0.1s

#16 [eurekaserver 1/3] FROM docker.io/library/maven:3.8.5-openjdk-17@sha256:3a9c30b3af6278a8ae0007d3a3bf00fff80ec3ed7ae4eb9bfa1772853101549b
#16 resolve docker.io/library/maven:3.8.5-openjdk-17@sha256:3a9c30b3af6278a8ae0007d3a3bf00fff80ec3ed7ae4eb9bfa1772853101549b
#16 ...

#17 [flightservice internal] load .dockerignore
#17 transferring context: 2B done
#17 DONE 0.1s

#16 [configserver 1/3] FROM docker.io/library/maven:3.8.5-openjdk-17@sha256:3a9c30b3af6278a8ae0007d3a3bf00fff80ec3ed7ae4eb9bfa1772853101549b
#16 resolve docker.io/library/maven:3.8.5-openjdk-17@sha256:3a9c30b3af6278a8ae0007d3a3bf00fff80ec3ed7ae4eb9bfa1772853101549b 0.1s done
#16 DONE 0.4s

#18 [flightservice 2/3] WORKDIR /flightservice
#18 ...

#19 [bookingservice internal] load build context
#19 transferring context: 9.67MB 5.1s
#19 ...

#20 [authservice internal] load build context
#20 ...

#21 [configserver internal] load build context
#21 ...

#20 [authservice internal] load build context
#20 ...

#22 [apigateway internal] load build context
#22 ...

#23 [flightservice internal] load build context
#23 ...

#14 [eurekaserver internal] load build context
#14 ...

#22 [apigateway internal] load build context
#22 transferring context: 13.67MB 10.3s
#22 ...

#24 [configserver 2/3] WORKDIR /configserver
#24 ...

#25 [bookingservice 2/3] WORKDIR /bookingservive
#25 ...

#26 [apigateway 2/3] WORKDIR /apigateway
#26 ...

#27 [eurekaserver 2/3] WORKDIR /eurekaserver
#27 ...

#28 [authservice 2/3] WORKDIR /authservice
#28 ...

#22 [apigateway internal] load build context
#22 ...

#19 [bookingservice internal] load build context
#19 ...

#21 [configserver internal] load build context
#21 ...

#20 [authservice internal] load build context
#20 ...

#27 [eurekaserver 2/3] WORKDIR /eurekaserver
#27 DONE 19.9s

#25 [bookingservice 2/3] WORKDIR /bookingservive
#25 DONE 19.9s

#24 [configserver 2/3] WORKDIR /configserver
#24 DONE 19.9s

#20 [authservice internal] load build context
#20 transferring context: 14.55MB 20.2s
#20 ...

#22 [apigateway internal] load build context
#22 ...

#28 [authservice 2/3] WORKDIR /authservice
#28 DONE 19.9s

#26 [apigateway 2/3] WORKDIR /apigateway
#26 DONE 19.9s

#18 [flightservice 2/3] WORKDIR /flightservice
#18 DONE 19.9s

#22 [apigateway internal] load build context
#22 ...

#14 [eurekaserver internal] load build context
#14 ...

#23 [flightservice internal] load build context
#23 ...

#21 [configserver internal] load build context
#21 transferring context: 40.59MB 22.8s done
#21 DONE 22.8s

#23 [flightservice internal] load build context
#23 ...

#29 [configserver 3/3] COPY target/configserver-0.0.1-SNAPSHOT.jar app.jar
#29 DONE 0.5s

#23 [flightservice internal] load build context
#23 ...

#22 [apigateway internal] load build context
#22 transferring context: 52.93MB 24.9s done
#22 DONE 25.0s

#23 [flightservice internal] load build context
#23 transferring context: 54.29MB 25.1s done
#23 DONE 25.2s

#19 [bookingservice internal] load build context
#19 ...

#30 [apigateway 3/3] COPY target/apigateway-0.0.1-SNAPSHOT.jar app.jar
#30 DONE 0.5s

#19 [bookingservice internal] load build context
#19 ...

#31 [apigateway] exporting to image
#31 exporting layers
#31 ...

#14 [eurekaserver internal] load build context
#14 transferring context: 56.99MB 25.6s done
#14 DONE 25.7s

#32 [flightservice 3/3] COPY target/flightservice-0.0.1-SNAPSHOT.jar app.jar
#32 DONE 0.5s

#33 [flightservice] exporting to image
#33 ...

#34 [eurekaserver 3/3] COPY target/eurekaserver-0.0.1-SNAPSHOT.jar app.jar
#34 DONE 0.3s

#35 [eurekaserver] exporting to image
#35 ...

#20 [authservice internal] load build context
#20 transferring context: 59.70MB 26.3s done
#20 DONE 26.4s

#19 [bookingservice internal] load build context
#19 transferring context: 75.66MB 26.8s done
#19 DONE 26.8s

#36 [authservice 3/3] COPY target/authservice-0.0.1-SNAPSHOT.jar app.jar
#36 DONE 0.5s

#37 [authservice] exporting to image
#37 ...

#38 [bookingservice 3/3] COPY target/bookingservive-0.0.1-SNAPSHOT.jar app.jar
#38 DONE 1.9s

#39 [bookingservice] exporting to image
#39 ...

#40 [configserver] exporting to image
#40 exporting layers 3.6s done
#40 exporting manifest sha256:d81d3397705307e1d9334cda3b3afc385a0f55ae9fb59969a475a92910bedb4b 0.1s done
#40 exporting config sha256:e4e4f37133862eaad02c2950a7cd5fefe7174eb00a8fc37c6954d55ae1f80060 0.1s done
#40 exporting attestation manifest sha256:6ec1a5900449dc535c7d544371aa44f6056ef9e28947483cc56ce9bace510953 0.0s done
#40 exporting manifest list sha256:0be68d2cd5b67834d7dfa33e5e9a59c58d3f00180a80edd72748531d9f12233c 1.4s done
#40 naming to docker.io/library/flight_docker-configserver:latest 0.1s done
#40 unpacking to docker.io/library/flight_docker-configserver:latest 0.9s done
#40 DONE 6.4s

#35 [eurekaserver] exporting to image
#35 ...

#31 [apigateway] exporting to image
#31 exporting layers 5.3s done
#31 exporting manifest sha256:27b64de6ef908fefdad0c5a5618bb14e6e15833b28fdcf7459eaa21b464d3a26 0.1s done
#31 exporting config sha256:4cab8b3bbf8b92360a9fe71248693af6f65762c4e848224fa60e5cd2e2ac03ee 0.1s done
#31 exporting attestation manifest sha256:85eee46d2b8c5a8fb874d3fd746ae47b98b49f750f92d960bcdd5e20f8610a23
#31 ...

#41 [configserver] resolving provenance for metadata file
#41 DONE 0.0s

#31 [apigateway] exporting to image
#31 exporting attestation manifest sha256:85eee46d2b8c5a8fb874d3fd746ae47b98b49f750f92d960bcdd5e20f8610a23 0.1s done
#31 exporting manifest list sha256:1e0125a9ebe2ccf7a27bc427d68ab1d01b409dc103f83f90b22ac0066ef949b2
#31 exporting manifest list sha256:1e0125a9ebe2ccf7a27bc427d68ab1d01b409dc103f83f90b22ac0066ef949b2 0.1s done
#31 naming to docker.io/library/flight_docker-apigateway:latest done
#31 unpacking to docker.io/library/flight_docker-apigateway:latest
#31 unpacking to docker.io/library/flight_docker-apigateway:latest 3.1s done
#31 DONE 10.0s

#37 [authservice] exporting to image
#37 exporting layers 7.0s done
#37 exporting manifest sha256:445623e4245c9f5caa39e9af9386470ba4f854a53dc6e15ee26fe4ab0ed07f5f 0.0s done
#37 exporting config sha256:7a10b7c5636bed54dd24e935df5b36b9691bce959f90a871c1f9e1abd6b4b28b 0.1s done
#37 exporting attestation manifest sha256:14c70a0749a0d7cfdb3bc074e3a1578d7cbb539bf664961f98de1b9d13e40911 0.1s done
#37 exporting manifest list sha256:6c57cf5416f277385779cb0465322f6bb7f31db263e63c6da9d3978d5103a44e 0.1s done
#37 naming to docker.io/library/flight_docker-authservice:latest done
#37 unpacking to docker.io/library/flight_docker-authservice:latest
#37 unpacking to docker.io/library/flight_docker-authservice:latest 1.8s done
#37 DONE 9.3s

#35 [eurekaserver] exporting to image
#35 exporting layers 6.3s done
#35 exporting manifest sha256:7839abe13fe119b5745058ccf478b85b38aecba50bfe8ce9302db8280c532958 0.6s done
#35 exporting config sha256:215a7c77ee4a5860d252ecc55e74b705c5dddb2e5849d79179c4a1b212e34eb8 0.7s done
#35 exporting attestation manifest sha256:9f6dac247a06a08dc9f908e9e84abc8f39be496c84d2abd76f9030fbad152f4a 0.1s done
#35 exporting manifest list sha256:21c74c5a70d6aa94e81a439797d5474c7452c04c58c9df6c8534b06c2c3ea2fd 0.1s done
#35 naming to docker.io/library/flight_docker-eurekaserver:latest done
#35 unpacking to docker.io/library/flight_docker-eurekaserver:latest 2.0s done
#35 DONE 10.0s

#33 [flightservice] exporting to image
#33 exporting layers 6.6s done
#33 exporting manifest sha256:519a8b2a6ebe2a8cc98c48e1ef33fd7556ad4eead973a8b5ae360c747c40c9d2 0.0s done
#33 exporting config sha256:0bb6ad9c9a1c2bf4e08039d8cd274a6a3232ec22e454769a17ab60736f335e10 0.6s done
#33 exporting attestation manifest sha256:6af2a6f72a5f719b8d89446b2c18eeacb81ce287e324fadfd9d1b23b83210383 0.1s done
#33 exporting manifest list sha256:af62f1bfe42c61b37944e5c19f5fc9625260483655fe2155649d1e164f927f01 0.1s done
#33 naming to docker.io/library/flight_docker-flightservice:latest 0.0s done
#33 unpacking to docker.io/library/flight_docker-flightservice:latest 2.0s done
#33 DONE 10.4s

#39 [bookingservice] exporting to image
#39 exporting layers 7.5s done
#39 exporting manifest sha256:60ceaa6bd4d52cb7fba3b60106503155af8e65fe96213f4735a2a4ef79b5a88b 0.1s done
#39 exporting config sha256:48564ccf0987e97eeed8f80be9e863a849969f6cd109b840b62fd405ef3e97ea 0.1s done
#39 exporting attestation manifest sha256:5712df214e02b59e671b80232dce26a3fea5b5637cd5ca590cd76a55fbc4a81f 0.1s done
#39 exporting manifest list sha256:46d09c97b76ee8fd161b70dffe8002135cddfd3c2e705f92a8bb47f386b2f346
#39 exporting manifest list sha256:46d09c97b76ee8fd161b70dffe8002135cddfd3c2e705f92a8bb47f386b2f346 0.1s done
#39 naming to docker.io/library/flight_docker-bookingservice:latest
#39 naming to docker.io/library/flight_docker-bookingservice:latest 0.1s done
#39 unpacking to docker.io/library/flight_docker-bookingservice:latest
#39 ...

#42 [apigateway] resolving provenance for metadata file
#42 DONE 0.8s

#43 [eurekaserver] resolving provenance for metadata file
#43 DONE 0.4s

#44 [flightservice] resolving provenance for metadata file
#44 DONE 0.2s

#45 [authservice] resolving provenance for metadata file
#45 DONE 0.0s

#39 [bookingservice] exporting to image
#39 unpacking to docker.io/library/flight_docker-bookingservice:latest 1.2s done
#39 DONE 9.4s

#46 [bookingservice] resolving provenance for metadata file
#46 DONE 0.0s
Attaching to apigateway, authservice, bookingservice, configserver, eurekaserver, flightservice, kafka, mongodb, zookeeper
zookeeper  | ===> User
zookeeper  | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
zookeeper  | ===> Configuring ...
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.041+00:00"},"s":"I",  "c":"CONTROL",  "id":23285,   "ctx":"-","msg":"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.043+00:00"},"s":"I",  "c":"NETWORK",  "id":4915701, "ctx":"main","msg":"Initialized wire specification","attr":{"spec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":13},"incomingInternalClient":{"minWireVersion":0,"maxWireVersion":13},"outgoing":{"minWireVersion":0,"maxWireVersion":13},"isInternalClient":true}}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.045+00:00"},"s":"W",  "c":"ASIO",     "id":22601,   "ctx":"main","msg":"No TransportLayer configured during NetworkInterface startup"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.046+00:00"},"s":"I",  "c":"NETWORK",  "id":4648601, "ctx":"main","msg":"Implicit TCP FastOpen unavailable. If TCP FastOpen is required, set tcpFastOpenServer, tcpFastOpenClient, and tcpFastOpenQueueSize."}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.048+00:00"},"s":"W",  "c":"ASIO",     "id":22601,   "ctx":"main","msg":"No TransportLayer configured during NetworkInterface startup"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.048+00:00"},"s":"I",  "c":"REPL",     "id":5123008, "ctx":"main","msg":"Successfully registered PrimaryOnlyService","attr":{"service":"TenantMigrationDonorService","ns":"config.tenantMigrationDonors"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.048+00:00"},"s":"I",  "c":"REPL",     "id":5123008, "ctx":"main","msg":"Successfully registered PrimaryOnlyService","attr":{"service":"TenantMigrationRecipientService","ns":"config.tenantMigrationRecipients"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.048+00:00"},"s":"I",  "c":"CONTROL",  "id":5945603, "ctx":"main","msg":"Multi threading initialized"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.049+00:00"},"s":"I",  "c":"CONTROL",  "id":4615611, "ctx":"initandlisten","msg":"MongoDB starting","attr":{"pid":1,"port":27017,"dbPath":"/data/db","architecture":"64-bit","host":"8df559d41726"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.049+00:00"},"s":"I",  "c":"CONTROL",  "id":23403,   "ctx":"initandlisten","msg":"Build Info","attr":{"buildInfo":{"version":"5.0.31","gitVersion":"973237567d45610d6976d5d489dfaaef6a52c2f9","openSSLVersion":"OpenSSL 1.1.1f  31 Mar 2020","modules":[],"allocator":"tcmalloc","environment":{"distmod":"ubuntu2004","distarch":"x86_64","target_arch":"x86_64"}}}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.049+00:00"},"s":"I",  "c":"CONTROL",  "id":51765,   "ctx":"initandlisten","msg":"Operating System","attr":{"os":{"name":"Ubuntu","version":"20.04"}}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.049+00:00"},"s":"I",  "c":"CONTROL",  "id":21951,   "ctx":"initandlisten","msg":"Options set by command line","attr":{"options":{"net":{"bindIp":"*"}}}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.053+00:00"},"s":"I",  "c":"STORAGE",  "id":22270,   "ctx":"initandlisten","msg":"Storage engine to use detected by data files","attr":{"dbpath":"/data/db","storageEngine":"wiredTiger"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.053+00:00"},"s":"I",  "c":"STORAGE",  "id":22297,   "ctx":"initandlisten","msg":"Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem","tags":["startupWarnings"]}
mongodb    | {"t":{"$date":"2025-12-22T19:23:37.053+00:00"},"s":"I",  "c":"STORAGE",  "id":22315,   "ctx":"initandlisten","msg":"Opening WiredTiger","attr":{"config":"create,cache_size=3348M,session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),builtin_extension_config=(zstd=(compression_level=6)),file_manager=(close_idle_time=600,close_scan_interval=10,close_handle_minimum=2000),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress,compact_progress],"}}
kafka      | ===> User
kafka      | uid=0(root) gid=0(root) groups=0(root)
kafka      | ===> Configuring ...
kafka      | Running in Zookeeper mode...
mongodb    | {"t":{"$date":"2025-12-22T19:23:38.272+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431418:272951][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 3 through 4"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:38.572+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431418:572696][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 4 through 4"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.031+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:31323][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_ALL] Main recovery loop: starting at 3/497152 to 4/256"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.236+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:236475][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 3 through 4"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.408+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:408197][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] Recovering log 4 through 4"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.592+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:592259][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] recovery log replay has successfully finished and ran for 1322 milliseconds"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.592+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:592403][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_ALL] Set global recovery timestamp: (0, 0)"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.592+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:592425][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_ALL] Set global oldest timestamp: (0, 0)"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.593+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:593702][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] recovery rollback to stable has successfully finished and ran for 1 milliseconds"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.637+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:637189][1:0x7f75971abc80], WT_SESSION.checkpoint: [WT_VERB_CHECKPOINT_PROGRESS] saving checkpoint snapshot min: 1, snapshot max: 1 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 7178"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.704+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:704627][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] recovery checkpoint has successfully finished and ran for 110 milliseconds"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.704+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"initandlisten","msg":"WiredTiger message","attr":{"message":"[1766431419:704795][1:0x7f75971abc80], txn-recover: [WT_VERB_RECOVERY_PROGRESS] recovery was completed successfully and took 1435ms, including 1322ms for the log replay, 1ms for the rollback to stable, and 110ms for the checkpoint."}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.714+00:00"},"s":"I",  "c":"STORAGE",  "id":4795906, "ctx":"initandlisten","msg":"WiredTiger opened","attr":{"durationMillis":2661}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.716+00:00"},"s":"I",  "c":"RECOVERY", "id":23987,   "ctx":"initandlisten","msg":"WiredTiger recoveryTimestamp","attr":{"recoveryTimestamp":{"$timestamp":{"t":0,"i":0}}}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.831+00:00"},"s":"I",  "c":"STORAGE",  "id":22262,   "ctx":"initandlisten","msg":"Timestamp monitor starting"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.841+00:00"},"s":"W",  "c":"CONTROL",  "id":22120,   "ctx":"initandlisten","msg":"Access control is not enabled for the database. Read and write access to data and configuration is unrestricted","tags":["startupWarnings"]}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.842+00:00"},"s":"W",  "c":"CONTROL",  "id":22178,   "ctx":"initandlisten","msg":"/sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' in this binary version","tags":["startupWarnings"]}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.899+00:00"},"s":"I",  "c":"NETWORK",  "id":4915702, "ctx":"initandlisten","msg":"Updated wire specification","attr":{"oldSpec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":13},"incomingInternalClient":{"minWireVersion":0,"maxWireVersion":13},"outgoing":{"minWireVersion":0,"maxWireVersion":13},"isInternalClient":true},"newSpec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":13},"incomingInternalClient":{"minWireVersion":13,"maxWireVersion":13},"outgoing":{"minWireVersion":13,"maxWireVersion":13},"isInternalClient":true}}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.899+00:00"},"s":"I",  "c":"STORAGE",  "id":5071100, "ctx":"initandlisten","msg":"Clearing temp directory"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.906+00:00"},"s":"I",  "c":"CONTROL",  "id":20536,   "ctx":"initandlisten","msg":"Flow Control is enabled on this deployment"}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.976+00:00"},"s":"I",  "c":"FTDC",     "id":20625,   "ctx":"initandlisten","msg":"Initializing full-time diagnostic data capture","attr":{"dataDirectory":"/data/db/diagnostic.data"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:39.991+00:00"},"s":"I",  "c":"REPL",     "id":6015317, "ctx":"initandlisten","msg":"Setting new configuration state","attr":{"newState":"ConfigReplicationDisabled","oldState":"ConfigPreStart"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:40.068+00:00"},"s":"I",  "c":"NETWORK",  "id":23015,   "ctx":"listener","msg":"Listening on","attr":{"address":"/tmp/mongodb-27017.sock"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:40.069+00:00"},"s":"I",  "c":"NETWORK",  "id":23015,   "ctx":"listener","msg":"Listening on","attr":{"address":"0.0.0.0"}}
mongodb    | {"t":{"$date":"2025-12-22T19:23:40.069+00:00"},"s":"I",  "c":"NETWORK",  "id":23016,   "ctx":"listener","msg":"Waiting for connections","attr":{"port":27017,"ssl":"off"}}
eurekaserver  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
zookeeper     | ===> Running preflight checks ... 
zookeeper     | ===> Check if /var/lib/zookeeper/data is writable ...
zookeeper     | ===> Check if /var/lib/zookeeper/log is writable ...
kafka         | ===> Running preflight checks ... 
kafka         | ===> Check if /var/lib/kafka/data is writable ...
zookeeper     | ===> Launching ... 
zookeeper     | ===> Launching zookeeper ... 
kafka         | ===> Check if Zookeeper is healthy ...
kafka         | [2025-12-22 19:24:01,836] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,839] INFO Client environment:host.name=2475ac2257b9 (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,839] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,839] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,839] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,839] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/kafka-clients-7.4.0-ccs.jar:/usr/share/java/cp-base-new/kafka_2.13-7.4.0-ccs.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.11.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/kafka-storage-7.4.0-ccs.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/kafka-raft-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.2-1.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.4.0-ccs.jar:/usr/share/java/cp-base-new/snappy-java-1.1.8.4.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/common-utils-7.4.0.jar:/usr/share/java/cp-base-new/kafka-metadata-7.4.0-ccs.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/logredactor-1.0.11.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/utility-belt-7.4.0.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.4.0-ccs.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.4.0.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/kafka-server-common-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/jose4j-0.7.9.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.6.0.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:os.memory.free=112MB (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:os.memory.max=1932MB (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,840] INFO Client environment:os.memory.total=122MB (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,866] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@646be2c3 (org.apache.zookeeper.ZooKeeper)
kafka         | [2025-12-22 19:24:01,899] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
kafka         | [2025-12-22 19:24:02,001] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
kafka         | [2025-12-22 19:24:02,077] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
kafka         | [2025-12-22 19:24:03,374] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka         | [2025-12-22 19:24:03,375] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
flightservice  | 
flightservice  |   .   ____          _            __ _ _
flightservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
flightservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
flightservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
flightservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
flightservice  |  =========|_|==============|___/=/_/_/_/
flightservice  | 
flightservice  |  :: Spring Boot ::                (v3.3.1)
flightservice  | 
kafka          | [2025-12-22 19:24:03,448] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
kafka          | java.net.ConnectException: Connection refused
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
kafka          | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
kafka          | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
eurekaserver   | 
eurekaserver   |   .   ____          _            __ _ _
eurekaserver   |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
eurekaserver   | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
eurekaserver   |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
eurekaserver   |   '  |____| .__|_| |_|_| |_\__, | / / / /
eurekaserver   |  =========|_|==============|___/=/_/_/_/
eurekaserver   | 
eurekaserver   |  :: Spring Boot ::                (v3.3.1)
eurekaserver   | 
zookeeper      | [2025-12-22 19:24:03,566] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,605] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,606] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,607] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,607] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,613] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
zookeeper      | [2025-12-22 19:24:03,613] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
zookeeper      | [2025-12-22 19:24:03,613] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
zookeeper      | [2025-12-22 19:24:03,613] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
zookeeper      | [2025-12-22 19:24:03,626] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
zookeeper      | [2025-12-22 19:24:03,627] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,628] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,628] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,628] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,629] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
zookeeper      | [2025-12-22 19:24:03,630] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
configserver   | 
configserver   |   .   ____          _            __ _ _
configserver   |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
configserver   | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
configserver   |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
configserver   |   '  |____| .__|_| |_|_| |_\__, | / / / /
configserver   |  =========|_|==============|___/=/_/_/_/
configserver   | 
configserver   |  :: Spring Boot ::                (v3.3.1)
configserver   | 
apigateway     | 
apigateway     |   .   ____          _            __ _ _
apigateway     |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
apigateway     | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
apigateway     |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
apigateway     |   '  |____| .__|_| |_|_| |_\__, | / / / /
apigateway     |  =========|_|==============|___/=/_/_/_/
apigateway     | 
apigateway     |  :: Spring Boot ::                (v3.3.1)
apigateway     | 
zookeeper      | [2025-12-22 19:24:04,246] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@8317c52 (org.apache.zookeeper.server.ServerMetrics)
zookeeper      | [2025-12-22 19:24:04,307] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
zookeeper      | [2025-12-22 19:24:04,397] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,397] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,419] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,449] INFO Server environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,460] INFO Server environment:host.name=3f513cd5b14d (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,460] INFO Server environment:java.version=11.0.18 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,460] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,460] INFO Server environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:java.class.path=/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:user.name=appuser (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:user.home=/home/appuser (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:user.dir=/home/appuser (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,461] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,462] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,462] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,462] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,462] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,462] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,462] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,463] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,468] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
zookeeper      | [2025-12-22 19:24:04,470] INFO minSessionTimeout set to 4000 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,471] INFO maxSessionTimeout set to 40000 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,501] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
zookeeper      | [2025-12-22 19:24:04,505] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
zookeeper      | [2025-12-22 19:24:04,527] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper      | [2025-12-22 19:24:04,527] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper      | [2025-12-22 19:24:04,528] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper      | [2025-12-22 19:24:04,528] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper      | [2025-12-22 19:24:04,528] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper      | [2025-12-22 19:24:04,528] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
zookeeper      | [2025-12-22 19:24:04,543] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,544] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:04,544] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 clientPortListenBacklog -1 datadir /var/lib/zookeeper/log/version-2 snapdir /var/lib/zookeeper/data/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
kafka          | [2025-12-22 19:24:04,576] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:04,577] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:04,578] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
kafka          | java.net.ConnectException: Connection refused
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
kafka          | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
kafka          | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
authservice    | 
authservice    |   .   ____          _            __ _ _
authservice    |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
authservice    | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
authservice    |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
authservice    |   '  |____| .__|_| |_|_| |_\__, | / / / /
authservice    |  =========|_|==============|___/=/_/_/_/
authservice    |  :: Spring Boot ::                (v3.1.0)
authservice    | 
zookeeper      | [2025-12-22 19:24:05,336] INFO Logging initialized @4495ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
kafka          | [2025-12-22 19:24:05,688] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:05,688] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:05,689] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
kafka          | java.net.ConnectException: Connection refused
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
kafka          | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
kafka          | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
configserver   | 2025-12-22T19:24:06.060Z  INFO 1 --- [configserver] [           main] c.configserver.ConfigserverApplication   : Starting ConfigserverApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/configserver/app.jar started by root in /configserver)
configserver   | 2025-12-22T19:24:06.083Z  INFO 1 --- [configserver] [           main] c.configserver.ConfigserverApplication   : No active profile set, falling back to 1 default profile: "default"
flightservice  | 2025-12-22T19:24:06.082Z  INFO 1 --- [flightservice] [           main] c.f.FlightserviceApplication             : Starting FlightserviceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/flightservice/app.jar started by root in /flightservice)
flightservice  | 2025-12-22T19:24:06.311Z  INFO 1 --- [flightservice] [           main] c.f.FlightserviceApplication             : The following 1 profile is active: "docker"
kafka          | [2025-12-22 19:24:06,830] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:06,831] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:06,832] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
kafka          | java.net.ConnectException: Connection refused
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
kafka          | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
kafka          | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
eurekaserver   | 2025-12-22T19:24:07.085Z  INFO 1 --- [eurekaserver] [           main] c.eurekaserver.EurekaserverApplication   : Starting EurekaserverApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/eurekaserver/app.jar started by root in /eurekaserver)
eurekaserver   | 2025-12-22T19:24:07.235Z  INFO 1 --- [eurekaserver] [           main] c.eurekaserver.EurekaserverApplication   : No active profile set, falling back to 1 default profile: "default"
zookeeper      | [2025-12-22 19:24:07,456] WARN o.e.j.s.ServletContextHandler@57db2b13{/,null,STOPPED} contextPath ends with /* (org.eclipse.jetty.server.handler.ContextHandler)
zookeeper      | [2025-12-22 19:24:07,481] WARN Empty contextPath (org.eclipse.jetty.server.handler.ContextHandler)
apigateway     | 2025-12-22T19:24:07.461Z  INFO 1 --- [apigateway] [           main] com.apigateway.ApigatewayApplication     : Starting ApigatewayApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/apigateway/app.jar started by root in /apigateway)
apigateway     | 2025-12-22T19:24:07.537Z  INFO 1 --- [apigateway] [           main] com.apigateway.ApigatewayApplication     : The following 1 profile is active: "docker"
authservice    | 2025-12-22T19:24:07.731Z  INFO 1 --- [           main] com.authservice.AuthserviceApplication   : Starting AuthserviceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/authservice/app.jar started by root in /authservice)
authservice    | 2025-12-22T19:24:07.794Z  INFO 1 --- [           main] com.authservice.AuthserviceApplication   : The following 1 profile is active: "docker"
kafka          | [2025-12-22 19:24:07,936] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:07,937] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:07,937] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
kafka          | java.net.ConnectException: Connection refused
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
kafka          | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
kafka          | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
zookeeper      | [2025-12-22 19:24:08,030] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.18+10-LTS (org.eclipse.jetty.server.Server)
zookeeper      | [2025-12-22 19:24:08,971] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
zookeeper      | [2025-12-22 19:24:08,971] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
zookeeper      | [2025-12-22 19:24:09,061] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
zookeeper      | [2025-12-22 19:24:09,108] WARN ServletContext@o.e.j.s.ServletContextHandler@57db2b13{/,null,STARTING} has uncovered http methods for path: /* (org.eclipse.jetty.security.SecurityHandler)
kafka          | [2025-12-22 19:24:09,103] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:09,104] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:09,105] WARN Session 0x0 for sever zookeeper/172.18.0.3:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
kafka          | java.net.ConnectException: Connection refused
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
kafka          | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
kafka          | 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
kafka          | 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
zookeeper      | [2025-12-22 19:24:09,205] INFO Started o.e.j.s.ServletContextHandler@57db2b13{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
zookeeper      | [2025-12-22 19:24:09,301] INFO Started ServerConnector@6e9a5ed8{HTTP/1.1, (http/1.1)}{0.0.0.0:8080} (org.eclipse.jetty.server.AbstractConnector)
zookeeper      | [2025-12-22 19:24:09,303] INFO Started @8462ms (org.eclipse.jetty.server.Server)
zookeeper      | [2025-12-22 19:24:09,304] INFO Started AdminServer on address 0.0.0.0, port 8080 and command URL /commands (org.apache.zookeeper.server.admin.JettyAdminServer)
zookeeper      | [2025-12-22 19:24:09,341] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
zookeeper      | [2025-12-22 19:24:09,344] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
zookeeper      | [2025-12-22 19:24:09,347] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
zookeeper      | [2025-12-22 19:24:09,350] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
zookeeper      | [2025-12-22 19:24:09,403] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
zookeeper      | [2025-12-22 19:24:09,406] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
zookeeper      | [2025-12-22 19:24:09,418] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
zookeeper      | [2025-12-22 19:24:09,418] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
zookeeper      | [2025-12-22 19:24:09,438] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
zookeeper      | [2025-12-22 19:24:09,438] INFO Snapshotting: 0x0 to /var/lib/zookeeper/data/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
zookeeper      | [2025-12-22 19:24:09,446] INFO Snapshot loaded in 27 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
zookeeper      | [2025-12-22 19:24:09,447] INFO Snapshotting: 0x0 to /var/lib/zookeeper/data/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
zookeeper      | [2025-12-22 19:24:09,449] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
zookeeper      | [2025-12-22 19:24:09,486] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
zookeeper      | [2025-12-22 19:24:09,487] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
zookeeper      | [2025-12-22 19:24:09,540] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
zookeeper      | [2025-12-22 19:24:09,542] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
kafka          | [2025-12-22 19:24:10,206] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:10,206] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:10,218] INFO Socket connection established, initiating session, client: /172.18.0.4:38944, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
zookeeper      | [2025-12-22 19:24:10,357] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
kafka          | [2025-12-22 19:24:10,943] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x10000760c0f0000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
kafka          | [2025-12-22 19:24:11,238] INFO Session: 0x10000760c0f0000 closed (org.apache.zookeeper.ZooKeeper)
kafka          | Using log4j config /etc/kafka/log4j.properties
kafka          | ===> Launching ... 
kafka          | ===> Launching kafka ... 
bookingservice  | 
bookingservice  |   .   ____          _            __ _ _
bookingservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
bookingservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
bookingservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
bookingservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
bookingservice  |  =========|_|==============|___/=/_/_/_/
bookingservice  | 
bookingservice  |  :: Spring Boot ::                (v3.3.1)
bookingservice  | 
bookingservice  | 2025-12-22T19:24:15.873Z  INFO 1 --- [bookingservice] [           main] c.b.BookingserviceApplication            : Starting BookingserviceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/bookingservive/app.jar started by root in /bookingservive)
bookingservice  | 2025-12-22T19:24:15.891Z  INFO 1 --- [bookingservice] [           main] c.b.BookingserviceApplication            : The following 1 profile is active: "docker"
authservice     | 2025-12-22T19:24:16.384Z  INFO 1 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
bookingservice  | 2025-12-22T19:24:16.401Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-22T19:24:16.402Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Exception on Url - http://configserver:8888:org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://configserver:8888/bookingservice/default": Connection refused. Will be trying the next url if available
bookingservice  | 2025-12-22T19:24:16.402Z  WARN 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Could not locate PropertySource ([ConfigServerConfigDataResource@60fa3495 uris = array<String>['http://configserver:8888'], optional = true, profiles = 'default']): I/O error on GET request for "http://configserver:8888/bookingservice/default": Connection refused
bookingservice  | 2025-12-22T19:24:16.403Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-22T19:24:16.403Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Exception on Url - http://configserver:8888:org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://configserver:8888/bookingservice/docker": Connection refused. Will be trying the next url if available
bookingservice  | 2025-12-22T19:24:16.403Z  WARN 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Could not locate PropertySource ([ConfigServerConfigDataResource@5f3b9c57 uris = array<String>['http://configserver:8888'], optional = true, profiles = 'docker']): I/O error on GET request for "http://configserver:8888/bookingservice/docker": Connection refused
bookingservice  | 2025-12-22T19:24:16.403Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-22T19:24:16.403Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Exception on Url - http://configserver:8888:org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://configserver:8888/bookingservice/default": Connection refused. Will be trying the next url if available
bookingservice  | 2025-12-22T19:24:16.403Z  WARN 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Could not locate PropertySource ([ConfigServerConfigDataResource@1e044120 uris = array<String>['http://configserver:8888'], optional = true, profiles = 'default']): I/O error on GET request for "http://configserver:8888/bookingservice/default": Connection refused
bookingservice  | 2025-12-22T19:24:16.403Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-22T19:24:16.479Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Exception on Url - http://configserver:8888:org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://configserver:8888/bookingservice/docker": Connection refused. Will be trying the next url if available
bookingservice  | 2025-12-22T19:24:16.479Z  WARN 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Could not locate PropertySource ([ConfigServerConfigDataResource@60b71e8f uris = array<String>['http://configserver:8888'], optional = true, profiles = 'docker']): I/O error on GET request for "http://configserver:8888/bookingservice/docker": Connection refused
bookingservice  | 2025-12-22T19:24:16.479Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-22T19:24:16.479Z  INFO 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Exception on Url - http://configserver:8888:org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://configserver:8888/bookingservice/default": Connection refused. Will be trying the next url if available
bookingservice  | 2025-12-22T19:24:16.489Z  WARN 1 --- [bookingservice] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Could not locate PropertySource ([ConfigServerConfigDataResource@1255b1d1 uris = array<String>['http://configserver:8888'], optional = true, profiles = 'default']): I/O error on GET request for "http://configserver:8888/bookingservice/default": Connection refused
authservice     | 2025-12-22T19:24:17.407Z  INFO 1 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 1008 ms. Found 1 MongoDB repository interfaces.
kafka           | [2025-12-22 19:24:17,756] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
configserver    | 2025-12-22T19:24:17.869Z  INFO 1 --- [configserver] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=f3248120-d716-3680-9f4c-a4161603b502
flightservice   | 2025-12-22T19:24:18.438Z  INFO 1 --- [flightservice] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
flightservice   | 2025-12-22T19:24:19.913Z  INFO 1 --- [flightservice] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 1423 ms. Found 2 MongoDB repository interfaces.
kafka           | [2025-12-22 19:24:20,255] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
kafka           | [2025-12-22 19:24:21,204] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka           | [2025-12-22 19:24:21,215] INFO starting (kafka.server.KafkaServer)
kafka           | [2025-12-22 19:24:21,217] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
authservice     | 2025-12-22T19:24:21.255Z  INFO 1 --- [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=010ec9ed-e310-356c-b2b8-1f28a8577b0c
kafka           | [2025-12-22 19:24:21,258] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2025-12-22 19:24:21,289] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,290] INFO Client environment:host.name=2475ac2257b9 (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,290] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,291] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,291] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,291] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,292] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,292] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,292] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,292] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,293] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,293] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,293] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,293] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,293] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,293] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,294] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,294] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,299] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@37c7595 (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:24:21,370] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
kafka           | [2025-12-22 19:24:21,404] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
kafka           | [2025-12-22 19:24:21,439] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2025-12-22 19:24:21,467] INFO Opening socket connection to server zookeeper/172.18.0.3:2181. (org.apache.zookeeper.ClientCnxn)
configserver    | 2025-12-22T19:24:21.463Z  INFO 1 --- [configserver] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8888 (http)
kafka           | [2025-12-22 19:24:21,505] INFO Socket connection established, initiating session, client: /172.18.0.4:36034, server: zookeeper/172.18.0.3:2181 (org.apache.zookeeper.ClientCnxn)
kafka           | [2025-12-22 19:24:21,576] INFO Session establishment complete on server zookeeper/172.18.0.3:2181, session id = 0x10000760c0f0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
kafka           | [2025-12-22 19:24:21,595] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
configserver    | 2025-12-22T19:24:21.615Z  INFO 1 --- [configserver] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
configserver    | 2025-12-22T19:24:21.620Z  INFO 1 --- [configserver] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.25]
apigateway      | 2025-12-22T19:24:21.986Z  INFO 1 --- [apigateway] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=021273c0-1d3e-34c3-9559-622f562a290a
configserver    | 2025-12-22T19:24:22.023Z  INFO 1 --- [configserver] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
configserver    | 2025-12-22T19:24:22.044Z  INFO 1 --- [configserver] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 14577 ms
flightservice   | 2025-12-22T19:24:22.156Z  INFO 1 --- [flightservice] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=84e14537-b0e9-339f-9002-d316eafb03ac
eurekaserver    | 2025-12-22T19:24:22.668Z  INFO 1 --- [eurekaserver] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=c18b0fac-8510-379b-9a15-81fa6b831394
apigateway      | 2025-12-22T19:24:22.682Z  WARN 1 --- [apigateway] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
apigateway      | 2025-12-22T19:24:22.715Z  WARN 1 --- [apigateway] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'deferringLoadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.DeferringLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
apigateway      | 2025-12-22T19:24:22.729Z  WARN 1 --- [apigateway] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [loadBalancerWebClientBuilderBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
apigateway      | 2025-12-22T19:24:22.736Z  WARN 1 --- [apigateway] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [loadBalancerWebClientBuilderBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
apigateway      | 2025-12-22T19:24:22.739Z  WARN 1 --- [apigateway] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [loadBalancerWebClientBuilderBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
flightservice   | 2025-12-22T19:24:22.847Z  WARN 1 --- [flightservice] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
flightservice   | 2025-12-22T19:24:22.875Z  WARN 1 --- [flightservice] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'deferringLoadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.DeferringLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
eurekaserver    | 2025-12-22T19:24:23.466Z  WARN 1 --- [eurekaserver] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
eurekaserver    | 2025-12-22T19:24:23.504Z  WARN 1 --- [eurekaserver] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'deferringLoadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.DeferringLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
kafka           | [2025-12-22 19:24:23,959] INFO Cluster ID = rrb9RMHdQYGSE_4KHmO67Q (kafka.server.KafkaServer)
kafka           | [2025-12-22 19:24:24,187] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
kafka           | [2025-12-22 19:24:24,939] INFO KafkaConfig values: 
kafka           | 	advertised.listeners = PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
kafka           | 	alter.config.policy.class.name = null
kafka           | 	alter.log.dirs.replication.quota.window.num = 11
kafka           | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka           | 	authorizer.class.name = 
kafka           | 	auto.create.topics.enable = true
kafka           | 	auto.include.jmx.reporter = true
kafka           | 	auto.leader.rebalance.enable = true
kafka           | 	background.threads = 10
kafka           | 	broker.heartbeat.interval.ms = 2000
kafka           | 	broker.id = 1
kafka           | 	broker.id.generation.enable = true
kafka           | 	broker.rack = null
kafka           | 	broker.session.timeout.ms = 9000
kafka           | 	client.quota.callback.class = null
kafka           | 	compression.type = producer
kafka           | 	connection.failed.authentication.delay.ms = 100
kafka           | 	connections.max.idle.ms = 600000
kafka           | 	connections.max.reauth.ms = 0
kafka           | 	control.plane.listener.name = null
kafka           | 	controlled.shutdown.enable = true
kafka           | 	controlled.shutdown.max.retries = 3
kafka           | 	controlled.shutdown.retry.backoff.ms = 5000
kafka           | 	controller.listener.names = null
kafka           | 	controller.quorum.append.linger.ms = 25
kafka           | 	controller.quorum.election.backoff.max.ms = 1000
kafka           | 	controller.quorum.election.timeout.ms = 1000
kafka           | 	controller.quorum.fetch.timeout.ms = 2000
kafka           | 	controller.quorum.request.timeout.ms = 2000
kafka           | 	controller.quorum.retry.backoff.ms = 20
kafka           | 	controller.quorum.voters = []
kafka           | 	controller.quota.window.num = 11
kafka           | 	controller.quota.window.size.seconds = 1
kafka           | 	controller.socket.timeout.ms = 30000
kafka           | 	create.topic.policy.class.name = null
kafka           | 	default.replication.factor = 1
kafka           | 	delegation.token.expiry.check.interval.ms = 3600000
kafka           | 	delegation.token.expiry.time.ms = 86400000
kafka           | 	delegation.token.master.key = null
kafka           | 	delegation.token.max.lifetime.ms = 604800000
kafka           | 	delegation.token.secret.key = null
kafka           | 	delete.records.purgatory.purge.interval.requests = 1
kafka           | 	delete.topic.enable = true
kafka           | 	early.start.listeners = null
kafka           | 	fetch.max.bytes = 57671680
kafka           | 	fetch.purgatory.purge.interval.requests = 1000
kafka           | 	group.initial.rebalance.delay.ms = 3000
kafka           | 	group.max.session.timeout.ms = 1800000
kafka           | 	group.max.size = 2147483647
kafka           | 	group.min.session.timeout.ms = 6000
kafka           | 	initial.broker.registration.timeout.ms = 60000
kafka           | 	inter.broker.listener.name = PLAINTEXT_INTERNAL
kafka           | 	inter.broker.protocol.version = 3.4-IV0
kafka           | 	kafka.metrics.polling.interval.secs = 10
kafka           | 	kafka.metrics.reporters = []
kafka           | 	leader.imbalance.check.interval.seconds = 300
kafka           | 	leader.imbalance.per.broker.percentage = 10
kafka           | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
kafka           | 	listeners = PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
kafka           | 	log.cleaner.backoff.ms = 15000
kafka           | 	log.cleaner.dedupe.buffer.size = 134217728
kafka           | 	log.cleaner.delete.retention.ms = 86400000
kafka           | 	log.cleaner.enable = true
kafka           | 	log.cleaner.io.buffer.load.factor = 0.9
kafka           | 	log.cleaner.io.buffer.size = 524288
kafka           | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka           | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka           | 	log.cleaner.min.cleanable.ratio = 0.5
kafka           | 	log.cleaner.min.compaction.lag.ms = 0
kafka           | 	log.cleaner.threads = 1
kafka           | 	log.cleanup.policy = [delete]
kafka           | 	log.dir = /tmp/kafka-logs
kafka           | 	log.dirs = /var/lib/kafka/data
kafka           | 	log.flush.interval.messages = 9223372036854775807
kafka           | 	log.flush.interval.ms = null
kafka           | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka           | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka           | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka           | 	log.index.interval.bytes = 4096
kafka           | 	log.index.size.max.bytes = 10485760
kafka           | 	log.message.downconversion.enable = true
kafka           | 	log.message.format.version = 3.0-IV1
kafka           | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka           | 	log.message.timestamp.type = CreateTime
kafka           | 	log.preallocate = false
kafka           | 	log.retention.bytes = -1
kafka           | 	log.retention.check.interval.ms = 300000
kafka           | 	log.retention.hours = 168
kafka           | 	log.retention.minutes = null
kafka           | 	log.retention.ms = null
kafka           | 	log.roll.hours = 168
kafka           | 	log.roll.jitter.hours = 0
kafka           | 	log.roll.jitter.ms = null
kafka           | 	log.roll.ms = null
kafka           | 	log.segment.bytes = 1073741824
kafka           | 	log.segment.delete.delay.ms = 60000
kafka           | 	max.connection.creation.rate = 2147483647
kafka           | 	max.connections = 2147483647
kafka           | 	max.connections.per.ip = 2147483647
kafka           | 	max.connections.per.ip.overrides = 
kafka           | 	max.incremental.fetch.session.cache.slots = 1000
kafka           | 	message.max.bytes = 1048588
kafka           | 	metadata.log.dir = null
kafka           | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka           | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka           | 	metadata.log.segment.bytes = 1073741824
kafka           | 	metadata.log.segment.min.bytes = 8388608
kafka           | 	metadata.log.segment.ms = 604800000
kafka           | 	metadata.max.idle.interval.ms = 500
kafka           | 	metadata.max.retention.bytes = 104857600
kafka           | 	metadata.max.retention.ms = 604800000
kafka           | 	metric.reporters = []
kafka           | 	metrics.num.samples = 2
kafka           | 	metrics.recording.level = INFO
kafka           | 	metrics.sample.window.ms = 30000
kafka           | 	min.insync.replicas = 1
kafka           | 	node.id = 1
kafka           | 	num.io.threads = 8
kafka           | 	num.network.threads = 3
kafka           | 	num.partitions = 1
kafka           | 	num.recovery.threads.per.data.dir = 1
kafka           | 	num.replica.alter.log.dirs.threads = null
kafka           | 	num.replica.fetchers = 1
kafka           | 	offset.metadata.max.bytes = 4096
kafka           | 	offsets.commit.required.acks = -1
kafka           | 	offsets.commit.timeout.ms = 5000
kafka           | 	offsets.load.buffer.size = 5242880
kafka           | 	offsets.retention.check.interval.ms = 600000
kafka           | 	offsets.retention.minutes = 10080
kafka           | 	offsets.topic.compression.codec = 0
kafka           | 	offsets.topic.num.partitions = 50
kafka           | 	offsets.topic.replication.factor = 1
kafka           | 	offsets.topic.segment.bytes = 104857600
kafka           | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka           | 	password.encoder.iterations = 4096
kafka           | 	password.encoder.key.length = 128
kafka           | 	password.encoder.keyfactory.algorithm = null
kafka           | 	password.encoder.old.secret = null
kafka           | 	password.encoder.secret = null
kafka           | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka           | 	process.roles = []
kafka           | 	producer.id.expiration.check.interval.ms = 600000
kafka           | 	producer.id.expiration.ms = 86400000
kafka           | 	producer.purgatory.purge.interval.requests = 1000
kafka           | 	queued.max.request.bytes = -1
kafka           | 	queued.max.requests = 500
kafka           | 	quota.window.num = 11
kafka           | 	quota.window.size.seconds = 1
kafka           | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka           | 	remote.log.manager.task.interval.ms = 30000
kafka           | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka           | 	remote.log.manager.task.retry.backoff.ms = 500
kafka           | 	remote.log.manager.task.retry.jitter = 0.2
kafka           | 	remote.log.manager.thread.pool.size = 10
kafka           | 	remote.log.metadata.manager.class.name = null
kafka           | 	remote.log.metadata.manager.class.path = null
kafka           | 	remote.log.metadata.manager.impl.prefix = null
kafka           | 	remote.log.metadata.manager.listener.name = null
kafka           | 	remote.log.reader.max.pending.tasks = 100
kafka           | 	remote.log.reader.threads = 10
kafka           | 	remote.log.storage.manager.class.name = null
kafka           | 	remote.log.storage.manager.class.path = null
kafka           | 	remote.log.storage.manager.impl.prefix = null
kafka           | 	remote.log.storage.system.enable = false
kafka           | 	replica.fetch.backoff.ms = 1000
kafka           | 	replica.fetch.max.bytes = 1048576
kafka           | 	replica.fetch.min.bytes = 1
kafka           | 	replica.fetch.response.max.bytes = 10485760
kafka           | 	replica.fetch.wait.max.ms = 500
kafka           | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka           | 	replica.lag.time.max.ms = 30000
kafka           | 	replica.selector.class = null
kafka           | 	replica.socket.receive.buffer.bytes = 65536
kafka           | 	replica.socket.timeout.ms = 30000
kafka           | 	replication.quota.window.num = 11
kafka           | 	replication.quota.window.size.seconds = 1
kafka           | 	request.timeout.ms = 30000
kafka           | 	reserved.broker.max.id = 1000
kafka           | 	sasl.client.callback.handler.class = null
kafka           | 	sasl.enabled.mechanisms = [GSSAPI]
kafka           | 	sasl.jaas.config = null
kafka           | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka           | 	sasl.kerberos.min.time.before.relogin = 60000
kafka           | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka           | 	sasl.kerberos.service.name = null
kafka           | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka           | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka           | 	sasl.login.callback.handler.class = null
kafka           | 	sasl.login.class = null
kafka           | 	sasl.login.connect.timeout.ms = null
kafka           | 	sasl.login.read.timeout.ms = null
kafka           | 	sasl.login.refresh.buffer.seconds = 300
kafka           | 	sasl.login.refresh.min.period.seconds = 60
kafka           | 	sasl.login.refresh.window.factor = 0.8
kafka           | 	sasl.login.refresh.window.jitter = 0.05
kafka           | 	sasl.login.retry.backoff.max.ms = 10000
kafka           | 	sasl.login.retry.backoff.ms = 100
kafka           | 	sasl.mechanism.controller.protocol = GSSAPI
kafka           | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka           | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka           | 	sasl.oauthbearer.expected.audience = null
kafka           | 	sasl.oauthbearer.expected.issuer = null
kafka           | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka           | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka           | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka           | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka           | 	sasl.oauthbearer.scope.claim.name = scope
kafka           | 	sasl.oauthbearer.sub.claim.name = sub
kafka           | 	sasl.oauthbearer.token.endpoint.url = null
kafka           | 	sasl.server.callback.handler.class = null
kafka           | 	sasl.server.max.receive.size = 524288
kafka           | 	security.inter.broker.protocol = PLAINTEXT
kafka           | 	security.providers = null
kafka           | 	socket.connection.setup.timeout.max.ms = 30000
kafka           | 	socket.connection.setup.timeout.ms = 10000
kafka           | 	socket.listen.backlog.size = 50
kafka           | 	socket.receive.buffer.bytes = 102400
kafka           | 	socket.request.max.bytes = 104857600
kafka           | 	socket.send.buffer.bytes = 102400
kafka           | 	ssl.cipher.suites = []
kafka           | 	ssl.client.auth = none
kafka           | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka           | 	ssl.endpoint.identification.algorithm = https
kafka           | 	ssl.engine.factory.class = null
kafka           | 	ssl.key.password = null
kafka           | 	ssl.keymanager.algorithm = SunX509
kafka           | 	ssl.keystore.certificate.chain = null
kafka           | 	ssl.keystore.key = null
kafka           | 	ssl.keystore.location = null
kafka           | 	ssl.keystore.password = null
kafka           | 	ssl.keystore.type = JKS
kafka           | 	ssl.principal.mapping.rules = DEFAULT
kafka           | 	ssl.protocol = TLSv1.3
kafka           | 	ssl.provider = null
kafka           | 	ssl.secure.random.implementation = null
kafka           | 	ssl.trustmanager.algorithm = PKIX
kafka           | 	ssl.truststore.certificates = null
kafka           | 	ssl.truststore.location = null
kafka           | 	ssl.truststore.password = null
kafka           | 	ssl.truststore.type = JKS
kafka           | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka           | 	transaction.max.timeout.ms = 900000
kafka           | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka           | 	transaction.state.log.load.buffer.size = 5242880
kafka           | 	transaction.state.log.min.isr = 1
kafka           | 	transaction.state.log.num.partitions = 50
kafka           | 	transaction.state.log.replication.factor = 1
kafka           | 	transaction.state.log.segment.bytes = 104857600
kafka           | 	transactional.id.expiration.ms = 604800000
kafka           | 	unclean.leader.election.enable = false
kafka           | 	zookeeper.clientCnxnSocket = null
kafka           | 	zookeeper.connect = zookeeper:2181
kafka           | 	zookeeper.connection.timeout.ms = null
kafka           | 	zookeeper.max.in.flight.requests = 10
kafka           | 	zookeeper.metadata.migration.enable = false
kafka           | 	zookeeper.session.timeout.ms = 18000
kafka           | 	zookeeper.set.acl = false
kafka           | 	zookeeper.ssl.cipher.suites = null
kafka           | 	zookeeper.ssl.client.enable = false
kafka           | 	zookeeper.ssl.crl.enable = false
kafka           | 	zookeeper.ssl.enabled.protocols = null
kafka           | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka           | 	zookeeper.ssl.keystore.location = null
kafka           | 	zookeeper.ssl.keystore.password = null
kafka           | 	zookeeper.ssl.keystore.type = null
kafka           | 	zookeeper.ssl.ocsp.enable = false
kafka           | 	zookeeper.ssl.protocol = TLSv1.2
kafka           | 	zookeeper.ssl.truststore.location = null
kafka           | 	zookeeper.ssl.truststore.password = null
kafka           | 	zookeeper.ssl.truststore.type = null
kafka           |  (kafka.server.KafkaConfig)
kafka           | [2025-12-22 19:24:25,134] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
apigateway      | 2025-12-22T19:24:25.201Z  INFO 1 --- [apigateway] [           main] ctiveUserDetailsServiceAutoConfiguration : 
apigateway      | 
apigateway      | Using generated security password: fa354bd1-ff03-43ec-afa9-625a40a6687e
apigateway      | 
kafka           | [2025-12-22 19:24:25,219] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:24:25,219] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:24:25,255] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:24:25,428] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:25,508] INFO Attempting recovery for all logs in /var/lib/kafka/data since no clean shutdown file was found (kafka.log.LogManager)
flightservice   | 2025-12-22T19:24:25.567Z  INFO 1 --- [flightservice] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8082 (http)
kafka           | [2025-12-22 19:24:25,639] INFO Loaded 0 logs in 198ms. (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:25,641] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:25,656] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:25,793] INFO Starting the log cleaner (kafka.log.LogCleaner)
flightservice   | 2025-12-22T19:24:25.814Z  INFO 1 --- [flightservice] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
flightservice   | 2025-12-22T19:24:25.832Z  INFO 1 --- [flightservice] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.25]
authservice     | 2025-12-22T19:24:25.971Z  INFO 1 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8001 (http)
authservice     | 2025-12-22T19:24:26.129Z  INFO 1 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
authservice     | 2025-12-22T19:24:26.132Z  INFO 1 --- [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.8]
flightservice   | 2025-12-22T19:24:26.315Z  INFO 1 --- [flightservice] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
flightservice   | 2025-12-22T19:24:26.361Z  INFO 1 --- [flightservice] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 18153 ms
eurekaserver    | 2025-12-22T19:24:26.544Z  INFO 1 --- [eurekaserver] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8761 (http)
kafka           | [2025-12-22 19:24:27,078] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
eurekaserver    | 2025-12-22T19:24:27.312Z  INFO 1 --- [eurekaserver] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
eurekaserver    | 2025-12-22T19:24:27.312Z  INFO 1 --- [eurekaserver] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.25]
kafka           | [2025-12-22 19:24:27,334] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka           | [2025-12-22 19:24:27,370] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
kafka           | [2025-12-22 19:24:27,692] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
eurekaserver    | 2025-12-22T19:24:28.110Z  INFO 1 --- [eurekaserver] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
eurekaserver    | 2025-12-22T19:24:28.114Z  INFO 1 --- [eurekaserver] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 18934 ms
eurekaserver    | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
authservice     | 2025-12-22T19:24:28.148Z  INFO 1 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
authservice     | 2025-12-22T19:24:28.157Z  INFO 1 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 19037 ms
bookingservice  | 2025-12-22T19:24:28.305Z  INFO 1 --- [bookingservice] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
configserver    | 2025-12-22T19:24:29.192Z  INFO 1 --- [configserver] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8888 (http) with context path '/'
bookingservice  | 2025-12-22T19:24:29.309Z  INFO 1 --- [bookingservice] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 959 ms. Found 2 MongoDB repository interfaces.
flightservice   | 2025-12-22T19:24:29.631Z  INFO 1 --- [flightservice] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.167.4-microsoft-standard-WSL2"}, "platform": "Java/Oracle Corporation/17.0.2+8-86", "env": {"container": {"runtime": "docker"}}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5e593b08, com.mongodb.Jep395RecordCodecProvider@3946075, com.mongodb.KotlinCodecProvider@122635ef]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.028+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.18.0.7:48028","uuid":"87991208-6b74-4cca-af61-e2f5f018d93d","connectionId":1,"connectionCount":1}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.122+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.18.0.7:48036","uuid":"986f1c19-7f2f-470f-baf5-750d4bba0ed0","connectionId":2,"connectionCount":2}}
authservice     | 2025-12-22T19:24:30.231Z  INFO 1 --- [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.9.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.167.4-microsoft-standard-WSL2"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@162be91c, com.mongodb.Jep395RecordCodecProvider@2488b073]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.338+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.18.0.8:39844","uuid":"53e3a5b3-96b4-49d5-9d64-14b1b17b3fab","connectionId":3,"connectionCount":3}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.351+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.18.0.8:49764","uuid":"647573e4-3bc4-43a6-bd3e-a70d2ca88c50","connectionId":4,"connectionCount":4}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.556+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn2","msg":"client metadata","attr":{"remote":"172.18.0.7:48036","client":"conn2","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"5.0.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86","env":{"container":{"runtime":"docker"}}}}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.557+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn3","msg":"client metadata","attr":{"remote":"172.18.0.8:39844","client":"conn3","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"4.9.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86"}}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.598+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn1","msg":"client metadata","attr":{"remote":"172.18.0.7:48028","client":"conn1","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"5.0.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86","env":{"container":{"runtime":"docker"}}}}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.637+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn4","msg":"client metadata","attr":{"remote":"172.18.0.8:49764","client":"conn4","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"4.9.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86"}}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.649+00:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn2","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","command":{"isMaster":1,"helloOk":true,"client":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"5.0.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86","env":{"container":{"runtime":"docker"}}},"$db":"admin"},"numYields":0,"reslen":329,"locks":{},"remote":"172.18.0.7:48036","protocol":"op_query","durationMillis":102}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:30.724+00:00"},"s":"I",  "c":"COMMAND",  "id":51803,   "ctx":"conn4","msg":"Slow query","attr":{"type":"command","ns":"admin.$cmd","command":{"isMaster":1,"helloOk":true,"client":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"4.9.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86"},"$db":"admin"},"numYields":0,"reslen":329,"locks":{},"remote":"172.18.0.8:49764","protocol":"op_query","durationMillis":108}}
flightservice   | 2025-12-22T19:24:30.810Z  INFO 1 --- [flightservice] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=824887327}
configserver    | 2025-12-22T19:24:30.829Z  INFO 1 --- [configserver] [           main] c.configserver.ConfigserverApplication   : Started ConfigserverApplication in 34.264 seconds (process running for 52.397)
authservice     | 2025-12-22T19:24:30.839Z  INFO 1 --- [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=480298957}
kafka           | [2025-12-22 19:24:31,166] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka           | [2025-12-22 19:24:31,184] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafka           | [2025-12-22 19:24:31,293] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka           | [2025-12-22 19:24:31,295] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka           | [2025-12-22 19:24:31,296] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
kafka           | [2025-12-22 19:24:31,323] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_INTERNAL) (kafka.network.SocketServer)
kafka           | [2025-12-22 19:24:31,359] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:24:31,489] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:31,517] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:31,557] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:31,567] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:31,770] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
bookingservice  | 2025-12-22T19:24:32.022Z  INFO 1 --- [bookingservice] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=156ea48e-dfc7-3c13-9382-638149b0fab1
kafka           | [2025-12-22 19:24:32,033] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
kafka           | [2025-12-22 19:24:32,235] INFO Stat of the created znode at /brokers/ids/1 is: 27,27,1766431472166,1766431472166,1,0,0,72058101046378497,270,0,27
kafka           |  (kafka.zk.KafkaZkClient)
kafka           | [2025-12-22 19:24:32,254] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092, czxid (broker epoch): 27 (kafka.zk.KafkaZkClient)
bookingservice  | 2025-12-22T19:24:32.629Z  WARN 1 --- [bookingservice] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$DeferringLoadBalancerInterceptorConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
bookingservice  | 2025-12-22T19:24:32.634Z  WARN 1 --- [bookingservice] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'deferringLoadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.DeferringLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
apigateway      | 2025-12-22T19:24:32.695Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [After]
apigateway      | 2025-12-22T19:24:32.695Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Before]
apigateway      | 2025-12-22T19:24:32.695Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Between]
apigateway      | 2025-12-22T19:24:32.695Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Cookie]
apigateway      | 2025-12-22T19:24:32.696Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Header]
apigateway      | 2025-12-22T19:24:32.696Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Host]
apigateway      | 2025-12-22T19:24:32.696Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Method]
apigateway      | 2025-12-22T19:24:32.698Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Path]
apigateway      | 2025-12-22T19:24:32.708Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Query]
apigateway      | 2025-12-22T19:24:32.708Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [ReadBody]
apigateway      | 2025-12-22T19:24:32.713Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [RemoteAddr]
apigateway      | 2025-12-22T19:24:32.713Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [XForwardedRemoteAddr]
apigateway      | 2025-12-22T19:24:32.714Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Weight]
apigateway      | 2025-12-22T19:24:32.715Z  INFO 1 --- [apigateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [CloudFoundryRouteService]
kafka           | [2025-12-22 19:24:32,912] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
kafka           | [2025-12-22 19:24:32,993] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:33,110] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:33,134] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
kafka           | [2025-12-22 19:24:33,147] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:33,276] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:33,285] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:33,334] INFO [Controller id=1] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map()) (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:33,354] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
kafka           | [2025-12-22 19:24:33,398] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:33,542] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka           | [2025-12-22 19:24:33,591] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka           | [2025-12-22 19:24:33,699] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
bookingservice  | 2025-12-22T19:24:33.776Z  INFO 1 --- [bookingservice] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8081 (http)
kafka           | [2025-12-22 19:24:33,788] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:33,812] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:33,815] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
bookingservice  | 2025-12-22T19:24:33.813Z  INFO 1 --- [bookingservice] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
bookingservice  | 2025-12-22T19:24:33.827Z  INFO 1 --- [bookingservice] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.25]
kafka           | [2025-12-22 19:24:33,831] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:33,886] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
bookingservice  | 2025-12-22T19:24:33.982Z  INFO 1 --- [bookingservice] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
bookingservice  | 2025-12-22T19:24:33.989Z  INFO 1 --- [bookingservice] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 17457 ms
kafka           | [2025-12-22 19:24:33,992] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 27) (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,017] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:24:34,025] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,058] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
kafka           | [2025-12-22 19:24:34,160] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,208] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,209] INFO [Controller id=1] Current list of topics in the cluster: HashSet() (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,209] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,167] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
kafka           | [2025-12-22 19:24:34,226] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,250] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,258] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,259] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
kafka           | [2025-12-22 19:24:34,260] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,266] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:34,304] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
kafka           | [2025-12-22 19:24:34,306] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
kafka           | [2025-12-22 19:24:34,315] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
kafka           | [2025-12-22 19:24:34,316] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap() (kafka.controller.ZkReplicaStateMachine)
kafka           | [2025-12-22 19:24:34,317] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
kafka           | [2025-12-22 19:24:34,319] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
kafka           | [2025-12-22 19:24:34,325] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap() (kafka.controller.ZkPartitionStateMachine)
kafka           | [2025-12-22 19:24:34,326] INFO [Controller id=1] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,331] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
kafka           | [2025-12-22 19:24:34,336] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,336] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,337] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,338] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,340] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,372] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:34,397] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka           | [2025-12-22 19:24:34,447] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
apigateway      | 2025-12-22T19:24:34.539Z  INFO 1 --- [apigateway] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
kafka           | [2025-12-22 19:24:34,612] INFO Kafka version: 7.4.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2025-12-22 19:24:34,612] INFO Kafka commitId: 30969fa33c185e880b9e02044761dfaac013151d (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2025-12-22 19:24:34,612] INFO Kafka startTimeMs: 1766431474568 (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2025-12-22 19:24:34,659] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
apigateway      | 2025-12-22T19:24:34.704Z  WARN 1 --- [apigateway] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
kafka           | [2025-12-22 19:24:34,814] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:24:34,858] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:24:34,888] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
apigateway      | 2025-12-22T19:24:34.949Z  INFO 1 --- [apigateway] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
apigateway      | 2025-12-22T19:24:35.164Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
apigateway      | 2025-12-22T19:24:35.181Z  INFO 1 --- [apigateway] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
apigateway      | 2025-12-22T19:24:35.287Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway      | 2025-12-22T19:24:35.308Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway      | 2025-12-22T19:24:35.308Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway      | 2025-12-22T19:24:35.309Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway      | 2025-12-22T19:24:35.312Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway      | 2025-12-22T19:24:35.312Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
apigateway      | 2025-12-22T19:24:35.312Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-22T19:24:35.471Z  INFO 1 --- [bookingservice] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'FLIGHTSERVICE' URL not provided. Will try picking an instance via load-balancing.
eurekaserver    | 2025-12-22T19:24:36.373Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eurekaserver    | 2025-12-22T19:24:36.387Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
authservice     | 2025-12-22T19:24:36.411Z  INFO 1 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@aa21042, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@e93f3d5, org.springframework.security.web.context.SecurityContextHolderFilter@27abb83e, org.springframework.security.web.header.HeaderWriterFilter@54acff7d, org.springframework.security.web.authentication.logout.LogoutFilter@3c5a54b7, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@1a1ed4e5, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@667e34b1, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@4cee7fa0, org.springframework.security.web.session.SessionManagementFilter@54534abf, org.springframework.security.web.access.ExceptionTranslationFilter@77bb0ab5, org.springframework.security.web.access.intercept.AuthorizationFilter@6f8d7714]
mongodb         | {"t":{"$date":"2025-12-22T19:24:36.563+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.18.0.10:52520","uuid":"5f098cfc-3c57-4aa9-a9e1-ee3f4cc3a2d2","connectionId":5,"connectionCount":5}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:36.569+00:00"},"s":"I",  "c":"NETWORK",  "id":22943,   "ctx":"listener","msg":"Connection accepted","attr":{"remote":"172.18.0.10:52526","uuid":"f21089bf-8671-4e1c-b81e-7f24f4480281","connectionId":6,"connectionCount":6}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:36.600+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn5","msg":"client metadata","attr":{"remote":"172.18.0.10:52520","client":"conn5","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"5.0.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86","env":{"container":{"runtime":"docker"}}}}}
mongodb         | {"t":{"$date":"2025-12-22T19:24:36.608+00:00"},"s":"I",  "c":"NETWORK",  "id":51800,   "ctx":"conn6","msg":"client metadata","attr":{"remote":"172.18.0.10:52526","client":"conn6","negotiatedCompressors":[],"doc":{"driver":{"name":"mongo-java-driver|sync|spring-boot","version":"5.0.1"},"os":{"type":"Linux","name":"Linux","architecture":"amd64","version":"5.15.167.4-microsoft-standard-WSL2"},"platform":"Java/Oracle Corporation/17.0.2+8-86","env":{"container":{"runtime":"docker"}}}}}
bookingservice  | 2025-12-22T19:24:36.635Z  INFO 1 --- [bookingservice] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=62748038}
bookingservice  | 2025-12-22T19:24:36.704Z  INFO 1 --- [bookingservice] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.167.4-microsoft-standard-WSL2"}, "platform": "Java/Oracle Corporation/17.0.2+8-86", "env": {"container": {"runtime": "docker"}}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6249a08d, com.mongodb.Jep395RecordCodecProvider@36525ab, com.mongodb.KotlinCodecProvider@27438750]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
flightservice   | 2025-12-22T19:24:36.891Z  INFO 1 --- [flightservice] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
flightservice   | 2025-12-22T19:24:37.087Z  WARN 1 --- [flightservice] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
flightservice   | 2025-12-22T19:24:37.221Z  INFO 1 --- [flightservice] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
flightservice   | 2025-12-22T19:24:37.345Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
flightservice   | 2025-12-22T19:24:37.355Z  INFO 1 --- [flightservice] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
flightservice   | 2025-12-22T19:24:37.453Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
flightservice   | 2025-12-22T19:24:37.453Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
flightservice   | 2025-12-22T19:24:37.454Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
flightservice   | 2025-12-22T19:24:37.455Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
flightservice   | 2025-12-22T19:24:37.455Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
flightservice   | 2025-12-22T19:24:37.455Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
flightservice   | 2025-12-22T19:24:37.455Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
authservice     | 2025-12-22T19:24:37.632Z  INFO 1 --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
authservice     | 2025-12-22T19:24:37.947Z  WARN 1 --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
authservice     | 2025-12-22T19:24:38.002Z  INFO 1 --- [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
eurekaserver    | 2025-12-22T19:24:38.246Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eurekaserver    | 2025-12-22T19:24:38.247Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
kafka           | [2025-12-22 19:24:39,377] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:39,378] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
mongodb         | {"t":{"$date":"2025-12-22T19:24:39.854+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":"[1766431479:854426][1:0x7f758e999700], WT_SESSION.checkpoint: [WT_VERB_CHECKPOINT_PROGRESS] saving checkpoint snapshot min: 3, snapshot max: 3 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 7178"}}
bookingservice  | 2025-12-22T19:24:39.932Z  INFO 1 --- [bookingservice] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
bookingservice  | 2025-12-22T19:24:40.080Z  WARN 1 --- [bookingservice] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
authservice     | 2025-12-22T19:24:40.101Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
authservice     | 2025-12-22T19:24:40.146Z  INFO 1 --- [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
authservice     | 2025-12-22T19:24:40.444Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
authservice     | 2025-12-22T19:24:40.456Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
authservice     | 2025-12-22T19:24:40.458Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
authservice     | 2025-12-22T19:24:40.459Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
authservice     | 2025-12-22T19:24:40.459Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
authservice     | 2025-12-22T19:24:40.459Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
authservice     | 2025-12-22T19:24:40.459Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-22T19:24:40.552Z  INFO 1 --- [bookingservice] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
bookingservice  | 2025-12-22T19:24:40.714Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
bookingservice  | 2025-12-22T19:24:40.763Z  INFO 1 --- [bookingservice] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
bookingservice  | 2025-12-22T19:24:40.804Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
bookingservice  | 2025-12-22T19:24:40.804Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
bookingservice  | 2025-12-22T19:24:40.804Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
bookingservice  | 2025-12-22T19:24:40.804Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
bookingservice  | 2025-12-22T19:24:40.804Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
bookingservice  | 2025-12-22T19:24:40.805Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
bookingservice  | 2025-12-22T19:24:40.805Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
flightservice   | 2025-12-22T19:24:40.932Z  INFO 1 --- [flightservice] [           main] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
flightservice   | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:915)
flightservice   | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:895)
flightservice   | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:790)
flightservice   | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:672)
flightservice   | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
flightservice   | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplications(RestTemplateEurekaHttpClient.java:135)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1046)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:961)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:410)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:245)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:240)
flightservice   | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
flightservice   | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:321)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
flightservice   | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
flightservice   | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
flightservice   | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:140)
flightservice   | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:644)
flightservice   | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:636)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1337)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1167)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:562)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:522)
flightservice   | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:376)
flightservice   | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
flightservice   | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
flightservice   | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:373)
flightservice   | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
flightservice   | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
flightservice   | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
flightservice   | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
flightservice   | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
flightservice   | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
flightservice   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
flightservice   | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:768)
flightservice   | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:720)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:83)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:66)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:89)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:285)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:469)
flightservice   | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:257)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:202)
flightservice   | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:981)
flightservice   | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
flightservice   | 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
flightservice   | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
flightservice   | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:456)
flightservice   | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:335)
flightservice   | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363)
flightservice   | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352)
flightservice   | 	at com.flightservice.FlightserviceApplication.main(FlightserviceApplication.java:9)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
flightservice   | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
flightservice   | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
flightservice   | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:91)
flightservice   | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:53)
flightservice   | 	at org.springframework.boot.loader.launch.JarLauncher.main(JarLauncher.java:58)
flightservice   | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
flightservice   | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
flightservice   | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
flightservice   | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
flightservice   | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
flightservice   | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
flightservice   | 	at java.base/java.net.Socket.connect(Socket.java:633)
flightservice   | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:91)
flightservice   | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
flightservice   | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:90)
flightservice   | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:123)
flightservice   | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:189)
flightservice   | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
flightservice   | 	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
flightservice   | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
flightservice   | 	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:70)
flightservice   | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
flightservice   | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)
flightservice   | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$3(RestTemplateTransportClientFactory.java:170)
flightservice   | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
flightservice   | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
flightservice   | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
flightservice   | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
flightservice   | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:889)
flightservice   | 	... 74 more
flightservice   | 
flightservice   | 2025-12-22T19:24:40.932Z  WARN 1 --- [flightservice] [           main] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
flightservice   | 2025-12-22T19:24:40.939Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1046)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:961)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:410)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:245)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:240)
flightservice   | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
flightservice   | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:321)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
flightservice   | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
flightservice   | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
flightservice   | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:140)
flightservice   | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:644)
flightservice   | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:636)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1337)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1167)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:562)
flightservice   | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:522)
flightservice   | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:376)
flightservice   | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
flightservice   | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
flightservice   | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:373)
flightservice   | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
flightservice   | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
flightservice   | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
flightservice   | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
flightservice   | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
flightservice   | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
flightservice   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
flightservice   | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:768)
flightservice   | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:720)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:83)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:66)
flightservice   | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:89)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:285)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:469)
flightservice   | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:257)
flightservice   | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:202)
flightservice   | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:981)
flightservice   | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
flightservice   | 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
flightservice   | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
flightservice   | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:456)
flightservice   | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:335)
flightservice   | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363)
flightservice   | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352)
flightservice   | 	at com.flightservice.FlightserviceApplication.main(FlightserviceApplication.java:9)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
flightservice   | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
flightservice   | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
flightservice   | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
flightservice   | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:91)
flightservice   | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:53)
flightservice   | 	at org.springframework.boot.loader.launch.JarLauncher.main(JarLauncher.java:58)
flightservice   | 
flightservice   | 2025-12-22T19:24:40.941Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from primary servers failed
flightservice   | 2025-12-22T19:24:40.941Z  WARN 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.
flightservice   | 2025-12-22T19:24:40.942Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from backup servers failed
flightservice   | 2025-12-22T19:24:40.958Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
flightservice   | 2025-12-22T19:24:40.980Z  INFO 1 --- [flightservice] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
flightservice   | 2025-12-22T19:24:41.000Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1766431480983 with initial instances count: 0
flightservice   | 2025-12-22T19:24:41.024Z  INFO 1 --- [flightservice] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application FLIGHTSERVICE with eureka with status UP
flightservice   | 2025-12-22T19:24:41.030Z  INFO 1 --- [flightservice] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431481030, current=UP, previous=STARTING]
flightservice   | 2025-12-22T19:24:41.035Z  INFO 1 --- [flightservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082: registering service...
apigateway      | 2025-12-22T19:24:41.047Z  INFO 1 --- [apigateway] [           main] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
apigateway      | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:915)
apigateway      | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:895)
apigateway      | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:790)
apigateway      | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:672)
apigateway      | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
apigateway      | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplications(RestTemplateEurekaHttpClient.java:135)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1046)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:961)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:410)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:245)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:240)
apigateway      | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
apigateway      | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:321)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
apigateway      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apigateway      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
apigateway      | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:140)
apigateway      | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:644)
apigateway      | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:636)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1337)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1167)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:562)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:522)
apigateway      | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:376)
apigateway      | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
apigateway      | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
apigateway      | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:373)
apigateway      | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
apigateway      | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
apigateway      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apigateway      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
apigateway      | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
apigateway      | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
apigateway      | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
apigateway      | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:768)
apigateway      | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:720)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:83)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:66)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:89)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:285)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:469)
apigateway      | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:257)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:202)
apigateway      | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:981)
apigateway      | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
apigateway      | 	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:66)
apigateway      | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
apigateway      | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:456)
apigateway      | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:335)
apigateway      | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363)
apigateway      | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352)
apigateway      | 	at com.apigateway.ApigatewayApplication.main(ApigatewayApplication.java:10)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
apigateway      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apigateway      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
apigateway      | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:91)
apigateway      | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:53)
apigateway      | 	at org.springframework.boot.loader.launch.JarLauncher.main(JarLauncher.java:58)
apigateway      | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
apigateway      | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
apigateway      | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
apigateway      | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
apigateway      | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
apigateway      | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
apigateway      | 	at java.base/java.net.Socket.connect(Socket.java:633)
apigateway      | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:91)
apigateway      | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
apigateway      | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:90)
apigateway      | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:123)
apigateway      | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:189)
apigateway      | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
apigateway      | 	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
apigateway      | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
apigateway      | 	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:70)
apigateway      | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
apigateway      | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)
apigateway      | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$3(RestTemplateTransportClientFactory.java:170)
apigateway      | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
apigateway      | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
apigateway      | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
apigateway      | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
apigateway      | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:889)
apigateway      | 	... 74 more
apigateway      | 
apigateway      | 2025-12-22T19:24:41.047Z  WARN 1 --- [apigateway] [           main] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
apigateway      | 2025-12-22T19:24:41.060Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1046)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:961)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:410)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:245)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:240)
apigateway      | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
apigateway      | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:321)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
apigateway      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apigateway      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
apigateway      | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:140)
apigateway      | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:644)
apigateway      | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:636)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1337)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1167)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:562)
apigateway      | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:522)
apigateway      | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:376)
apigateway      | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
apigateway      | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
apigateway      | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:373)
apigateway      | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
apigateway      | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
apigateway      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apigateway      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
apigateway      | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
apigateway      | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
apigateway      | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
apigateway      | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:768)
apigateway      | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:720)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:83)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:66)
apigateway      | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:89)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:285)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:469)
apigateway      | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:257)
apigateway      | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:202)
apigateway      | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:981)
apigateway      | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
apigateway      | 	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:66)
apigateway      | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
apigateway      | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:456)
apigateway      | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:335)
apigateway      | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363)
apigateway      | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352)
apigateway      | 	at com.apigateway.ApigatewayApplication.main(ApigatewayApplication.java:10)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
apigateway      | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
apigateway      | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
apigateway      | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
apigateway      | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:91)
apigateway      | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:53)
apigateway      | 	at org.springframework.boot.loader.launch.JarLauncher.main(JarLauncher.java:58)
apigateway      | 
apigateway      | 2025-12-22T19:24:41.061Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from primary servers failed
apigateway      | 2025-12-22T19:24:41.061Z  WARN 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.
apigateway      | 2025-12-22T19:24:41.063Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from backup servers failed
apigateway      | 2025-12-22T19:24:41.077Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
apigateway      | 2025-12-22T19:24:41.132Z  INFO 1 --- [apigateway] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
apigateway      | 2025-12-22T19:24:41.142Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1766431481141 with initial instances count: 0
apigateway      | 2025-12-22T19:24:41.183Z  INFO 1 --- [apigateway] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application APIGATEWAY with eureka with status UP
apigateway      | 2025-12-22T19:24:41.195Z  INFO 1 --- [apigateway] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431481195, current=UP, previous=STARTING]
apigateway      | 2025-12-22T19:24:41.212Z  INFO 1 --- [apigateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088: registering service...
flightservice   | 2025-12-22T19:24:41.221Z  INFO 1 --- [flightservice] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8082 (http) with context path '/'
flightservice   | 2025-12-22T19:24:41.223Z  INFO 1 --- [flightservice] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8082
flightservice   | 2025-12-22T19:24:41.413Z  INFO 1 --- [flightservice] [           main] c.f.FlightserviceApplication             : Started FlightserviceApplication in 46.274 seconds (process running for 60.754)
flightservice   | 2025-12-22T19:24:41.428Z  INFO 1 --- [flightservice] [foReplicator-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on POST request for "http://eurekaserver:8761/eureka/apps/FLIGHTSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/FLIGHTSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
flightservice   | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:915)
flightservice   | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:895)
flightservice   | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:790)
flightservice   | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:672)
flightservice   | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:77)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
flightservice   | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828)
flightservice   | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125)
flightservice   | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105)
flightservice   | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
flightservice   | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
flightservice   | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
flightservice   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
flightservice   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
flightservice   | 	at java.base/java.lang.Thread.run(Thread.java:833)
flightservice   | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
flightservice   | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
flightservice   | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
flightservice   | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
flightservice   | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
flightservice   | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
flightservice   | 	at java.base/java.net.Socket.connect(Socket.java:633)
flightservice   | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:91)
flightservice   | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
flightservice   | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:90)
flightservice   | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:123)
flightservice   | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:189)
flightservice   | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
flightservice   | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
flightservice   | 	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
flightservice   | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
flightservice   | 	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:70)
flightservice   | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
flightservice   | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)
flightservice   | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$3(RestTemplateTransportClientFactory.java:170)
flightservice   | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
flightservice   | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
flightservice   | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
flightservice   | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
flightservice   | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:889)
flightservice   | 	... 22 more
flightservice   | 
flightservice   | 2025-12-22T19:24:41.429Z  WARN 1 --- [flightservice] [foReplicator-%d] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/FLIGHTSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
flightservice   | 2025-12-22T19:24:41.430Z  WARN 1 --- [flightservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082 - registration failed Cannot execute request on any known server
flightservice   | 
flightservice   | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
flightservice   | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
flightservice   | 
flightservice   | 2025-12-22T19:24:41.435Z  WARN 1 --- [flightservice] [foReplicator-%d] c.n.discovery.InstanceInfoReplicator     : There was a problem with the instance info replicator
flightservice   | 
flightservice   | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105) ~[eureka-client-2.0.3.jar!/:2.0.3]
flightservice   | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
flightservice   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
flightservice   | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
flightservice   | 
apigateway      | 2025-12-22T19:24:41.563Z  INFO 1 --- [apigateway] [foReplicator-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on POST request for "http://eurekaserver:8761/eureka/apps/APIGATEWAY": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/APIGATEWAY": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
apigateway      | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:915)
apigateway      | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:895)
apigateway      | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:790)
apigateway      | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:672)
apigateway      | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:77)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
apigateway      | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828)
apigateway      | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125)
apigateway      | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105)
apigateway      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
apigateway      | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
apigateway      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
apigateway      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
apigateway      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
apigateway      | 	at java.base/java.lang.Thread.run(Thread.java:833)
apigateway      | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
apigateway      | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
apigateway      | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
apigateway      | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
apigateway      | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
apigateway      | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
apigateway      | 	at java.base/java.net.Socket.connect(Socket.java:633)
apigateway      | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:91)
apigateway      | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
apigateway      | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:90)
apigateway      | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:123)
apigateway      | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:189)
apigateway      | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
apigateway      | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
apigateway      | 	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
apigateway      | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
apigateway      | 	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:70)
apigateway      | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
apigateway      | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)
apigateway      | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$3(RestTemplateTransportClientFactory.java:170)
apigateway      | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
apigateway      | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
apigateway      | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
apigateway      | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
apigateway      | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:889)
apigateway      | 	... 22 more
apigateway      | 
apigateway      | 2025-12-22T19:24:41.563Z  WARN 1 --- [apigateway] [foReplicator-%d] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/APIGATEWAY": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
apigateway      | 2025-12-22T19:24:41.563Z  WARN 1 --- [apigateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088 - registration failed Cannot execute request on any known server
apigateway      | 
apigateway      | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
apigateway      | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
apigateway      | 
apigateway      | 2025-12-22T19:24:41.680Z  WARN 1 --- [apigateway] [foReplicator-%d] c.n.discovery.InstanceInfoReplicator     : There was a problem with the instance info replicator
apigateway      | 
apigateway      | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105) ~[eureka-client-2.0.3.jar!/:2.0.3]
apigateway      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
apigateway      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
apigateway      | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
apigateway      | 
apigateway      | 2025-12-22T19:24:42.066Z  INFO 1 --- [apigateway] [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 8088 (http)
apigateway      | 2025-12-22T19:24:42.094Z  INFO 1 --- [apigateway] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8088
apigateway      | 2025-12-22T19:24:42.157Z  INFO 1 --- [apigateway] [           main] com.apigateway.ApigatewayApplication     : Started ApigatewayApplication in 46.289 seconds (process running for 60.738)
eurekaserver    | 2025-12-22T19:24:42.282Z  WARN 1 --- [eurekaserver] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
eurekaserver    | 2025-12-22T19:24:42.419Z  INFO 1 --- [eurekaserver] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
eurekaserver    | 2025-12-22T19:24:42.508Z  INFO 1 --- [eurekaserver] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
eurekaserver    | 2025-12-22T19:24:42.509Z  INFO 1 --- [eurekaserver] [           main] com.netflix.discovery.DiscoveryClient    : Client configured to neither register nor query for data.
eurekaserver    | 2025-12-22T19:24:42.513Z  INFO 1 --- [eurekaserver] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1766431482512 with initial instances count: 0
bookingservice  | 2025-12-22T19:24:42.584Z  INFO 1 --- [bookingservice] [           main] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
bookingservice  | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:915)
bookingservice  | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:895)
bookingservice  | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:790)
bookingservice  | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:672)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplications(RestTemplateEurekaHttpClient.java:135)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1046)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:961)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:410)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:245)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:240)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:321)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
bookingservice  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
bookingservice  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
bookingservice  | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:140)
bookingservice  | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:644)
bookingservice  | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:636)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1337)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1167)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:562)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:522)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:376)
bookingservice  | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
bookingservice  | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:373)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
bookingservice  | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
bookingservice  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
bookingservice  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
bookingservice  | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
bookingservice  | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
bookingservice  | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
bookingservice  | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:768)
bookingservice  | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:720)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:83)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:66)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:89)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:285)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:469)
bookingservice  | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:257)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:202)
bookingservice  | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:981)
bookingservice  | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
bookingservice  | 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
bookingservice  | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
bookingservice  | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:456)
bookingservice  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:335)
bookingservice  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363)
bookingservice  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352)
bookingservice  | 	at com.bookingservice.BookingserviceApplication.main(BookingserviceApplication.java:11)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
bookingservice  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
bookingservice  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
bookingservice  | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:91)
bookingservice  | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:53)
bookingservice  | 	at org.springframework.boot.loader.launch.JarLauncher.main(JarLauncher.java:58)
bookingservice  | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
bookingservice  | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
bookingservice  | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
bookingservice  | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
bookingservice  | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
bookingservice  | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
bookingservice  | 	at java.base/java.net.Socket.connect(Socket.java:633)
bookingservice  | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:91)
bookingservice  | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
bookingservice  | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:90)
bookingservice  | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:123)
bookingservice  | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:189)
bookingservice  | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
bookingservice  | 	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
bookingservice  | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
bookingservice  | 	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:70)
bookingservice  | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
bookingservice  | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$3(RestTemplateTransportClientFactory.java:170)
bookingservice  | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
bookingservice  | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
bookingservice  | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
bookingservice  | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
bookingservice  | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:889)
bookingservice  | 	... 74 more
bookingservice  | 
bookingservice  | 2025-12-22T19:24:42.585Z  WARN 1 --- [bookingservice] [           main] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
bookingservice  | 2025-12-22T19:24:42.586Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1046)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:961)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:410)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:245)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:240)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:321)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
bookingservice  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
bookingservice  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
bookingservice  | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:140)
bookingservice  | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:644)
bookingservice  | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:636)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1337)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1167)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:562)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:522)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:376)
bookingservice  | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
bookingservice  | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:373)
bookingservice  | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
bookingservice  | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
bookingservice  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
bookingservice  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
bookingservice  | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
bookingservice  | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
bookingservice  | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
bookingservice  | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:768)
bookingservice  | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:720)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:83)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:66)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:89)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:285)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:469)
bookingservice  | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:257)
bookingservice  | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:202)
bookingservice  | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:981)
bookingservice  | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
bookingservice  | 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
bookingservice  | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754)
bookingservice  | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:456)
bookingservice  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:335)
bookingservice  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363)
bookingservice  | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352)
bookingservice  | 	at com.bookingservice.BookingserviceApplication.main(BookingserviceApplication.java:11)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
bookingservice  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
bookingservice  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
bookingservice  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
bookingservice  | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:91)
bookingservice  | 	at org.springframework.boot.loader.launch.Launcher.launch(Launcher.java:53)
bookingservice  | 	at org.springframework.boot.loader.launch.JarLauncher.main(JarLauncher.java:58)
bookingservice  | 
bookingservice  | 2025-12-22T19:24:42.587Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from primary servers failed
bookingservice  | 2025-12-22T19:24:42.587Z  WARN 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.
bookingservice  | 2025-12-22T19:24:42.588Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from backup servers failed
bookingservice  | 2025-12-22T19:24:42.607Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
bookingservice  | 2025-12-22T19:24:42.615Z  INFO 1 --- [bookingservice] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
bookingservice  | 2025-12-22T19:24:42.620Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1766431482618 with initial instances count: 0
bookingservice  | 2025-12-22T19:24:42.651Z  INFO 1 --- [bookingservice] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application BOOKINGSERVICE with eureka with status UP
bookingservice  | 2025-12-22T19:24:42.652Z  INFO 1 --- [bookingservice] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431482652, current=UP, previous=STARTING]
bookingservice  | 2025-12-22T19:24:42.666Z  INFO 1 --- [bookingservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081: registering service...
authservice     | 2025-12-22T19:24:42.690Z  INFO 1 --- [           main] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
authservice     | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:888)
authservice     | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:868)
authservice     | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:764)
authservice     | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:646)
authservice     | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:149)
authservice     | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplications(RestTemplateEurekaHttpClient.java:139)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
authservice     | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1045)
authservice     | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:958)
authservice     | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:396)
authservice     | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:247)
authservice     | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:242)
authservice     | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
authservice     | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:320)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
authservice     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
authservice     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
authservice     | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:139)
authservice     | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655)
authservice     | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:647)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1332)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1162)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:560)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:520)
authservice     | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:365)
authservice     | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
authservice     | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
authservice     | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:362)
authservice     | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
authservice     | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
authservice     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
authservice     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
authservice     | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
authservice     | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
authservice     | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
authservice     | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)
authservice     | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:702)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:54)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:38)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:83)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356)
authservice     | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123)
authservice     | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:958)
authservice     | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:611)
authservice     | 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
authservice     | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:733)
authservice     | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:435)
authservice     | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
authservice     | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1305)
authservice     | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1294)
authservice     | 	at com.authservice.AuthserviceApplication.main(AuthserviceApplication.java:10)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
authservice     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
authservice     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
authservice     | 	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49)
authservice     | 	at org.springframework.boot.loader.Launcher.launch(Launcher.java:95)
authservice     | 	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58)
authservice     | 	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:65)
authservice     | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
authservice     | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
authservice     | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
authservice     | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
authservice     | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
authservice     | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
authservice     | 	at java.base/java.net.Socket.connect(Socket.java:633)
authservice     | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:85)
authservice     | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
authservice     | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:84)
authservice     | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:113)
authservice     | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:181)
authservice     | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:447)
authservice     | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
authservice     | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:96)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:115)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
authservice     | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:106)
authservice     | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
authservice     | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:93)
authservice     | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
authservice     | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
authservice     | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:101)
authservice     | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$0(RestTemplateTransportClientFactory.java:143)
authservice     | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:87)
authservice     | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:71)
authservice     | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
authservice     | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
authservice     | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:862)
authservice     | 	... 75 more
authservice     | 
authservice     | 2025-12-22T19:24:42.690Z  WARN 1 --- [           main] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on GET request for "http://eurekaserver:8761/eureka/apps/": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
authservice     | 2025-12-22T19:24:42.692Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
authservice     | 	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1045)
authservice     | 	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:958)
authservice     | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:396)
authservice     | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:247)
authservice     | 	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:242)
authservice     | 	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:68)
authservice     | 	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:320)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
authservice     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
authservice     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
authservice     | 	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:139)
authservice     | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655)
authservice     | 	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:647)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1332)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1162)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:560)
authservice     | 	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:520)
authservice     | 	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:365)
authservice     | 	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:375)
authservice     | 	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
authservice     | 	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:362)
authservice     | 	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
authservice     | 	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:128)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:116)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
authservice     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
authservice     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
authservice     | 	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:281)
authservice     | 	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:482)
authservice     | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
authservice     | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)
authservice     | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:702)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$SpringCGLIB$$0.getEurekaClient(<generated>)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:54)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:38)
authservice     | 	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:83)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356)
authservice     | 	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155)
authservice     | 	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123)
authservice     | 	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:958)
authservice     | 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:611)
authservice     | 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
authservice     | 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:733)
authservice     | 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:435)
authservice     | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
authservice     | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1305)
authservice     | 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1294)
authservice     | 	at com.authservice.AuthserviceApplication.main(AuthserviceApplication.java:10)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
authservice     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
authservice     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
authservice     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
authservice     | 	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49)
authservice     | 	at org.springframework.boot.loader.Launcher.launch(Launcher.java:95)
authservice     | 	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58)
authservice     | 	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:65)
authservice     | 
authservice     | 2025-12-22T19:24:42.693Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from primary servers failed
authservice     | 2025-12-22T19:24:42.693Z  WARN 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.
authservice     | 2025-12-22T19:24:42.694Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Initial registry fetch from backup servers failed
authservice     | 2025-12-22T19:24:42.709Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
eurekaserver    | 2025-12-22T19:24:42.703Z  INFO 1 --- [eurekaserver] [           main] c.n.eureka.DefaultEurekaServerContext    : Initializing ...
eurekaserver    | 2025-12-22T19:24:42.715Z  INFO 1 --- [eurekaserver] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Adding new peer nodes [http://localhost:8761/eureka/]
bookingservice  | 2025-12-22T19:24:42.730Z  INFO 1 --- [bookingservice] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8081 (http) with context path '/'
bookingservice  | 2025-12-22T19:24:42.732Z  INFO 1 --- [bookingservice] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8081
authservice     | 2025-12-22T19:24:42.753Z  INFO 1 --- [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
authservice     | 2025-12-22T19:24:42.797Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1766431482795 with initial instances count: 0
authservice     | 2025-12-22T19:24:42.820Z  INFO 1 --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application AUTHSERVICE with eureka with status UP
authservice     | 2025-12-22T19:24:42.822Z  INFO 1 --- [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431482822, current=UP, previous=STARTING]
authservice     | 2025-12-22T19:24:42.836Z  INFO 1 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001: registering service...
bookingservice  | 2025-12-22T19:24:42.947Z  INFO 1 --- [bookingservice] [foReplicator-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on POST request for "http://eurekaserver:8761/eureka/apps/BOOKINGSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/BOOKINGSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
bookingservice  | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:915)
bookingservice  | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:895)
bookingservice  | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:790)
bookingservice  | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:672)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:77)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828)
bookingservice  | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125)
bookingservice  | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105)
bookingservice  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
bookingservice  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
bookingservice  | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
bookingservice  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
bookingservice  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
bookingservice  | 	at java.base/java.lang.Thread.run(Thread.java:833)
bookingservice  | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
bookingservice  | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
bookingservice  | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
bookingservice  | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
bookingservice  | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
bookingservice  | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
bookingservice  | 	at java.base/java.net.Socket.connect(Socket.java:633)
bookingservice  | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:91)
bookingservice  | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
bookingservice  | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:90)
bookingservice  | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:123)
bookingservice  | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:189)
bookingservice  | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
bookingservice  | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
bookingservice  | 	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
bookingservice  | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
bookingservice  | 	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:70)
bookingservice  | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
bookingservice  | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:112)
bookingservice  | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$3(RestTemplateTransportClientFactory.java:170)
bookingservice  | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
bookingservice  | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
bookingservice  | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
bookingservice  | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
bookingservice  | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:889)
bookingservice  | 	... 22 more
bookingservice  | 
bookingservice  | 2025-12-22T19:24:42.949Z  WARN 1 --- [bookingservice] [foReplicator-%d] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/BOOKINGSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
bookingservice  | 2025-12-22T19:24:42.949Z  WARN 1 --- [bookingservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081 - registration failed Cannot execute request on any known server
bookingservice  | 
bookingservice  | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
bookingservice  | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
bookingservice  | 
bookingservice  | 2025-12-22T19:24:42.964Z  INFO 1 --- [bookingservice] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
bookingservice  | 	allow.auto.create.topics = true
bookingservice  | 	auto.commit.interval.ms = 5000
bookingservice  | 	auto.include.jmx.reporter = true
bookingservice  | 	auto.offset.reset = latest
bookingservice  | 	bootstrap.servers = [kafka:29092]
bookingservice  | 	check.crcs = true
bookingservice  | 	client.dns.lookup = use_all_dns_ips
bookingservice  | 	client.id = consumer-email-group-1
bookingservice  | 	client.rack = 
bookingservice  | 	connections.max.idle.ms = 540000
bookingservice  | 	default.api.timeout.ms = 60000
bookingservice  | 	enable.auto.commit = false
bookingservice  | 	enable.metrics.push = true
bookingservice  | 	exclude.internal.topics = true
bookingservice  | 	fetch.max.bytes = 52428800
bookingservice  | 	fetch.max.wait.ms = 500
bookingservice  | 	fetch.min.bytes = 1
bookingservice  | 	group.id = email-group
bookingservice  | 	group.instance.id = null
bookingservice  | 	group.protocol = classic
bookingservice  | 	group.remote.assignor = null
bookingservice  | 	heartbeat.interval.ms = 3000
bookingservice  | 	interceptor.classes = []
bookingservice  | 	internal.leave.group.on.close = true
bookingservice  | 	internal.throw.on.fetch.stable.offset.unsupported = false
bookingservice  | 	isolation.level = read_uncommitted
bookingservice  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
bookingservice  | 	max.partition.fetch.bytes = 1048576
bookingservice  | 	max.poll.interval.ms = 300000
bookingservice  | 	max.poll.records = 500
bookingservice  | 	metadata.max.age.ms = 300000
bookingservice  | 	metric.reporters = []
bookingservice  | 	metrics.num.samples = 2
bookingservice  | 	metrics.recording.level = INFO
bookingservice  | 	metrics.sample.window.ms = 30000
bookingservice  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
bookingservice  | 	receive.buffer.bytes = 65536
bookingservice  | 	reconnect.backoff.max.ms = 1000
bookingservice  | 	reconnect.backoff.ms = 50
bookingservice  | 	request.timeout.ms = 30000
bookingservice  | 	retry.backoff.max.ms = 1000
bookingservice  | 	retry.backoff.ms = 100
bookingservice  | 	sasl.client.callback.handler.class = null
bookingservice  | 	sasl.jaas.config = null
bookingservice  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
bookingservice  | 	sasl.kerberos.min.time.before.relogin = 60000
bookingservice  | 	sasl.kerberos.service.name = null
bookingservice  | 	sasl.kerberos.ticket.renew.jitter = 0.05
bookingservice  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
bookingservice  | 	sasl.login.callback.handler.class = null
bookingservice  | 	sasl.login.class = null
bookingservice  | 	sasl.login.connect.timeout.ms = null
bookingservice  | 	sasl.login.read.timeout.ms = null
bookingservice  | 	sasl.login.refresh.buffer.seconds = 300
bookingservice  | 	sasl.login.refresh.min.period.seconds = 60
bookingservice  | 	sasl.login.refresh.window.factor = 0.8
bookingservice  | 	sasl.login.refresh.window.jitter = 0.05
bookingservice  | 	sasl.login.retry.backoff.max.ms = 10000
bookingservice  | 	sasl.login.retry.backoff.ms = 100
bookingservice  | 	sasl.mechanism = GSSAPI
bookingservice  | 	sasl.oauthbearer.clock.skew.seconds = 30
bookingservice  | 	sasl.oauthbearer.expected.audience = null
bookingservice  | 	sasl.oauthbearer.expected.issuer = null
bookingservice  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
bookingservice  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
bookingservice  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
bookingservice  | 	sasl.oauthbearer.jwks.endpoint.url = null
bookingservice  | 	sasl.oauthbearer.scope.claim.name = scope
bookingservice  | 	sasl.oauthbearer.sub.claim.name = sub
bookingservice  | 	sasl.oauthbearer.token.endpoint.url = null
bookingservice  | 	security.protocol = PLAINTEXT
bookingservice  | 	security.providers = null
bookingservice  | 	send.buffer.bytes = 131072
bookingservice  | 	session.timeout.ms = 45000
bookingservice  | 	socket.connection.setup.timeout.max.ms = 30000
bookingservice  | 	socket.connection.setup.timeout.ms = 10000
bookingservice  | 	ssl.cipher.suites = null
bookingservice  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
bookingservice  | 	ssl.endpoint.identification.algorithm = https
bookingservice  | 	ssl.engine.factory.class = null
bookingservice  | 	ssl.key.password = null
bookingservice  | 	ssl.keymanager.algorithm = SunX509
bookingservice  | 	ssl.keystore.certificate.chain = null
bookingservice  | 	ssl.keystore.key = null
bookingservice  | 	ssl.keystore.location = null
bookingservice  | 	ssl.keystore.password = null
bookingservice  | 	ssl.keystore.type = JKS
bookingservice  | 	ssl.protocol = TLSv1.3
bookingservice  | 	ssl.provider = null
bookingservice  | 	ssl.secure.random.implementation = null
bookingservice  | 	ssl.trustmanager.algorithm = PKIX
bookingservice  | 	ssl.truststore.certificates = null
bookingservice  | 	ssl.truststore.location = null
bookingservice  | 	ssl.truststore.password = null
bookingservice  | 	ssl.truststore.type = JKS
bookingservice  | 	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
bookingservice  | 
bookingservice  | 2025-12-22T19:24:42.957Z  WARN 1 --- [bookingservice] [foReplicator-%d] c.n.discovery.InstanceInfoReplicator     : There was a problem with the instance info replicator
bookingservice  | 
bookingservice  | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105) ~[eureka-client-2.0.3.jar!/:2.0.3]
bookingservice  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
bookingservice  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
bookingservice  | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
bookingservice  | 
authservice     | 2025-12-22T19:24:42.972Z  INFO 1 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8001 (http) with context path ''
authservice     | 2025-12-22T19:24:42.977Z  INFO 1 --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8001
authservice     | 2025-12-22T19:24:42.999Z  INFO 1 --- [nfoReplicator-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://eurekaserver:8761/eureka/}, exception=I/O error on POST request for "http://eurekaserver:8761/eureka/apps/AUTHSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/AUTHSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
authservice     | 	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:888)
authservice     | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:868)
authservice     | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:764)
authservice     | 	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:646)
authservice     | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:81)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
authservice     | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:820)
authservice     | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
authservice     | 	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
authservice     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
authservice     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
authservice     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
authservice     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
authservice     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
authservice     | 	at java.base/java.lang.Thread.run(Thread.java:833)
authservice     | Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
authservice     | 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
authservice     | 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
authservice     | 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
authservice     | 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
authservice     | 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
authservice     | 	at java.base/java.net.Socket.connect(Socket.java:633)
authservice     | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.lambda$connectSocket$0(PlainConnectionSocketFactory.java:85)
authservice     | 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
authservice     | 	at org.apache.hc.client5.http.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:84)
authservice     | 	at org.apache.hc.client5.http.socket.ConnectionSocketFactory.connectSocket(ConnectionSocketFactory.java:113)
authservice     | 	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:181)
authservice     | 	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:447)
authservice     | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)
authservice     | 	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:96)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:115)
authservice     | 	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
authservice     | 	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
authservice     | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:106)
authservice     | 	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
authservice     | 	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:93)
authservice     | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
authservice     | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
authservice     | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:101)
authservice     | 	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$0(RestTemplateTransportClientFactory.java:143)
authservice     | 	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:87)
authservice     | 	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:71)
authservice     | 	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
authservice     | 	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
authservice     | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:862)
authservice     | 	... 22 more
authservice     | 
authservice     | 2025-12-22T19:24:43.002Z  WARN 1 --- [nfoReplicator-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on POST request for "http://eurekaserver:8761/eureka/apps/AUTHSERVICE": Connect to http://eurekaserver:8761 [eurekaserver/172.18.0.6] failed: Connection refused
authservice     | 2025-12-22T19:24:43.003Z  WARN 1 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001 - registration failed Cannot execute request on any known server
authservice     | 
authservice     | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:820) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
authservice     | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
authservice     | 
authservice     | 2025-12-22T19:24:43.011Z  WARN 1 --- [nfoReplicator-0] c.n.discovery.InstanceInfoReplicator     : There was a problem with the instance info replicator
authservice     | 
authservice     | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
authservice     | 	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:820) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101) ~[eureka-client-2.0.1.jar!/:2.0.1]
authservice     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
authservice     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
authservice     | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
authservice     | 
authservice     | 2025-12-22T19:24:43.038Z  INFO 1 --- [           main] com.authservice.AuthserviceApplication   : Started AuthserviceApplication in 47.177 seconds (process running for 62.293)
eurekaserver    | 2025-12-22T19:24:43.075Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eurekaserver    | 2025-12-22T19:24:43.075Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eurekaserver    | 2025-12-22T19:24:43.075Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eurekaserver    | 2025-12-22T19:24:43.075Z  INFO 1 --- [eurekaserver] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
bookingservice  | 2025-12-22T19:24:43.105Z  INFO 1 --- [bookingservice] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
eurekaserver    | 2025-12-22T19:24:43.207Z  INFO 1 --- [eurekaserver] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Replica node URL:  http://localhost:8761/eureka/
eurekaserver    | 2025-12-22T19:24:43.227Z  INFO 1 --- [eurekaserver] [           main] c.n.e.registry.AbstractInstanceRegistry  : Finished initializing remote region registries. All known remote regions: []
eurekaserver    | 2025-12-22T19:24:43.228Z  INFO 1 --- [eurekaserver] [           main] c.n.eureka.DefaultEurekaServerContext    : Initialized
eurekaserver    | 2025-12-22T19:24:43.252Z  INFO 1 --- [eurekaserver] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
eurekaserver    | 2025-12-22T19:24:43.347Z  INFO 1 --- [eurekaserver] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application EUREKASERVER with eureka with status UP
bookingservice  | 2025-12-22T19:24:43.401Z  INFO 1 --- [bookingservice] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.7.0
bookingservice  | 2025-12-22T19:24:43.402Z  INFO 1 --- [bookingservice] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 2ae524ed625438c5
bookingservice  | 2025-12-22T19:24:43.402Z  INFO 1 --- [bookingservice] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1766431483398
eurekaserver    | 2025-12-22T19:24:43.403Z  INFO 1 --- [eurekaserver] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : isAws returned false
eurekaserver    | 2025-12-22T19:24:43.404Z  INFO 1 --- [eurekaserver] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : Initialized server context
eurekaserver    | 2025-12-22T19:24:43.406Z  INFO 1 --- [eurekaserver] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node
eurekaserver    | 2025-12-22T19:24:43.406Z  INFO 1 --- [eurekaserver] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1
eurekaserver    | 2025-12-22T19:24:43.407Z  INFO 1 --- [eurekaserver] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP
eurekaserver    | 2025-12-22T19:24:43.410Z  INFO 1 --- [eurekaserver] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8761 (http) with context path '/'
bookingservice  | 2025-12-22T19:24:43.411Z  INFO 1 --- [bookingservice] [           main] o.a.k.c.c.internals.LegacyKafkaConsumer  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): booking-email
eurekaserver    | 2025-12-22T19:24:43.413Z  INFO 1 --- [eurekaserver] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8761
eurekaserver    | 2025-12-22T19:24:43.414Z  INFO 1 --- [eurekaserver] [       Thread-9] e.s.EurekaServerInitializerConfiguration : Started Eureka Server
eurekaserver    | 2025-12-22T19:24:43.451Z  INFO 1 --- [eurekaserver] [           main] c.eurekaserver.EurekaserverApplication   : Started EurekaserverApplication in 47.557 seconds (process running for 64.273)
bookingservice  | 2025-12-22T19:24:43.466Z  INFO 1 --- [bookingservice] [           main] c.b.BookingserviceApplication            : Started BookingserviceApplication in 45.813 seconds (process running for 62.034)
kafka           | [2025-12-22 19:24:44,023] INFO Creating topic booking-email with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
bookingservice  | 2025-12-22T19:24:44.094Z  WARN 1 --- [bookingservice] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-group-1, groupId=email-group] Error while fetching metadata with correlation id 2 : {booking-email=LEADER_NOT_AVAILABLE}
bookingservice  | 2025-12-22T19:24:44.096Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: rrb9RMHdQYGSE_4KHmO67Q
kafka           | [2025-12-22 19:24:44,113] INFO [Controller id=1] New topics: [Set(booking-email)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(booking-email,Some(566XM1GtSFOLVQRaXQaXhA),Map(booking-email-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:44,116] INFO [Controller id=1] New partition creation callback for booking-email-0 (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:44,120] INFO [Controller id=1 epoch=1] Changed partition booking-email-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,120] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 23 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 45 -> ArrayBuffer(1), 46 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 49 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
kafka           | [2025-12-22 19:24:44,121] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,127] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition booking-email-0 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,127] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,162] INFO [Controller id=1 epoch=1] Changed partition booking-email-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,166] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition booking-email-0 (state.change.logger)
kafka           | [2025-12-22 19:24:44,167] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,171] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,174] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition booking-email-0 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,174] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,179] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 1 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,181] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,183] INFO [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(zzTFhURtRwmF1KPJB16HMA),HashMap(__consumer_offsets-22 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-30 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-25 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-35 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-37 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-38 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-13 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-8 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-21 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-27 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-9 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-46 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-41 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-33 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-23 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-49 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-47 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-16 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-28 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-31 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-36 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-42 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-18 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-15 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-24 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-17 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-48 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-19 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-11 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-43 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-6 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-14 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-20 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-44 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-39 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-12 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-45 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-5 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-26 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-29 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-34 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-32 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-40 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:44,183] INFO [Controller id=1] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-37,__consumer_offsets-38,__consumer_offsets-13,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,184] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,185] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,186] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,186] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,186] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,186] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,186] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,187] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,187] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,187] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,187] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,187] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,188] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,189] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,189] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,189] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,189] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,189] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,189] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,190] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,191] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,191] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,191] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,193] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,196] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,198] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,199] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,200] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,227] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition booking-email-0 (state.change.logger)
kafka           | [2025-12-22 19:24:44,236] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(booking-email-0) (kafka.server.ReplicaFetcherManager)
kafka           | [2025-12-22 19:24:44,236] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 1 as part of the become-leader transition for 1 partitions (state.change.logger)
bookingservice  | 2025-12-22T19:24:44.285Z  WARN 1 --- [bookingservice] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-group-1, groupId=email-group] Error while fetching metadata with correlation id 5 : {booking-email=LEADER_NOT_AVAILABLE}
kafka           | [2025-12-22 19:24:44,351] INFO [LogLoader partition=booking-email-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,373] INFO Created log for partition booking-email-0 in /var/lib/kafka/data/booking-email-0 with properties {} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,376] INFO [Partition booking-email-0 broker=1] No checkpointed highwatermark is found for partition booking-email-0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,377] INFO [Partition booking-email-0 broker=1] Log loaded for partition booking-email-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,379] INFO [Broker id=1] Leader booking-email-0 with topic id Some(566XM1GtSFOLVQRaXQaXhA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,399] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition booking-email-0 (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Broker id=1] Finished LeaderAndIsr request in 233ms correlationId 1 from controller 1 for 1 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,409] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,410] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,411] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] INFO [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), leaderRecoveryState=RECOVERED, partitionEpoch=0) (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
kafka           | [2025-12-22 19:24:44,412] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
kafka           | [2025-12-22 19:24:44,413] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
kafka           | [2025-12-22 19:24:44,414] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=566XM1GtSFOLVQRaXQaXhA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
kafka           | [2025-12-22 19:24:44,415] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
kafka           | [2025-12-22 19:24:44,416] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
kafka           | [2025-12-22 19:24:44,417] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
kafka           | [2025-12-22 19:24:44,417] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
kafka           | [2025-12-22 19:24:44,417] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
kafka           | [2025-12-22 19:24:44,417] INFO [Controller id=1 epoch=1] Sending LeaderAndIsr request to broker 1 with 50 become-leader and 0 become-follower partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,417] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 50 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,420] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,421] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
kafka           | [2025-12-22 19:24:44,422] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,426] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='booking-email', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition booking-email-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
kafka           | [2025-12-22 19:24:44,427] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
kafka           | [2025-12-22 19:24:44,428] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 for 50 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,432] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,433] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,434] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=true, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
kafka           | [2025-12-22 19:24:44,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
kafka           | [2025-12-22 19:24:44,461] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
kafka           | [2025-12-22 19:24:44,462] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
kafka           | [2025-12-22 19:24:44,463] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 1 epoch 1 as part of the become-leader transition for 50 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:44,471] INFO [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,473] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,475] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,475] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,476] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,487] INFO [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,488] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,488] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,488] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,488] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,502] INFO [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,503] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,503] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,503] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,503] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,521] INFO [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,522] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,522] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,523] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,523] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,536] INFO [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,537] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,537] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,537] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,537] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,588] INFO [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,589] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,589] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,589] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,589] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,603] INFO [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,604] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,604] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,604] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,604] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,618] INFO [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,619] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,619] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,619] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,619] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,632] INFO [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,633] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,633] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,633] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,633] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,647] INFO [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,648] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,648] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,649] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,649] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,662] INFO [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,663] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,663] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,663] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,663] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,685] INFO [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,686] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,686] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,687] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,687] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,735] INFO [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,736] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,736] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,736] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,737] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,750] INFO [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,751] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,751] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,751] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,751] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,763] INFO [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,764] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,764] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,765] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,765] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,776] INFO [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,777] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,777] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,777] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,777] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,788] INFO [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,789] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,789] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,789] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,789] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,845] INFO [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,847] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,847] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,847] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,847] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,861] INFO [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,862] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,862] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,862] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,862] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,874] INFO [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,876] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,876] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,876] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,876] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,893] INFO [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,894] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,894] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,894] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,894] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,936] INFO [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,937] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,937] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,937] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,937] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,950] INFO [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,951] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,951] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,952] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,952] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,964] INFO [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,965] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,965] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,965] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,965] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:44,976] INFO [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:44,977] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:44,977] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,977] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:44,977] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,023] INFO [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,024] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,025] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,025] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,025] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,036] INFO [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,037] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,037] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,037] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,037] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,049] INFO [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,049] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,050] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,050] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,050] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,061] INFO [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,061] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,062] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,062] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,062] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,106] INFO [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,107] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,107] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,107] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,107] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,120] INFO [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,121] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,121] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,121] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,122] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,132] INFO [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,132] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,133] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,133] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,133] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,144] INFO [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,145] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,145] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,145] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,145] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,194] INFO [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,195] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,195] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,195] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,195] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,204] INFO [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,205] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,206] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,206] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,206] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,217] INFO [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,218] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,218] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,218] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,218] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,230] INFO [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,230] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,231] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,231] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,231] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,272] INFO [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,273] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,273] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,273] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,273] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,288] INFO [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,288] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,288] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,288] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,289] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,298] INFO [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,299] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,299] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,299] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,299] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,311] INFO [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,312] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,312] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,312] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,312] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,362] INFO [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,363] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,363] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,363] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,363] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,375] INFO [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,376] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,376] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,376] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,376] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,386] INFO [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,387] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,387] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,387] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,387] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,397] INFO [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,398] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,398] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,398] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,398] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,438] INFO [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,439] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,439] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,439] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,440] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,458] INFO [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,458] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,459] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,459] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,459] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,471] INFO [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,472] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,472] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,472] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,472] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,482] INFO [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,483] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,483] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,483] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,483] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,492] INFO [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2025-12-22 19:24:45,493] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafka           | [2025-12-22 19:24:45,493] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,493] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2025-12-22 19:24:45,493] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(zzTFhURtRwmF1KPJB16HMA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
kafka           | [2025-12-22 19:24:45,500] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
kafka           | [2025-12-22 19:24:45,501] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
kafka           | [2025-12-22 19:24:45,502] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,503] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,504] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,505] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,507] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,507] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,507] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,507] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,507] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:45,507] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,507] INFO [Broker id=1] Finished LeaderAndIsr request in 1075ms correlationId 3 from controller 1 for 50 partitions (state.change.logger)
kafka           | [2025-12-22 19:24:45,508] TRACE [Controller id=1 epoch=1] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=zzTFhURtRwmF1KPJB16HMA, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=13, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=46, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=9, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=42, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=21, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=17, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=30, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=26, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=5, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=38, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=1, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=34, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=16, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=45, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=12, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=41, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=24, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=20, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=49, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=29, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=25, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=8, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=37, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=4, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=33, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=15, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=48, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=11, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=44, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=23, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=19, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=32, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=28, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=7, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=40, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=3, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=36, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=47, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=14, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=43, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=10, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=22, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=18, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=31, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=27, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=39, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=6, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=35, errorCode=0), LeaderAndIsrPartitionError(topicName='', partitionIndex=2, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 3 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=46, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=9, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=21, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=5, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=1, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=34, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=45, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,510] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=37, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=33, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=15, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=11, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=44, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=19, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,511] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=28, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=36, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 7 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,512] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=43, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=10, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=22, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=27, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,513] INFO [Broker id=1] Add 50 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
kafka           | [2025-12-22 19:24:45,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,514] TRACE [Controller id=1 epoch=1] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 4 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
kafka           | [2025-12-22 19:24:45,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 11 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 11 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,519] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,519] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,519] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,519] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,519] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,521] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,521] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,521] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2025-12-22 19:24:45,521] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
bookingservice  | 2025-12-22T19:24:45.858Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator kafka:29092 (id: 2147483646 rack: null)
bookingservice  | 2025-12-22T19:24:45.871Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
kafka           | [2025-12-22 19:24:45,892] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group email-group in Empty state. Created a new member id consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
bookingservice  | 2025-12-22T19:24:45.897Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8
bookingservice  | 2025-12-22T19:24:45.898Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
kafka           | [2025-12-22 19:24:45,905] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8 with group instance id None; client reason: need to re-join with the given member-id: consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8) (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:24:48,921] INFO [GroupCoordinator 1]: Stabilized group email-group generation 1 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
bookingservice  | 2025-12-22T19:24:48.928Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8', protocol='range'}
bookingservice  | 2025-12-22T19:24:48.934Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Finished assignment for group at generation 1: {consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8=Assignment(partitions=[booking-email-0])}
kafka           | [2025-12-22 19:24:48,947] INFO [GroupCoordinator 1]: Assignment received from leader consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8 for group email-group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
bookingservice  | 2025-12-22T19:24:49.054Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8', protocol='range'}
bookingservice  | 2025-12-22T19:24:49.054Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[booking-email-0])
bookingservice  | 2025-12-22T19:24:49.057Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: booking-email-0
bookingservice  | 2025-12-22T19:24:49.069Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Found no committed offset for partition booking-email-0
bookingservice  | 2025-12-22T19:24:49.074Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Found no committed offset for partition booking-email-0
bookingservice  | 2025-12-22T19:24:49.088Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting offset for partition booking-email-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:29092 (id: 1 rack: null)], epoch=0}}.
bookingservice  | 2025-12-22T19:24:49.106Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-group: partitions assigned: [booking-email-0]
flightservice   | 2025-12-22T19:25:10.944Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
flightservice   | 2025-12-22T19:25:10.944Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
flightservice   | 2025-12-22T19:25:10.944Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
flightservice   | 2025-12-22T19:25:10.944Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
flightservice   | 2025-12-22T19:25:10.944Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
flightservice   | 2025-12-22T19:25:10.944Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
flightservice   | 2025-12-22T19:25:10.945Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
eurekaserver    | 2025-12-22T19:25:11.032Z  INFO 1 --- [eurekaserver] [nio-8761-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
eurekaserver    | 2025-12-22T19:25:11.032Z  INFO 1 --- [eurekaserver] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
eurekaserver    | 2025-12-22T19:25:11.033Z  INFO 1 --- [eurekaserver] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
apigateway      | 2025-12-22T19:25:11.063Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
eurekaserver    | 2025-12-22T19:25:11.137Z  WARN 1 --- [eurekaserver] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : DS: Registry: lease doesn't exist, registering resource: FLIGHTSERVICE - b2d76f89341f:flightservice:8082
eurekaserver    | 2025-12-22T19:25:11.137Z  WARN 1 --- [eurekaserver] [nio-8761-exec-2] c.n.eureka.resources.InstanceResource    : Not Found (Renew): FLIGHTSERVICE - b2d76f89341f:flightservice:8082
eurekaserver    | 2025-12-22T19:25:11.142Z  WARN 1 --- [eurekaserver] [nio-8761-exec-4] c.n.e.registry.AbstractInstanceRegistry  : DS: Registry: lease doesn't exist, registering resource: APIGATEWAY - b5fa703cd3a8:apigateway:8088
eurekaserver    | 2025-12-22T19:25:11.143Z  WARN 1 --- [eurekaserver] [nio-8761-exec-4] c.n.eureka.resources.InstanceResource    : Not Found (Renew): APIGATEWAY - b5fa703cd3a8:apigateway:8088
apigateway      | 2025-12-22T19:25:11.213Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
flightservice   | 2025-12-22T19:25:11.231Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
apigateway      | 2025-12-22T19:25:11.253Z  INFO 1 --- [apigateway] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088 - Re-registering apps/APIGATEWAY
apigateway      | 2025-12-22T19:25:11.254Z  INFO 1 --- [apigateway] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088: registering service...
flightservice   | 2025-12-22T19:25:11.254Z  INFO 1 --- [flightservice] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082 - Re-registering apps/FLIGHTSERVICE
flightservice   | 2025-12-22T19:25:11.254Z  INFO 1 --- [flightservice] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082: registering service...
eurekaserver    | 2025-12-22T19:25:11.364Z  INFO 1 --- [eurekaserver] [nio-8761-exec-5] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/b2d76f89341f:flightservice:8082 with status UP (replication=false)
eurekaserver    | 2025-12-22T19:25:11.364Z  INFO 1 --- [eurekaserver] [nio-8761-exec-6] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/b5fa703cd3a8:apigateway:8088 with status UP (replication=false)
flightservice   | 2025-12-22T19:25:11.373Z  INFO 1 --- [flightservice] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082 - registration status: 204
apigateway      | 2025-12-22T19:25:11.373Z  INFO 1 --- [apigateway] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088 - registration status: 204
eurekaserver    | 2025-12-22T19:25:12.091Z  INFO 1 --- [eurekaserver] [nio-8761-exec-7] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/b5fa703cd3a8:apigateway:8088 with status UP (replication=true)
eurekaserver    | 2025-12-22T19:25:12.092Z  INFO 1 --- [eurekaserver] [nio-8761-exec-7] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/b2d76f89341f:flightservice:8082 with status UP (replication=true)
bookingservice  | 2025-12-22T19:25:12.606Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
bookingservice  | 2025-12-22T19:25:12.607Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
bookingservice  | 2025-12-22T19:25:12.607Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
bookingservice  | 2025-12-22T19:25:12.607Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
bookingservice  | 2025-12-22T19:25:12.607Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
bookingservice  | 2025-12-22T19:25:12.607Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
bookingservice  | 2025-12-22T19:25:12.607Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
eurekaserver    | 2025-12-22T19:25:12.638Z  WARN 1 --- [eurekaserver] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : DS: Registry: lease doesn't exist, registering resource: BOOKINGSERVICE - 288dadc79977:bookingservice:8081
eurekaserver    | 2025-12-22T19:25:12.638Z  WARN 1 --- [eurekaserver] [nio-8761-exec-9] c.n.eureka.resources.InstanceResource    : Not Found (Renew): BOOKINGSERVICE - 288dadc79977:bookingservice:8081
bookingservice  | 2025-12-22T19:25:12.674Z  INFO 1 --- [bookingservice] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081 - Re-registering apps/BOOKINGSERVICE
bookingservice  | 2025-12-22T19:25:12.674Z  INFO 1 --- [bookingservice] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081: registering service...
bookingservice  | 2025-12-22T19:25:12.674Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
eurekaserver    | 2025-12-22T19:25:12.683Z  INFO 1 --- [eurekaserver] [io-8761-exec-10] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/288dadc79977:bookingservice:8081 with status UP (replication=false)
bookingservice  | 2025-12-22T19:25:12.685Z  INFO 1 --- [bookingservice] [beatExecutor-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081 - registration status: 204
authservice     | 2025-12-22T19:25:12.705Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
authservice     | 2025-12-22T19:25:12.705Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
authservice     | 2025-12-22T19:25:12.706Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
authservice     | 2025-12-22T19:25:12.706Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
authservice     | 2025-12-22T19:25:12.706Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
authservice     | 2025-12-22T19:25:12.706Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
authservice     | 2025-12-22T19:25:12.706Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
eurekaserver    | 2025-12-22T19:25:12.760Z  WARN 1 --- [eurekaserver] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : DS: Registry: lease doesn't exist, registering resource: AUTHSERVICE - 9798ba71eb9c:authservice:8001
eurekaserver    | 2025-12-22T19:25:12.761Z  WARN 1 --- [eurekaserver] [nio-8761-exec-1] c.n.eureka.resources.InstanceResource    : Not Found (Renew): AUTHSERVICE - 9798ba71eb9c:authservice:8001
authservice     | 2025-12-22T19:25:12.773Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
authservice     | 2025-12-22T19:25:12.773Z  INFO 1 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001 - Re-registering apps/AUTHSERVICE
authservice     | 2025-12-22T19:25:12.773Z  INFO 1 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001: registering service...
eurekaserver    | 2025-12-22T19:25:12.783Z  INFO 1 --- [eurekaserver] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/9798ba71eb9c:authservice:8001 with status UP (replication=false)
authservice     | 2025-12-22T19:25:12.785Z  INFO 1 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001 - registration status: 204
eurekaserver    | 2025-12-22T19:25:13.191Z  INFO 1 --- [eurekaserver] [nio-8761-exec-4] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/288dadc79977:bookingservice:8081 with status UP (replication=true)
eurekaserver    | 2025-12-22T19:25:13.192Z  INFO 1 --- [eurekaserver] [nio-8761-exec-4] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/9798ba71eb9c:authservice:8001 with status UP (replication=true)
mongodb         | {"t":{"$date":"2025-12-22T19:25:39.983+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":"[1766431539:983051][1:0x7f758e999700], WT_SESSION.checkpoint: [WT_VERB_CHECKPOINT_PROGRESS] saving checkpoint snapshot min: 6, snapshot max: 6 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 7178"}}
apigateway      | 2025-12-22T19:25:41.213Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway      | 2025-12-22T19:25:41.213Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway      | 2025-12-22T19:25:41.213Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway      | 2025-12-22T19:25:41.213Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway      | 2025-12-22T19:25:41.214Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway      | 2025-12-22T19:25:41.214Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
apigateway      | 2025-12-22T19:25:41.214Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
apigateway      | 2025-12-22T19:25:41.225Z  INFO 1 --- [apigateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
flightservice   | 2025-12-22T19:25:41.229Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
flightservice   | 2025-12-22T19:25:41.230Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
flightservice   | 2025-12-22T19:25:41.230Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
flightservice   | 2025-12-22T19:25:41.230Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
flightservice   | 2025-12-22T19:25:41.230Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
flightservice   | 2025-12-22T19:25:41.230Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
flightservice   | 2025-12-22T19:25:41.230Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
flightservice   | 2025-12-22T19:25:41.253Z  INFO 1 --- [flightservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
bookingservice  | 2025-12-22T19:25:42.673Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
bookingservice  | 2025-12-22T19:25:42.673Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
bookingservice  | 2025-12-22T19:25:42.674Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
bookingservice  | 2025-12-22T19:25:42.674Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
bookingservice  | 2025-12-22T19:25:42.674Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
bookingservice  | 2025-12-22T19:25:42.674Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
bookingservice  | 2025-12-22T19:25:42.674Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-22T19:25:42.689Z  INFO 1 --- [bookingservice] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
authservice     | 2025-12-22T19:25:42.772Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
authservice     | 2025-12-22T19:25:42.772Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
authservice     | 2025-12-22T19:25:42.772Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
authservice     | 2025-12-22T19:25:42.772Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
authservice     | 2025-12-22T19:25:42.772Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
authservice     | 2025-12-22T19:25:42.772Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
authservice     | 2025-12-22T19:25:42.773Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
authservice     | 2025-12-22T19:25:42.791Z  INFO 1 --- [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
eurekaserver    | 2025-12-22T19:25:43.410Z  INFO 1 --- [eurekaserver] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
mongodb         | {"t":{"$date":"2025-12-22T19:26:40.053+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"Checkpointer","msg":"WiredTiger message","attr":{"message":"[1766431600:53149][1:0x7f758e999700], WT_SESSION.checkpoint: [WT_VERB_CHECKPOINT_PROGRESS] saving checkpoint snapshot min: 8, snapshot max: 8 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 7178"}}
authservice     | 2025-12-22T19:26:42.672Z  INFO 1 --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application AUTHSERVICE with eureka with status DOWN
apigateway      | 2025-12-22T19:26:42.674Z  INFO 1 --- [apigateway] [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application APIGATEWAY with eureka with status DOWN
apigateway      | 2025-12-22T19:26:42.675Z  INFO 1 --- [apigateway] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431602675, current=DOWN, previous=UP]
apigateway      | 2025-12-22T19:26:42.675Z  INFO 1 --- [apigateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088: registering service...
bookingservice  | 2025-12-22T19:26:42.678Z  INFO 1 --- [bookingservice] [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application BOOKINGSERVICE with eureka with status DOWN
bookingservice  | 2025-12-22T19:26:42.679Z  INFO 1 --- [bookingservice] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431602679, current=DOWN, previous=UP]
bookingservice  | 2025-12-22T19:26:42.680Z  INFO 1 --- [bookingservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081: registering service...
eurekaserver    | 2025-12-22T19:26:42.682Z  INFO 1 --- [eurekaserver] [nio-8761-exec-7] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/b5fa703cd3a8:apigateway:8088 with status DOWN (replication=false)
flightservice   | 2025-12-22T19:26:42.682Z  INFO 1 --- [flightservice] [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application FLIGHTSERVICE with eureka with status DOWN
flightservice   | 2025-12-22T19:26:42.682Z  INFO 1 --- [flightservice] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431602682, current=DOWN, previous=UP]
flightservice   | 2025-12-22T19:26:42.686Z  INFO 1 --- [flightservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082: registering service...
authservice     | 2025-12-22T19:26:42.690Z  INFO 1 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1766431602673, current=DOWN, previous=UP]
authservice     | 2025-12-22T19:26:42.690Z  INFO 1 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001: registering service...
eurekaserver    | 2025-12-22T19:26:42.691Z  INFO 1 --- [eurekaserver] [nio-8761-exec-8] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/288dadc79977:bookingservice:8081 with status DOWN (replication=false)
bookingservice  | 2025-12-22T19:26:42.694Z  INFO 1 --- [bookingservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/288dadc79977:bookingservice:8081 - registration status: 204
eurekaserver    | 2025-12-22T19:26:42.695Z  INFO 1 --- [eurekaserver] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/b2d76f89341f:flightservice:8082 with status DOWN (replication=false)
flightservice   | 2025-12-22T19:26:42.697Z  INFO 1 --- [flightservice] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/b2d76f89341f:flightservice:8082 - registration status: 204
bookingservice  | 2025-12-22T19:26:42.706Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions booking-email-0
eurekaserver    | 2025-12-22T19:26:42.708Z  INFO 1 --- [eurekaserver] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/9798ba71eb9c:authservice:8001 with status DOWN (replication=false)
apigateway      | 2025-12-22T19:26:42.708Z  INFO 1 --- [apigateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b5fa703cd3a8:apigateway:8088 - registration status: 204
bookingservice  | 2025-12-22T19:26:42.709Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-group: partitions revoked: [booking-email-0]
bookingservice  | 2025-12-22T19:26:42.710Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8 sending LeaveGroup request to coordinator kafka:29092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
authservice     | 2025-12-22T19:26:42.712Z  INFO 1 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/9798ba71eb9c:authservice:8001 - registration status: 204
bookingservice  | 2025-12-22T19:26:42.717Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
bookingservice  | 2025-12-22T19:26:42.717Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
bookingservice  | 2025-12-22T19:26:42.718Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.LegacyKafkaConsumer  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
bookingservice  | 2025-12-22T19:26:42.722Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
bookingservice  | 2025-12-22T19:26:42.722Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
mongodb         | {"t":{"$date":"2025-12-22T19:26:42.726+00:00"},"s":"I",  "c":"-",        "id":20883,   "ctx":"conn1","msg":"Interrupted operation as its client disconnected","attr":{"opId":2258}}
kafka           | [2025-12-22 19:26:42,730] INFO [GroupCoordinator 1]: Preparing to rebalance group email-group in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: Removing member consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8 on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:26:42,733] INFO [GroupCoordinator 1]: Group email-group with generation 2 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
flightservice   | 2025-12-22T19:26:42.738Z  INFO 1 --- [flightservice] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
kafka           | [2025-12-22 19:26:42,742] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-email-group-1-7e90b569-6e1b-4f3b-8711-8f1b345a60b8, groupInstanceId=None, clientId=consumer-email-group-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group email-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
mongodb         | {"t":{"$date":"2025-12-22T19:26:42.745+00:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn2","msg":"Connection ended","attr":{"remote":"172.18.0.7:48036","uuid":"986f1c19-7f2f-470f-baf5-750d4bba0ed0","connectionId":2,"connectionCount":5}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:42.750+00:00"},"s":"I",  "c":"-",        "id":20883,   "ctx":"conn4","msg":"Interrupted operation as its client disconnected","attr":{"opId":2256}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:42.756+00:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn1","msg":"Connection ended","attr":{"remote":"172.18.0.7:48028","uuid":"87991208-6b74-4cca-af61-e2f5f018d93d","connectionId":1,"connectionCount":4}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:42.757+00:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn4","msg":"Connection ended","attr":{"remote":"172.18.0.8:49764","uuid":"647573e4-3bc4-43a6-bd3e-a70d2ca88c50","connectionId":4,"connectionCount":3}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:42.759+00:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn3","msg":"Connection ended","attr":{"remote":"172.18.0.8:39844","uuid":"53e3a5b3-96b4-49d5-9d64-14b1b17b3fab","connectionId":3,"connectionCount":2}}
authservice     | 2025-12-22T19:26:42.759Z  INFO 1 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
bookingservice  | 2025-12-22T19:26:43.199Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
bookingservice  | 2025-12-22T19:26:43.199Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
bookingservice  | 2025-12-22T19:26:43.199Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
bookingservice  | 2025-12-22T19:26:43.200Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
eurekaserver    | 2025-12-22T19:26:43.200Z  INFO 1 --- [eurekaserver] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/b5fa703cd3a8:apigateway:8088 with status DOWN (replication=true)
eurekaserver    | 2025-12-22T19:26:43.202Z  INFO 1 --- [eurekaserver] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/288dadc79977:bookingservice:8081 with status DOWN (replication=true)
eurekaserver    | 2025-12-22T19:26:43.203Z  INFO 1 --- [eurekaserver] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/b2d76f89341f:flightservice:8082 with status DOWN (replication=true)
eurekaserver    | 2025-12-22T19:26:43.204Z  INFO 1 --- [eurekaserver] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/9798ba71eb9c:authservice:8001 with status DOWN (replication=true)
bookingservice  | 2025-12-22T19:26:43.211Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-email-group-1 unregistered
bookingservice  | 2025-12-22T19:26:43.212Z  INFO 1 --- [bookingservice] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-group: Consumer stopped
mongodb         | {"t":{"$date":"2025-12-22T19:26:43.230+00:00"},"s":"I",  "c":"-",        "id":20883,   "ctx":"conn6","msg":"Interrupted operation as its client disconnected","attr":{"opId":2196}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:43.231+00:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn6","msg":"Connection ended","attr":{"remote":"172.18.0.10:52526","uuid":"f21089bf-8671-4e1c-b81e-7f24f4480281","connectionId":6,"connectionCount":1}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:43.232+00:00"},"s":"I",  "c":"NETWORK",  "id":22944,   "ctx":"conn5","msg":"Connection ended","attr":{"remote":"172.18.0.10:52520","uuid":"5f098cfc-3c57-4aa9-a9e1-ee3f4cc3a2d2","connectionId":5,"connectionCount":0}}
bookingservice  | 2025-12-22T19:26:43.243Z  INFO 1 --- [bookingservice] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
eurekaserver    | 2025-12-22T19:26:43.411Z  INFO 1 --- [eurekaserver] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 6ms
[Kapigateway exited with code 137
[Kauthservice exited with code 137
[Kbookingservice exited with code 137
[Kflightservice exited with code 137
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.049+00:00"},"s":"I",  "c":"CONTROL",  "id":23377,   "ctx":"SignalHandler","msg":"Received signal","attr":{"signal":15,"error":"Terminated"}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.049+00:00"},"s":"I",  "c":"CONTROL",  "id":23378,   "ctx":"SignalHandler","msg":"Signal was sent by kill(2)","attr":{"pid":0,"uid":0}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.049+00:00"},"s":"I",  "c":"CONTROL",  "id":23381,   "ctx":"SignalHandler","msg":"will terminate after current cmd ends"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.053+00:00"},"s":"I",  "c":"REPL",     "id":4784900, "ctx":"SignalHandler","msg":"Stepping down the ReplicationCoordinator for shutdown","attr":{"waitTimeMillis":15000}}
eurekaserver    | 2025-12-22T19:26:45.055Z  INFO 1 --- [eurekaserver] [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application EUREKASERVER with eureka with status DOWN
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.060+00:00"},"s":"I",  "c":"REPL",     "id":4794602, "ctx":"SignalHandler","msg":"Attempting to enter quiesce mode"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.060+00:00"},"s":"I",  "c":"COMMAND",  "id":4784901, "ctx":"SignalHandler","msg":"Shutting down the MirrorMaestro"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.060+00:00"},"s":"I",  "c":"SHARDING", "id":4784902, "ctx":"SignalHandler","msg":"Shutting down the WaitForMajorityService"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.061+00:00"},"s":"I",  "c":"CONTROL",  "id":4784903, "ctx":"SignalHandler","msg":"Shutting down the LogicalSessionCache"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"NETWORK",  "id":20562,   "ctx":"SignalHandler","msg":"Shutdown: going to close listening sockets"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"NETWORK",  "id":23017,   "ctx":"listener","msg":"removing socket file","attr":{"path":"/tmp/mongodb-27017.sock"}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"NETWORK",  "id":4784905, "ctx":"SignalHandler","msg":"Shutting down the global connection pool"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"CONTROL",  "id":4784906, "ctx":"SignalHandler","msg":"Shutting down the FlowControlTicketholder"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"-",        "id":20520,   "ctx":"SignalHandler","msg":"Stopping further Flow Control ticket acquisitions."}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"CONTROL",  "id":4784908, "ctx":"SignalHandler","msg":"Shutting down the PeriodicThreadToAbortExpiredTransactions"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"REPL",     "id":4784909, "ctx":"SignalHandler","msg":"Shutting down the ReplicationCoordinator"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"SHARDING", "id":4784910, "ctx":"SignalHandler","msg":"Shutting down the ShardingInitializationMongoD"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.062+00:00"},"s":"I",  "c":"REPL",     "id":4784911, "ctx":"SignalHandler","msg":"Enqueuing the ReplicationStateTransitionLock for shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"-",        "id":4784912, "ctx":"SignalHandler","msg":"Killing all operations for shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"-",        "id":4695300, "ctx":"SignalHandler","msg":"Interrupted all currently running operations","attr":{"opsKilled":3}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"TENANT_M", "id":5093807, "ctx":"SignalHandler","msg":"Shutting down all TenantMigrationAccessBlockers on global shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"COMMAND",  "id":4784913, "ctx":"SignalHandler","msg":"Shutting down all open transactions"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"REPL",     "id":4784914, "ctx":"SignalHandler","msg":"Acquiring the ReplicationStateTransitionLock for shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"INDEX",    "id":4784915, "ctx":"SignalHandler","msg":"Shutting down the IndexBuildsCoordinator"}
eurekaserver    | 2025-12-22T19:26:45.063Z  INFO 1 --- [eurekaserver] [ionShutdownHook] o.s.c.n.e.server.EurekaServerBootstrap   : Shutting down Eureka Server..
eurekaserver    | 2025-12-22T19:26:45.063Z  INFO 1 --- [eurekaserver] [ionShutdownHook] c.n.eureka.DefaultEurekaServerContext    : Shutting down ...
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"REPL",     "id":4784916, "ctx":"SignalHandler","msg":"Reacquiring the ReplicationStateTransitionLock for shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.063+00:00"},"s":"I",  "c":"REPL",     "id":4784917, "ctx":"SignalHandler","msg":"Attempting to mark clean shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.064+00:00"},"s":"I",  "c":"NETWORK",  "id":4784918, "ctx":"SignalHandler","msg":"Shutting down the ReplicaSetMonitor"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.065+00:00"},"s":"I",  "c":"SHARDING", "id":4784921, "ctx":"SignalHandler","msg":"Shutting down the MigrationUtilExecutor"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.068+00:00"},"s":"I",  "c":"ASIO",     "id":22582,   "ctx":"MigrationUtil-TaskExecutor","msg":"Killing all outstanding egress activity."}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.069+00:00"},"s":"I",  "c":"COMMAND",  "id":4784923, "ctx":"SignalHandler","msg":"Shutting down the ServiceEntryPoint"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.069+00:00"},"s":"I",  "c":"CONTROL",  "id":4784927, "ctx":"SignalHandler","msg":"Shutting down the HealthLog"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.069+00:00"},"s":"I",  "c":"CONTROL",  "id":4784928, "ctx":"SignalHandler","msg":"Shutting down the TTL monitor"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.069+00:00"},"s":"I",  "c":"INDEX",    "id":3684100, "ctx":"SignalHandler","msg":"Shutting down TTL collection monitor thread"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.070+00:00"},"s":"I",  "c":"INDEX",    "id":3684101, "ctx":"SignalHandler","msg":"Finished shutting down TTL collection monitor thread"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.070+00:00"},"s":"I",  "c":"CONTROL",  "id":4784929, "ctx":"SignalHandler","msg":"Acquiring the global lock for shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.070+00:00"},"s":"I",  "c":"CONTROL",  "id":4784930, "ctx":"SignalHandler","msg":"Shutting down the storage engine"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.070+00:00"},"s":"I",  "c":"STORAGE",  "id":22320,   "ctx":"SignalHandler","msg":"Shutting down journal flusher thread"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.071+00:00"},"s":"I",  "c":"STORAGE",  "id":22321,   "ctx":"SignalHandler","msg":"Finished shutting down journal flusher thread"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.071+00:00"},"s":"I",  "c":"STORAGE",  "id":22322,   "ctx":"SignalHandler","msg":"Shutting down checkpoint thread"}
eurekaserver    | 2025-12-22T19:26:45.070Z  INFO 1 --- [eurekaserver] [ionShutdownHook] c.n.eureka.DefaultEurekaServerContext    : Shut down
eurekaserver    | 2025-12-22T19:26:45.071Z  INFO 1 --- [eurekaserver] [ionShutdownHook] o.s.c.n.e.server.EurekaServerBootstrap   : Eureka Service is now shutdown...
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.071+00:00"},"s":"I",  "c":"STORAGE",  "id":22323,   "ctx":"SignalHandler","msg":"Finished shutting down checkpoint thread"}
eurekaserver    | 2025-12-22T19:26:45.065Z ERROR 1 --- [eurekaserver] [t-Conn-Cleaner2] c.n.d.s.t.j.EurekaJersey3ClientImpl      : Cannot clean connections
eurekaserver    | 
eurekaserver    | java.lang.IllegalStateException: Client instance has been closed.
eurekaserver    | 	at org.glassfish.jersey.internal.guava.Preconditions.checkState(Preconditions.java:169) ~[jersey-common-3.1.7.jar!/:na]
eurekaserver    | 	at org.glassfish.jersey.client.JerseyClient.checkNotClosed(JerseyClient.java:248) ~[jersey-client-3.1.7.jar!/:na]
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.071+00:00"},"s":"I",  "c":"STORAGE",  "id":22261,   "ctx":"SignalHandler","msg":"Timestamp monitor shutting down"}
eurekaserver    | 	at org.glassfish.jersey.client.JerseyClient.getConfiguration(JerseyClient.java:363) ~[jersey-client-3.1.7.jar!/:na]
eurekaserver    | 	at org.glassfish.jersey.client.JerseyClient.getConfiguration(JerseyClient.java:54) ~[jersey-client-3.1.7.jar!/:na]
eurekaserver    | 	at com.netflix.discovery.shared.transport.jersey3.EurekaJersey3ClientImpl$ConnectionCleanerTask.run(EurekaJersey3ClientImpl.java:338) ~[eureka-client-jersey3-2.0.3.jar!/:2.0.3]
eurekaserver    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
eurekaserver    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
eurekaserver    | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
eurekaserver    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
eurekaserver    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
eurekaserver    | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
eurekaserver    | 
eurekaserver    | 2025-12-22T19:26:45.072Z  INFO 1 --- [eurekaserver] [ionShutdownHook] c.n.eureka.DefaultEurekaServerContext    : Shutting down ...
eurekaserver    | 2025-12-22T19:26:45.072Z  INFO 1 --- [eurekaserver] [ionShutdownHook] c.n.eureka.DefaultEurekaServerContext    : Shut down
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.072+00:00"},"s":"I",  "c":"STORAGE",  "id":20282,   "ctx":"SignalHandler","msg":"Deregistering all the collections"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.072+00:00"},"s":"I",  "c":"STORAGE",  "id":22317,   "ctx":"SignalHandler","msg":"WiredTigerKVEngine shutting down"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.072+00:00"},"s":"I",  "c":"STORAGE",  "id":22318,   "ctx":"SignalHandler","msg":"Shutting down session sweeper thread"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.073+00:00"},"s":"I",  "c":"STORAGE",  "id":22319,   "ctx":"SignalHandler","msg":"Finished shutting down session sweeper thread"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.073+00:00"},"s":"I",  "c":"STORAGE",  "id":4795902, "ctx":"SignalHandler","msg":"Closing WiredTiger","attr":{"closeConfig":"leak_memory=true,"}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.073+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"SignalHandler","msg":"WiredTiger message","attr":{"message":"[1766431605:73890][1:0x7f75971aa700], close_ckpt: [WT_VERB_CHECKPOINT_PROGRESS] saving checkpoint snapshot min: 10, snapshot max: 10 snapshot count: 0, oldest timestamp: (0, 0) , meta checkpoint timestamp: (0, 0) base write gen: 7178"}}
eurekaserver    | 2025-12-22T19:26:45.077Z  INFO 1 --- [eurekaserver] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
eurekaserver    | 2025-12-22T19:26:45.077Z  INFO 1 --- [eurekaserver] [ionShutdownHook] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.084+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"SignalHandler","msg":"WiredTiger message","attr":{"message":"[1766431605:84338][1:0x7f75971aa700], WT_CONNECTION.close: [WT_VERB_RECOVERY_PROGRESS] shutdown checkpoint has successfully finished and ran for 10 milliseconds"}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.085+00:00"},"s":"I",  "c":"STORAGE",  "id":22430,   "ctx":"SignalHandler","msg":"WiredTiger message","attr":{"message":"[1766431605:85682][1:0x7f75971aa700], WT_CONNECTION.close: [WT_VERB_RECOVERY_PROGRESS] shutdown was completed successfully and took 10ms, including 0ms for the rollback to stable, and 10ms for the checkpoint."}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.097+00:00"},"s":"I",  "c":"STORAGE",  "id":4795901, "ctx":"SignalHandler","msg":"WiredTiger closed","attr":{"durationMillis":24}}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.097+00:00"},"s":"I",  "c":"STORAGE",  "id":22279,   "ctx":"SignalHandler","msg":"shutdown: removing fs lock..."}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.098+00:00"},"s":"I",  "c":"-",        "id":4784931, "ctx":"SignalHandler","msg":"Dropping the scope cache for shutdown"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.098+00:00"},"s":"I",  "c":"FTDC",     "id":4784926, "ctx":"SignalHandler","msg":"Shutting down full-time data capture"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.098+00:00"},"s":"I",  "c":"FTDC",     "id":20626,   "ctx":"SignalHandler","msg":"Shutting down full-time diagnostic data capture"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.103+00:00"},"s":"I",  "c":"CONTROL",  "id":20565,   "ctx":"SignalHandler","msg":"Now exiting"}
mongodb         | {"t":{"$date":"2025-12-22T19:26:45.103+00:00"},"s":"I",  "c":"CONTROL",  "id":23138,   "ctx":"SignalHandler","msg":"Shutting down","attr":{"exitCode":0}}
[Kmongodb exited with code 0
[Keurekaserver exited with code 143
[Kconfigserver exited with code 143
kafka           | [2025-12-22 19:26:46,561] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka           | [2025-12-22 19:26:46,562] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
kafka           | [2025-12-22 19:26:46,564] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
kafka           | [2025-12-22 19:26:46,575] INFO [Controller id=1] Shutting down broker 1 (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,575] DEBUG [Controller id=1] All shutting down brokers: 1 (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,576] DEBUG [Controller id=1] Live brokers:  (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,578] INFO [Controller id=1 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
kafka           | [2025-12-22 19:26:46,579] TRACE [Controller id=1] All leaders = __consumer_offsets-13 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-46 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-9 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-42 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-21 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-17 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-30 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-26 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-5 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-38 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-1 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-34 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-16 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-45 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-12 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-41 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-24 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-20 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-49 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-29 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-25 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-8 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-37 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-4 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-33 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-15 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-48 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-11 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-44 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-23 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-19 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-32 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-28 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-7 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-40 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-3 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-36 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-47 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-14 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-43 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),booking-email-0 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-10 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-22 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-18 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-31 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-27 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-39 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-6 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-35 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1),__consumer_offsets-2 -> (Leader:1,ISR:1,LeaderRecoveryState:RECOVERED,LeaderEpoch:0,ZkVersion:0,ControllerEpoch:1) (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,581] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
kafka           | [2025-12-22 19:26:46,584] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka           | [2025-12-22 19:26:46,586] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka           | [2025-12-22 19:26:46,587] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka           | [2025-12-22 19:26:46,588] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
kafka           | [2025-12-22 19:26:46,603] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
kafka           | [2025-12-22 19:26:46,604] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
kafka           | [2025-12-22 19:26:46,607] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
kafka           | [2025-12-22 19:26:46,611] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,612] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,612] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,613] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
kafka           | [2025-12-22 19:26:46,614] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,615] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,615] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,617] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
kafka           | [2025-12-22 19:26:46,620] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
kafka           | [2025-12-22 19:26:46,620] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka           | [2025-12-22 19:26:46,620] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka           | [2025-12-22 19:26:46,620] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka           | [2025-12-22 19:26:46,622] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka           | [2025-12-22 19:26:46,622] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:26:46,623] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,623] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,623] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,626] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,627] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,627] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,628] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
kafka           | [2025-12-22 19:26:46,629] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
kafka           | [2025-12-22 19:26:46,629] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka           | [2025-12-22 19:26:46,629] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka           | [2025-12-22 19:26:46,629] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka           | [2025-12-22 19:26:46,630] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
kafka           | [2025-12-22 19:26:46,631] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
kafka           | [2025-12-22 19:26:46,631] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
kafka           | [2025-12-22 19:26:46,632] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
kafka           | [2025-12-22 19:26:46,632] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,632] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,632] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,632] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,633] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,633] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,634] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,636] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,636] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,637] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,637] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,637] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2025-12-22 19:26:46,647] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
kafka           | [2025-12-22 19:26:46,647] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutting down (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:26:46,648] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Stopped (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:26:46,648] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:26:46,650] INFO Broker to controller channel manager for alterPartition shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
kafka           | [2025-12-22 19:26:46,653] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:26:46,654] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:26:46,654] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
kafka           | [2025-12-22 19:26:46,655] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
kafka           | [2025-12-22 19:26:46,656] INFO Shutting down. (kafka.log.LogManager)
kafka           | [2025-12-22 19:26:46,657] INFO Shutting down the log cleaner. (kafka.log.LogCleaner)
kafka           | [2025-12-22 19:26:46,657] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner)
kafka           | [2025-12-22 19:26:46,658] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner)
kafka           | [2025-12-22 19:26:46,658] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner)
kafka           | [2025-12-22 19:26:46,765] INFO [ProducerStateManager partition=__consumer_offsets-8] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
kafka           | [2025-12-22 19:26:46,927] INFO Shutdown complete. (kafka.log.LogManager)
kafka           | [2025-12-22 19:26:46,927] INFO [ControllerEventThread controllerId=1] Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)
kafka           | [2025-12-22 19:26:46,927] INFO [ControllerEventThread controllerId=1] Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)
kafka           | [2025-12-22 19:26:46,927] INFO [ControllerEventThread controllerId=1] Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)
kafka           | [2025-12-22 19:26:46,928] DEBUG [Controller id=1] Resigning (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,929] DEBUG [Controller id=1] Unregister BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,930] INFO [PartitionStateMachine controllerId=1] Stopped partition state machine (kafka.controller.ZkPartitionStateMachine)
kafka           | [2025-12-22 19:26:46,931] INFO [ReplicaStateMachine controllerId=1] Stopped replica state machine (kafka.controller.ZkReplicaStateMachine)
kafka           | [2025-12-22 19:26:46,931] INFO [RequestSendThread controllerId=1] Shutting down (kafka.controller.RequestSendThread)
kafka           | [2025-12-22 19:26:46,931] INFO [RequestSendThread controllerId=1] Shutdown completed (kafka.controller.RequestSendThread)
kafka           | [2025-12-22 19:26:46,931] INFO [RequestSendThread controllerId=1] Stopped (kafka.controller.RequestSendThread)
kafka           | [2025-12-22 19:26:46,933] INFO [Controller id=1] Resigned (kafka.controller.KafkaController)
kafka           | [2025-12-22 19:26:46,934] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka           | [2025-12-22 19:26:46,934] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka           | [2025-12-22 19:26:46,934] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka           | [2025-12-22 19:26:46,936] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2025-12-22 19:26:47,042] INFO EventThread shut down for session: 0x10000760c0f0001 (org.apache.zookeeper.ClientCnxn)
kafka           | [2025-12-22 19:26:47,042] INFO Session: 0x10000760c0f0001 closed (org.apache.zookeeper.ZooKeeper)
kafka           | [2025-12-22 19:26:47,044] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2025-12-22 19:26:47,044] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,046] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,047] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,047] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,047] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,047] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2025-12-22 19:26:47,047] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
kafka           | [2025-12-22 19:26:47,066] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
kafka           | [2025-12-22 19:26:47,067] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
kafka           | [2025-12-22 19:26:47,067] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
kafka           | [2025-12-22 19:26:47,067] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
kafka           | [2025-12-22 19:26:47,069] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
kafka           | [2025-12-22 19:26:47,070] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2025-12-22 19:26:47,070] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[Kkafka exited with code 143
[Kzookeeper exited with code 143
